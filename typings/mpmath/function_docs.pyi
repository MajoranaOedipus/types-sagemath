"""

Extended docstrings for functions.py
"""
from __future__ import annotations
__all__: list[str] = ['acos', 'acosh', 'acot', 'acoth', 'acsc', 'acsch', 'agm', 'airyai', 'airyaizero', 'airybi', 'airybizero', 'altzeta', 'angerj', 'apery', 'appellf1', 'appellf2', 'appellf3', 'appellf4', 'arg', 'asec', 'asech', 'asin', 'asinh', 'atan', 'atan2', 'atanh', 'barnesg', 'bei', 'bell', 'ber', 'bernoulli', 'bernpoly', 'besseli', 'besselj', 'besselk', 'bessely', 'beta', 'betainc', 'binomial', 'catalan', 'cbrt', 'ceil', 'chebyt', 'chebyu', 'chi', 'ci', 'clcos', 'clsin', 'conj', 'cos', 'cosh', 'cospi', 'cot', 'coth', 'coulombc', 'coulombf', 'coulombg', 'csc', 'csch', 'cyclotomic', 'degree', 'degrees', 'digamma', 'dirichlet', 'e', 'e1', 'ei', 'ellipfun', 'ellipk', 'erf', 'erfc', 'erfi', 'erfinv', 'euler', 'eulernum', 'eulerpoly', 'exp', 'expint', 'expj', 'expjpi', 'expm1', 'fabs', 'fac2', 'factorial', 'ff', 'fibonacci', 'floor', 'fmod', 'frac', 'fresnelc', 'fresnels', 'gamma', 'gammainc', 'gammaprod', 'gegenbauer', 'glaisher', 'grampoint', 'hankel1', 'hankel2', 'harmonic', 'hermite', 'hyp0f1', 'hyp1f1', 'hyp1f2', 'hyp2f0', 'hyp2f1', 'hyp2f2', 'hyp2f3', 'hyp3f2', 'hyper', 'hypercomb', 'hyperfac', 'hyperu', 'im', 'jacobi', 'jtheta', 'kei', 'ker', 'khinchin', 'laguerre', 'lambertw', 'legendre', 'legenp', 'legenq', 'li', 'ln', 'log', 'log10', 'log1p', 'loggamma', 'lommels1', 'lommels2', 'meijerg', 'mertens', 'ncdf', 'nint', 'npdf', 'phi', 'pi', 'polar', 'polyexp', 'polylog', 'powm1', 'primepi', 'primepi2', 'primezeta', 'psi', 'radians', 're', 'rect', 'rf', 'rgamma', 'riemannr', 'root', 'sawtoothw', 'scorergi', 'scorerhi', 'sec', 'sech', 'shi', 'si', 'siegeltheta', 'siegelz', 'sigmoid', 'sign', 'sin', 'sinc', 'sincpi', 'sinh', 'sinpi', 'spherharm', 'sqrt', 'squarew', 'stieltjes', 'stirling1', 'stirling2', 'struveh', 'struvel', 'superfac', 'tan', 'tanh', 'trianglew', 'twinprime', 'unit_triangle', 'unitroots', 'webere', 'whitm', 'whitw', 'zeta']
acos: str = '\nComputes the inverse cosine or arccosine of `x`, `\\cos^{-1}(x)`.\nSince `-1 \\le \\cos(x) \\le 1` for real `x`, the inverse\ncosine is real-valued only for `-1 \\le x \\le 1`. On this interval,\n:func:`~mpmath.acos` is defined to be a monotonically decreasing\nfunction assuming values between `+\\pi` and `0`.\n\nBasic values are::\n\n    >>> from mpmath import *\n    >>> mp.dps = 25; mp.pretty = True\n    >>> acos(-1)\n    3.141592653589793238462643\n    >>> acos(0)\n    1.570796326794896619231322\n    >>> acos(1)\n    0.0\n    >>> nprint(chop(taylor(acos, 0, 6)))\n    [1.5708, -1.0, 0.0, -0.166667, 0.0, -0.075, 0.0]\n\n:func:`~mpmath.acos` is defined so as to be a proper inverse function of\n`\\cos(\\theta)` for `0 \\le \\theta < \\pi`.\nWe have `\\cos(\\cos^{-1}(x)) = x` for all `x`, but\n`\\cos^{-1}(\\cos(x)) = x` only for `0 \\le \\Re[x] < \\pi`::\n\n    >>> for x in [1, 10, -1, 2+3j, 10+3j]:\n    ...     print("%s %s" % (cos(acos(x)), acos(cos(x))))\n    ...\n    1.0 1.0\n    (10.0 + 0.0j) 2.566370614359172953850574\n    -1.0 1.0\n    (2.0 + 3.0j) (2.0 + 3.0j)\n    (10.0 + 3.0j) (2.566370614359172953850574 - 3.0j)\n\nThe inverse cosine has two branch points: `x = \\pm 1`. :func:`~mpmath.acos`\nplaces the branch cuts along the line segments `(-\\infty, -1)` and\n`(+1, +\\infty)`. In general,\n\n.. math ::\n\n    \\cos^{-1}(x) = \\frac{\\pi}{2} + i \\log\\left(ix + \\sqrt{1-x^2} \\right)\n\nwhere the principal-branch log and square root are implied.\n'
acosh: str = 'Computes the inverse hyperbolic cosine of `x`,\n`\\mathrm{cosh}^{-1}(x) = \\log(x+\\sqrt{x+1}\\sqrt{x-1})`.\n'
acot: str = 'Computes the inverse cotangent of `x`,\n`\\mathrm{cot}^{-1}(x) = \\tan^{-1}(1/x)`.'
acoth: str = 'Computes the inverse hyperbolic cotangent of `x`,\n`\\mathrm{coth}^{-1}(x) = \\tanh^{-1}(1/x)`.'
acsc: str = 'Computes the inverse cosecant of `x`,\n`\\mathrm{csc}^{-1}(x) = \\sin^{-1}(1/x)`.'
acsch: str = 'Computes the inverse hyperbolic cosecant of `x`,\n`\\mathrm{csch}^{-1}(x) = \\sinh^{-1}(1/x)`.'
agm: str = "\n``agm(a, b)`` computes the arithmetic-geometric mean of `a` and\n`b`, defined as the limit of the following iteration:\n\n.. math ::\n\n    a_0 = a\n\n    b_0 = b\n\n    a_{n+1} = \\frac{a_n+b_n}{2}\n\n    b_{n+1} = \\sqrt{a_n b_n}\n\nThis function can be called with a single argument, computing\n`\\mathrm{agm}(a,1) = \\mathrm{agm}(1,a)`.\n\n**Examples**\n\nIt is a well-known theorem that the geometric mean of\ntwo distinct positive numbers is less than the arithmetic\nmean. It follows that the arithmetic-geometric mean lies\nbetween the two means::\n\n    >>> from mpmath import *\n    >>> mp.dps = 15; mp.pretty = True\n    >>> a = mpf(3)\n    >>> b = mpf(4)\n    >>> sqrt(a*b)\n    3.46410161513775\n    >>> agm(a,b)\n    3.48202767635957\n    >>> (a+b)/2\n    3.5\n\nThe arithmetic-geometric mean is scale-invariant::\n\n    >>> agm(10*e, 10*pi)\n    29.261085515723\n    >>> 10*agm(e, pi)\n    29.261085515723\n\nAs an order-of-magnitude estimate, `\\mathrm{agm}(1,x) \\approx x`\nfor large `x`::\n\n    >>> agm(10**10)\n    643448704.760133\n    >>> agm(10**50)\n    1.34814309345871e+48\n\nFor tiny `x`, `\\mathrm{agm}(1,x) \\approx -\\pi/(2 \\log(x/4))`::\n\n    >>> agm('0.01')\n    0.262166887202249\n    >>> -pi/2/log('0.0025')\n    0.262172347753122\n\nThe arithmetic-geometric mean can also be computed for complex\nnumbers::\n\n    >>> agm(3, 2+j)\n    (2.51055133276184 + 0.547394054060638j)\n\nThe AGM iteration converges very quickly (each step doubles\nthe number of correct digits), so :func:`~mpmath.agm` supports efficient\nhigh-precision evaluation::\n\n    >>> mp.dps = 10000\n    >>> a = agm(1,2)\n    >>> str(a)[-10:]\n    '1679581912'\n\n**Mathematical relations**\n\nThe arithmetic-geometric mean may be used to evaluate the\nfollowing two parametric definite integrals:\n\n.. math ::\n\n  I_1 = \\int_0^{\\infty}\n    \\frac{1}{\\sqrt{(x^2+a^2)(x^2+b^2)}} \\,dx\n\n  I_2 = \\int_0^{\\pi/2}\n    \\frac{1}{\\sqrt{a^2 \\cos^2(x) + b^2 \\sin^2(x)}} \\,dx\n\nWe have::\n\n    >>> mp.dps = 15\n    >>> a = 3\n    >>> b = 4\n    >>> f1 = lambda x: ((x**2+a**2)*(x**2+b**2))**-0.5\n    >>> f2 = lambda x: ((a*cos(x))**2 + (b*sin(x))**2)**-0.5\n    >>> quad(f1, [0, inf])\n    0.451115405388492\n    >>> quad(f2, [0, pi/2])\n    0.451115405388492\n    >>> pi/(2*agm(a,b))\n    0.451115405388492\n\nA formula for `\\Gamma(1/4)`::\n\n    >>> gamma(0.25)\n    3.62560990822191\n    >>> sqrt(2*sqrt(2*pi**3)/agm(1,sqrt(2)))\n    3.62560990822191\n\n**Possible issues**\n\nThe branch cut chosen for complex `a` and `b` is somewhat\narbitrary.\n\n"
airyai: str = "\nComputes the Airy function `\\operatorname{Ai}(z)`, which is\nthe solution of the Airy differential equation `f''(z) - z f(z) = 0`\nwith initial conditions\n\n.. math ::\n\n    \\operatorname{Ai}(0) =\n        \\frac{1}{3^{2/3}\\Gamma\\left(\\frac{2}{3}\\right)}\n\n    \\operatorname{Ai}'(0) =\n        -\\frac{1}{3^{1/3}\\Gamma\\left(\\frac{1}{3}\\right)}.\n\nOther common ways of defining the Ai-function include\nintegrals such as\n\n.. math ::\n\n    \\operatorname{Ai}(x) = \\frac{1}{\\pi}\n        \\int_0^{\\infty} \\cos\\left(\\frac{1}{3}t^3+xt\\right) dt\n        \\qquad x \\in \\mathbb{R}\n\n    \\operatorname{Ai}(z) = \\frac{\\sqrt{3}}{2\\pi}\n        \\int_0^{\\infty}\n        \\exp\\left(-\\frac{t^3}{3}-\\frac{z^3}{3t^3}\\right) dt.\n\nThe Ai-function is an entire function with a turning point,\nbehaving roughly like a slowly decaying sine wave for `z < 0` and\nlike a rapidly decreasing exponential for `z > 0`.\nA second solution of the Airy differential equation\nis given by `\\operatorname{Bi}(z)` (see :func:`~mpmath.airybi`).\n\nOptionally, with *derivative=alpha*, :func:`airyai` can compute the\n`\\alpha`-th order fractional derivative with respect to `z`.\nFor `\\alpha = n = 1,2,3,\\ldots` this gives the derivative\n`\\operatorname{Ai}^{(n)}(z)`, and for `\\alpha = -n = -1,-2,-3,\\ldots`\nthis gives the `n`-fold iterated integral\n\n.. math ::\n\n    f_0(z) = \\operatorname{Ai}(z)\n\n    f_n(z) = \\int_0^z f_{n-1}(t) dt.\n\nThe Ai-function has infinitely many zeros, all located along the\nnegative half of the real axis. They can be computed with\n:func:`~mpmath.airyaizero`.\n\n**Plots**\n\n.. literalinclude :: /plots/ai.py\n.. image :: /plots/ai.png\n.. literalinclude :: /plots/ai_c.py\n.. image :: /plots/ai_c.png\n\n**Basic examples**\n\nLimits and values include::\n\n    >>> from mpmath import *\n    >>> mp.dps = 25; mp.pretty = True\n    >>> airyai(0); 1/(power(3,'2/3')*gamma('2/3'))\n    0.3550280538878172392600632\n    0.3550280538878172392600632\n    >>> airyai(1)\n    0.1352924163128814155241474\n    >>> airyai(-1)\n    0.5355608832923521187995166\n    >>> airyai(inf); airyai(-inf)\n    0.0\n    0.0\n\nEvaluation is supported for large magnitudes of the argument::\n\n    >>> airyai(-100)\n    0.1767533932395528780908311\n    >>> airyai(100)\n    2.634482152088184489550553e-291\n    >>> airyai(50+50j)\n    (-5.31790195707456404099817e-68 - 1.163588003770709748720107e-67j)\n    >>> airyai(-50+50j)\n    (1.041242537363167632587245e+158 + 3.347525544923600321838281e+157j)\n\nHuge arguments are also fine::\n\n    >>> airyai(10**10)\n    1.162235978298741779953693e-289529654602171\n    >>> airyai(-10**10)\n    0.0001736206448152818510510181\n    >>> w = airyai(10**10*(1+j))\n    >>> w.real\n    5.711508683721355528322567e-186339621747698\n    >>> w.imag\n    1.867245506962312577848166e-186339621747697\n\nThe first root of the Ai-function is::\n\n    >>> findroot(airyai, -2)\n    -2.338107410459767038489197\n    >>> airyaizero(1)\n    -2.338107410459767038489197\n\n**Properties and relations**\n\nVerifying the Airy differential equation::\n\n    >>> for z in [-3.4, 0, 2.5, 1+2j]:\n    ...     chop(airyai(z,2) - z*airyai(z))\n    ...\n    0.0\n    0.0\n    0.0\n    0.0\n\nThe first few terms of the Taylor series expansion around `z = 0`\n(every third term is zero)::\n\n    >>> nprint(taylor(airyai, 0, 5))\n    [0.355028, -0.258819, 0.0, 0.0591713, -0.0215683, 0.0]\n\nThe Airy functions satisfy the Wronskian relation\n`\\operatorname{Ai}(z) \\operatorname{Bi}'(z) -\n\\operatorname{Ai}'(z) \\operatorname{Bi}(z) = 1/\\pi`::\n\n    >>> z = -0.5\n    >>> airyai(z)*airybi(z,1) - airyai(z,1)*airybi(z)\n    0.3183098861837906715377675\n    >>> 1/pi\n    0.3183098861837906715377675\n\nThe Airy functions can be expressed in terms of Bessel\nfunctions of order `\\pm 1/3`. For `\\Re[z] \\le 0`, we have::\n\n    >>> z = -3\n    >>> airyai(z)\n    -0.3788142936776580743472439\n    >>> y = 2*power(-z,'3/2')/3\n    >>> (sqrt(-z) * (besselj('1/3',y) + besselj('-1/3',y)))/3\n    -0.3788142936776580743472439\n\n**Derivatives and integrals**\n\nDerivatives of the Ai-function (directly and using :func:`~mpmath.diff`)::\n\n    >>> airyai(-3,1); diff(airyai,-3)\n    0.3145837692165988136507873\n    0.3145837692165988136507873\n    >>> airyai(-3,2); diff(airyai,-3,2)\n    1.136442881032974223041732\n    1.136442881032974223041732\n    >>> airyai(1000,1); diff(airyai,1000)\n    -2.943133917910336090459748e-9156\n    -2.943133917910336090459748e-9156\n\nSeveral derivatives at `z = 0`::\n\n    >>> airyai(0,0); airyai(0,1); airyai(0,2)\n    0.3550280538878172392600632\n    -0.2588194037928067984051836\n    0.0\n    >>> airyai(0,3); airyai(0,4); airyai(0,5)\n    0.3550280538878172392600632\n    -0.5176388075856135968103671\n    0.0\n    >>> airyai(0,15); airyai(0,16); airyai(0,17)\n    1292.30211615165475090663\n    -3188.655054727379756351861\n    0.0\n\nThe integral of the Ai-function::\n\n    >>> airyai(3,-1); quad(airyai, [0,3])\n    0.3299203760070217725002701\n    0.3299203760070217725002701\n    >>> airyai(-10,-1); quad(airyai, [0,-10])\n    -0.765698403134212917425148\n    -0.765698403134212917425148\n\nIntegrals of high or fractional order::\n\n    >>> airyai(-2,0.5); differint(airyai,-2,0.5,0)\n    (0.0 + 0.2453596101351438273844725j)\n    (0.0 + 0.2453596101351438273844725j)\n    >>> airyai(-2,-4); differint(airyai,-2,-4,0)\n    0.2939176441636809580339365\n    0.2939176441636809580339365\n    >>> airyai(0,-1); airyai(0,-2); airyai(0,-3)\n    0.0\n    0.0\n    0.0\n\nIntegrals of the Ai-function can be evaluated at limit points::\n\n    >>> airyai(-1000000,-1); airyai(-inf,-1)\n    -0.6666843728311539978751512\n    -0.6666666666666666666666667\n    >>> airyai(10,-1); airyai(+inf,-1)\n    0.3333333332991690159427932\n    0.3333333333333333333333333\n    >>> airyai(+inf,-2); airyai(+inf,-3)\n    +inf\n    +inf\n    >>> airyai(-1000000,-2); airyai(-inf,-2)\n    666666.4078472650651209742\n    +inf\n    >>> airyai(-1000000,-3); airyai(-inf,-3)\n    -333333074513.7520264995733\n    -inf\n\n**References**\n\n1. [DLMF]_ Chapter 9: Airy and Related Functions\n2. [WolframFunctions]_ section: Bessel-Type Functions\n\n"
airyaizero: str = "\nGives the `k`-th zero of the Airy Ai-function,\ni.e. the `k`-th number `a_k` ordered by magnitude for which\n`\\operatorname{Ai}(a_k) = 0`.\n\nOptionally, with *derivative=1*, the corresponding\nzero `a'_k` of the derivative function, i.e.\n`\\operatorname{Ai}'(a'_k) = 0`, is computed.\n\n**Examples**\n\nSome values of `a_k`::\n\n    >>> from mpmath import *\n    >>> mp.dps = 25; mp.pretty = True\n    >>> airyaizero(1)\n    -2.338107410459767038489197\n    >>> airyaizero(2)\n    -4.087949444130970616636989\n    >>> airyaizero(3)\n    -5.520559828095551059129856\n    >>> airyaizero(1000)\n    -281.0315196125215528353364\n\nSome values of `a'_k`::\n\n    >>> airyaizero(1,1)\n    -1.018792971647471089017325\n    >>> airyaizero(2,1)\n    -3.248197582179836537875424\n    >>> airyaizero(3,1)\n    -4.820099211178735639400616\n    >>> airyaizero(1000,1)\n    -280.9378080358935070607097\n\nVerification::\n\n    >>> chop(airyai(airyaizero(1)))\n    0.0\n    >>> chop(airyai(airyaizero(1,1),1))\n    0.0\n\n"
airybi: str = "\nComputes the Airy function `\\operatorname{Bi}(z)`, which is\nthe solution of the Airy differential equation `f''(z) - z f(z) = 0`\nwith initial conditions\n\n.. math ::\n\n    \\operatorname{Bi}(0) =\n        \\frac{1}{3^{1/6}\\Gamma\\left(\\frac{2}{3}\\right)}\n\n    \\operatorname{Bi}'(0) =\n        \\frac{3^{1/6}}{\\Gamma\\left(\\frac{1}{3}\\right)}.\n\nLike the Ai-function (see :func:`~mpmath.airyai`), the Bi-function\nis oscillatory for `z < 0`, but it grows rather than decreases\nfor `z > 0`.\n\nOptionally, as for :func:`~mpmath.airyai`, derivatives, integrals\nand fractional derivatives can be computed with the *derivative*\nparameter.\n\nThe Bi-function has infinitely many zeros along the negative\nhalf-axis, as well as complex zeros, which can all be computed\nwith :func:`~mpmath.airybizero`.\n\n**Plots**\n\n.. literalinclude :: /plots/bi.py\n.. image :: /plots/bi.png\n.. literalinclude :: /plots/bi_c.py\n.. image :: /plots/bi_c.png\n\n**Basic examples**\n\nLimits and values include::\n\n    >>> from mpmath import *\n    >>> mp.dps = 25; mp.pretty = True\n    >>> airybi(0); 1/(power(3,'1/6')*gamma('2/3'))\n    0.6149266274460007351509224\n    0.6149266274460007351509224\n    >>> airybi(1)\n    1.207423594952871259436379\n    >>> airybi(-1)\n    0.10399738949694461188869\n    >>> airybi(inf); airybi(-inf)\n    +inf\n    0.0\n\nEvaluation is supported for large magnitudes of the argument::\n\n    >>> airybi(-100)\n    0.02427388768016013160566747\n    >>> airybi(100)\n    6.041223996670201399005265e+288\n    >>> airybi(50+50j)\n    (-5.322076267321435669290334e+63 + 1.478450291165243789749427e+65j)\n    >>> airybi(-50+50j)\n    (-3.347525544923600321838281e+157 + 1.041242537363167632587245e+158j)\n\nHuge arguments::\n\n    >>> airybi(10**10)\n    1.369385787943539818688433e+289529654602165\n    >>> airybi(-10**10)\n    0.001775656141692932747610973\n    >>> w = airybi(10**10*(1+j))\n    >>> w.real\n    -6.559955931096196875845858e+186339621747689\n    >>> w.imag\n    -6.822462726981357180929024e+186339621747690\n\nThe first real root of the Bi-function is::\n\n    >>> findroot(airybi, -1); airybizero(1)\n    -1.17371322270912792491998\n    -1.17371322270912792491998\n\n**Properties and relations**\n\nVerifying the Airy differential equation::\n\n    >>> for z in [-3.4, 0, 2.5, 1+2j]:\n    ...     chop(airybi(z,2) - z*airybi(z))\n    ...\n    0.0\n    0.0\n    0.0\n    0.0\n\nThe first few terms of the Taylor series expansion around `z = 0`\n(every third term is zero)::\n\n    >>> nprint(taylor(airybi, 0, 5))\n    [0.614927, 0.448288, 0.0, 0.102488, 0.0373574, 0.0]\n\nThe Airy functions can be expressed in terms of Bessel\nfunctions of order `\\pm 1/3`. For `\\Re[z] \\le 0`, we have::\n\n    >>> z = -3\n    >>> airybi(z)\n    -0.1982896263749265432206449\n    >>> p = 2*power(-z,'3/2')/3\n    >>> sqrt(-mpf(z)/3)*(besselj('-1/3',p) - besselj('1/3',p))\n    -0.1982896263749265432206449\n\n**Derivatives and integrals**\n\nDerivatives of the Bi-function (directly and using :func:`~mpmath.diff`)::\n\n    >>> airybi(-3,1); diff(airybi,-3)\n    -0.675611222685258537668032\n    -0.675611222685258537668032\n    >>> airybi(-3,2); diff(airybi,-3,2)\n    0.5948688791247796296619346\n    0.5948688791247796296619346\n    >>> airybi(1000,1); diff(airybi,1000)\n    1.710055114624614989262335e+9156\n    1.710055114624614989262335e+9156\n\nSeveral derivatives at `z = 0`::\n\n    >>> airybi(0,0); airybi(0,1); airybi(0,2)\n    0.6149266274460007351509224\n    0.4482883573538263579148237\n    0.0\n    >>> airybi(0,3); airybi(0,4); airybi(0,5)\n    0.6149266274460007351509224\n    0.8965767147076527158296474\n    0.0\n    >>> airybi(0,15); airybi(0,16); airybi(0,17)\n    2238.332923903442675949357\n    5522.912562599140729510628\n    0.0\n\nThe integral of the Bi-function::\n\n    >>> airybi(3,-1); quad(airybi, [0,3])\n    10.06200303130620056316655\n    10.06200303130620056316655\n    >>> airybi(-10,-1); quad(airybi, [0,-10])\n    -0.01504042480614002045135483\n    -0.01504042480614002045135483\n\nIntegrals of high or fractional order::\n\n    >>> airybi(-2,0.5); differint(airybi, -2, 0.5, 0)\n    (0.0 + 0.5019859055341699223453257j)\n    (0.0 + 0.5019859055341699223453257j)\n    >>> airybi(-2,-4); differint(airybi,-2,-4,0)\n    0.2809314599922447252139092\n    0.2809314599922447252139092\n    >>> airybi(0,-1); airybi(0,-2); airybi(0,-3)\n    0.0\n    0.0\n    0.0\n\nIntegrals of the Bi-function can be evaluated at limit points::\n\n    >>> airybi(-1000000,-1); airybi(-inf,-1)\n    0.000002191261128063434047966873\n    0.0\n    >>> airybi(10,-1); airybi(+inf,-1)\n    147809803.1074067161675853\n    +inf\n    >>> airybi(+inf,-2); airybi(+inf,-3)\n    +inf\n    +inf\n    >>> airybi(-1000000,-2); airybi(-inf,-2)\n    0.4482883750599908479851085\n    0.4482883573538263579148237\n    >>> gamma('2/3')*power(3,'2/3')/(2*pi)\n    0.4482883573538263579148237\n    >>> airybi(-100000,-3); airybi(-inf,-3)\n    -44828.52827206932872493133\n    -inf\n    >>> airybi(-100000,-4); airybi(-inf,-4)\n    2241411040.437759489540248\n    +inf\n\n"
airybizero: str = "\nWith *complex=False*, gives the `k`-th real zero of the Airy Bi-function,\ni.e. the `k`-th number `b_k` ordered by magnitude for which\n`\\operatorname{Bi}(b_k) = 0`.\n\nWith *complex=True*, gives the `k`-th complex zero in the upper\nhalf plane `\\beta_k`. Also the conjugate `\\overline{\\beta_k}`\nis a zero.\n\nOptionally, with *derivative=1*, the corresponding\nzero `b'_k` or `\\beta'_k` of the derivative function, i.e.\n`\\operatorname{Bi}'(b'_k) = 0` or `\\operatorname{Bi}'(\\beta'_k) = 0`,\nis computed.\n\n**Examples**\n\nSome values of `b_k`::\n\n    >>> from mpmath import *\n    >>> mp.dps = 25; mp.pretty = True\n    >>> airybizero(1)\n    -1.17371322270912792491998\n    >>> airybizero(2)\n    -3.271093302836352715680228\n    >>> airybizero(3)\n    -4.830737841662015932667709\n    >>> airybizero(1000)\n    -280.9378112034152401578834\n\nSome values of `b_k`::\n\n    >>> airybizero(1,1)\n    -2.294439682614123246622459\n    >>> airybizero(2,1)\n    -4.073155089071828215552369\n    >>> airybizero(3,1)\n    -5.512395729663599496259593\n    >>> airybizero(1000,1)\n    -281.0315164471118527161362\n\nSome values of `\\beta_k`::\n\n    >>> airybizero(1,complex=True)\n    (0.9775448867316206859469927 + 2.141290706038744575749139j)\n    >>> airybizero(2,complex=True)\n    (1.896775013895336346627217 + 3.627291764358919410440499j)\n    >>> airybizero(3,complex=True)\n    (2.633157739354946595708019 + 4.855468179979844983174628j)\n    >>> airybizero(1000,complex=True)\n    (140.4978560578493018899793 + 243.3907724215792121244867j)\n\nSome values of `\\beta'_k`::\n\n    >>> airybizero(1,1,complex=True)\n    (0.2149470745374305676088329 + 1.100600143302797880647194j)\n    >>> airybizero(2,1,complex=True)\n    (1.458168309223507392028211 + 2.912249367458445419235083j)\n    >>> airybizero(3,1,complex=True)\n    (2.273760763013482299792362 + 4.254528549217097862167015j)\n    >>> airybizero(1000,1,complex=True)\n    (140.4509972835270559730423 + 243.3096175398562811896208j)\n\nVerification::\n\n    >>> chop(airybi(airybizero(1)))\n    0.0\n    >>> chop(airybi(airybizero(1,1),1))\n    0.0\n    >>> u = airybizero(1,complex=True)\n    >>> chop(airybi(u))\n    0.0\n    >>> chop(airybi(conj(u)))\n    0.0\n\nThe complex zeros (in the upper and lower half-planes respectively)\nasymptotically approach the rays `z = R \\exp(\\pm i \\pi /3)`::\n\n    >>> arg(airybizero(1,complex=True))\n    1.142532510286334022305364\n    >>> arg(airybizero(1000,complex=True))\n    1.047271114786212061583917\n    >>> arg(airybizero(1000000,complex=True))\n    1.047197624741816183341355\n    >>> pi/3\n    1.047197551196597746154214\n\n"
altzeta: str = "\nGives the Dirichlet eta function, `\\eta(s)`, also known as the\nalternating zeta function. This function is defined in analogy\nwith the Riemann zeta function as providing the sum of the\nalternating series\n\n.. math ::\n\n    \\eta(s) = \\sum_{k=0}^{\\infty} \\frac{(-1)^k}{k^s}\n        = 1-\\frac{1}{2^s}+\\frac{1}{3^s}-\\frac{1}{4^s}+\\ldots\n\nThe eta function, unlike the Riemann zeta function, is an entire\nfunction, having a finite value for all complex `s`. The special case\n`\\eta(1) = \\log(2)` gives the value of the alternating harmonic series.\n\nThe alternating zeta function may expressed using the Riemann zeta function\nas `\\eta(s) = (1 - 2^{1-s}) \\zeta(s)`. It can also be expressed\nin terms of the Hurwitz zeta function, for example using\n:func:`~mpmath.dirichlet` (see documentation for that function).\n\n**Examples**\n\nSome special values are::\n\n    >>> from mpmath import *\n    >>> mp.dps = 15; mp.pretty = True\n    >>> altzeta(1)\n    0.693147180559945\n    >>> altzeta(0)\n    0.5\n    >>> altzeta(-1)\n    0.25\n    >>> altzeta(-2)\n    0.0\n\nAn example of a sum that can be computed more accurately and\nefficiently via :func:`~mpmath.altzeta` than via numerical summation::\n\n    >>> sum(-(-1)**n / mpf(n)**2.5 for n in range(1, 100))\n    0.867204951503984\n    >>> altzeta(2.5)\n    0.867199889012184\n\nAt positive even integers, the Dirichlet eta function\nevaluates to a rational multiple of a power of `\\pi`::\n\n    >>> altzeta(2)\n    0.822467033424113\n    >>> pi**2/12\n    0.822467033424113\n\nLike the Riemann zeta function, `\\eta(s)`, approaches 1\nas `s` approaches positive infinity, although it does\nso from below rather than from above::\n\n    >>> altzeta(30)\n    0.999999999068682\n    >>> altzeta(inf)\n    1.0\n    >>> mp.pretty = False\n    >>> altzeta(1000, rounding='d')\n    mpf('0.99999999999999989')\n    >>> altzeta(1000, rounding='u')\n    mpf('1.0')\n\n**References**\n\n1. http://mathworld.wolfram.com/DirichletEtaFunction.html\n\n2. http://en.wikipedia.org/wiki/Dirichlet_eta_function\n"
angerj: str = "\nGives the Anger function\n\n.. math ::\n\n    \\mathbf{J}_{\\nu}(z) = \\frac{1}{\\pi}\n        \\int_0^{\\pi} \\cos(\\nu t - z \\sin t) dt\n\nwhich is an entire function of both the parameter `\\nu` and\nthe argument `z`. It solves the inhomogeneous Bessel differential\nequation\n\n.. math ::\n\n    f''(z) + \\frac{1}{z}f'(z) + \\left(1-\\frac{\\nu^2}{z^2}\\right) f(z)\n        = \\frac{(z-\\nu)}{\\pi z^2} \\sin(\\pi \\nu).\n\n**Examples**\n\nEvaluation for real and complex parameter and argument::\n\n    >>> from mpmath import *\n    >>> mp.dps = 25; mp.pretty = True\n    >>> angerj(2,3)\n    0.4860912605858910769078311\n    >>> angerj(-3+4j, 2+5j)\n    (-5033.358320403384472395612 + 585.8011892476145118551756j)\n    >>> angerj(3.25, 1e6j)\n    (4.630743639715893346570743e+434290 - 1.117960409887505906848456e+434291j)\n    >>> angerj(-1.5, 1e6)\n    0.0002795719747073879393087011\n\nThe Anger function coincides with the Bessel J-function when `\\nu`\nis an integer::\n\n    >>> angerj(1,3); besselj(1,3)\n    0.3390589585259364589255146\n    0.3390589585259364589255146\n    >>> angerj(1.5,3); besselj(1.5,3)\n    0.4088969848691080859328847\n    0.4777182150870917715515015\n\nVerifying the differential equation::\n\n    >>> v,z = mpf(2.25), 0.75\n    >>> f = lambda z: angerj(v,z)\n    >>> diff(f,z,2) + diff(f,z)/z + (1-(v/z)**2)*f(z)\n    -0.6002108774380707130367995\n    >>> (z-v)/(pi*z**2) * sinpi(v)\n    -0.6002108774380707130367995\n\nVerifying the integral representation::\n\n    >>> angerj(v,z)\n    0.1145380759919333180900501\n    >>> quad(lambda t: cos(v*t-z*sin(t))/pi, [0,pi])\n    0.1145380759919333180900501\n\n**References**\n\n1. [DLMF]_ section 11.10: Anger-Weber Functions\n"
apery: str = "\nRepresents Apery's constant, which is the irrational number\napproximately equal to 1.2020569 given by\n\n.. math ::\n\n    \\zeta(3) = \\sum_{k=1}^\\infty\\frac{1}{k^3}.\n\nThe calculation is based on an efficient hypergeometric\nseries. To 50 decimal places, the value is given by::\n\n    >>> from mpmath import *\n    >>> mp.dps = 50; mp.pretty = True\n    >>> +apery\n    1.2020569031595942853997381615114499907649862923405\n\nOther ways to evaluate Apery's constant using mpmath\ninclude::\n\n    >>> zeta(3)\n    1.2020569031595942853997381615114499907649862923405\n    >>> -psi(2,1)/2\n    1.2020569031595942853997381615114499907649862923405\n    >>> 8*nsum(lambda k: 1/(2*k+1)**3, [0,inf])/7\n    1.2020569031595942853997381615114499907649862923405\n    >>> f = lambda k: 2/k**3/(exp(2*pi*k)-1)\n    >>> 7*pi**3/180 - nsum(f, [1,inf])\n    1.2020569031595942853997381615114499907649862923405\n\nThis shows digits 9991-10000 of Apery's constant::\n\n    >>> mp.dps = 10000\n    >>> str(apery)[-10:]\n    '3189504235'\n"
appellf1: str = '\nGives the Appell F1 hypergeometric function of two variables,\n\n.. math ::\n\n    F_1(a,b_1,b_2,c,x,y) = \\sum_{m=0}^{\\infty} \\sum_{n=0}^{\\infty}\n        \\frac{(a)_{m+n} (b_1)_m (b_2)_n}{(c)_{m+n}}\n        \\frac{x^m y^n}{m! n!}.\n\nThis series is only generally convergent when `|x| < 1` and `|y| < 1`,\nalthough :func:`~mpmath.appellf1` can evaluate an analytic continuation\nwith respecto to either variable, and sometimes both.\n\n**Examples**\n\nEvaluation is supported for real and complex parameters::\n\n    >>> from mpmath import *\n    >>> mp.dps = 25; mp.pretty = True\n    >>> appellf1(1,0,0.5,1,0.5,0.25)\n    1.154700538379251529018298\n    >>> appellf1(1,1+j,0.5,1,0.5,0.5j)\n    (1.138403860350148085179415 + 1.510544741058517621110615j)\n\nFor some integer parameters, the F1 series reduces to a polynomial::\n\n    >>> appellf1(2,-4,-3,1,2,5)\n    -816.0\n    >>> appellf1(-5,1,2,1,4,5)\n    -20528.0\n\nThe analytic continuation with respect to either `x` or `y`,\nand sometimes with respect to both, can be evaluated::\n\n    >>> appellf1(2,3,4,5,100,0.5)\n    (0.0006231042714165329279738662 + 0.0000005769149277148425774499857j)\n    >>> appellf1(\'1.1\', \'0.3\', \'0.2+2j\', \'0.4\', \'0.2\', 1.5+3j)\n    (-0.1782604566893954897128702 + 0.002472407104546216117161499j)\n    >>> appellf1(1,2,3,4,10,12)\n    -0.07122993830066776374929313\n\nFor certain arguments, F1 reduces to an ordinary hypergeometric function::\n\n    >>> appellf1(1,2,3,5,0.5,0.25)\n    1.547902270302684019335555\n    >>> 4*hyp2f1(1,2,5,\'1/3\')/3\n    1.547902270302684019335555\n    >>> appellf1(1,2,3,4,0,1.5)\n    (-1.717202506168937502740238 - 2.792526803190927323077905j)\n    >>> hyp2f1(1,3,4,1.5)\n    (-1.717202506168937502740238 - 2.792526803190927323077905j)\n\nThe F1 function satisfies a system of partial differential equations::\n\n    >>> a,b1,b2,c,x,y = map(mpf, [1,0.5,0.25,1.125,0.25,-0.25])\n    >>> F = lambda x,y: appellf1(a,b1,b2,c,x,y)\n    >>> chop(x*(1-x)*diff(F,(x,y),(2,0)) +\n    ...      y*(1-x)*diff(F,(x,y),(1,1)) +\n    ...      (c-(a+b1+1)*x)*diff(F,(x,y),(1,0)) -\n    ...      b1*y*diff(F,(x,y),(0,1)) -\n    ...      a*b1*F(x,y))\n    0.0\n    >>>\n    >>> chop(y*(1-y)*diff(F,(x,y),(0,2)) +\n    ...      x*(1-y)*diff(F,(x,y),(1,1)) +\n    ...      (c-(a+b2+1)*y)*diff(F,(x,y),(0,1)) -\n    ...      b2*x*diff(F,(x,y),(1,0)) -\n    ...      a*b2*F(x,y))\n    0.0\n\nThe Appell F1 function allows for closed-form evaluation of various\nintegrals, such as any integral of the form\n`\\int x^r (x+a)^p (x+b)^q dx`::\n\n    >>> def integral(a,b,p,q,r,x1,x2):\n    ...     a,b,p,q,r,x1,x2 = map(mpmathify, [a,b,p,q,r,x1,x2])\n    ...     f = lambda x: x**r * (x+a)**p * (x+b)**q\n    ...     def F(x):\n    ...         v = x**(r+1)/(r+1) * (a+x)**p * (b+x)**q\n    ...         v *= (1+x/a)**(-p)\n    ...         v *= (1+x/b)**(-q)\n    ...         v *= appellf1(r+1,-p,-q,2+r,-x/a,-x/b)\n    ...         return v\n    ...     print("Num. quad: %s" % quad(f, [x1,x2]))\n    ...     print("Appell F1: %s" % (F(x2)-F(x1)))\n    ...\n    >>> integral(\'1/5\',\'4/3\',\'-2\',\'3\',\'1/2\',0,1)\n    Num. quad: 9.073335358785776206576981\n    Appell F1: 9.073335358785776206576981\n    >>> integral(\'3/2\',\'4/3\',\'-2\',\'3\',\'1/2\',0,1)\n    Num. quad: 1.092829171999626454344678\n    Appell F1: 1.092829171999626454344678\n    >>> integral(\'3/2\',\'4/3\',\'-2\',\'3\',\'1/2\',12,25)\n    Num. quad: 1106.323225040235116498927\n    Appell F1: 1106.323225040235116498927\n\nAlso incomplete elliptic integrals fall into this category [1]::\n\n    >>> def E(z, m):\n    ...     if (pi/2).ae(z):\n    ...         return ellipe(m)\n    ...     return 2*round(re(z)/pi)*ellipe(m) + mpf(-1)**round(re(z)/pi)*\\\n    ...         sin(z)*appellf1(0.5,0.5,-0.5,1.5,sin(z)**2,m*sin(z)**2)\n    ...\n    >>> z, m = 1, 0.5\n    >>> E(z,m); quad(lambda t: sqrt(1-m*sin(t)**2), [0,pi/4,3*pi/4,z])\n    0.9273298836244400669659042\n    0.9273298836244400669659042\n    >>> z, m = 3, 2\n    >>> E(z,m); quad(lambda t: sqrt(1-m*sin(t)**2), [0,pi/4,3*pi/4,z])\n    (1.057495752337234229715836 + 1.198140234735592207439922j)\n    (1.057495752337234229715836 + 1.198140234735592207439922j)\n\n**References**\n\n1. [WolframFunctions]_ http://functions.wolfram.com/EllipticIntegrals/EllipticE2/26/01/\n2. [SrivastavaKarlsson]_\n3. [CabralRosetti]_\n4. [Vidunas]_\n5. [Slater]_\n\n'
appellf2: str = '\nGives the Appell F2 hypergeometric function of two variables\n\n.. math ::\n\n    F_2(a,b_1,b_2,c_1,c_2,x,y) = \\sum_{m=0}^{\\infty} \\sum_{n=0}^{\\infty}\n        \\frac{(a)_{m+n} (b_1)_m (b_2)_n}{(c_1)_m (c_2)_n}\n        \\frac{x^m y^n}{m! n!}.\n\nThe series is generally absolutely convergent for `|x| + |y| < 1`.\n\n**Examples**\n\nEvaluation for real and complex arguments::\n\n    >>> from mpmath import *\n    >>> mp.dps = 25; mp.pretty = True\n    >>> appellf2(1,2,3,4,5,0.25,0.125)\n    1.257417193533135344785602\n    >>> appellf2(1,-3,-4,2,3,2,3)\n    -42.8\n    >>> appellf2(0.5,0.25,-0.25,2,3,0.25j,0.25)\n    (0.9880539519421899867041719 + 0.01497616165031102661476978j)\n    >>> chop(appellf2(1,1+j,1-j,3j,-3j,0.25,0.25))\n    1.201311219287411337955192\n    >>> appellf2(1,1,1,4,6,0.125,16)\n    (-0.09455532250274744282125152 - 0.7647282253046207836769297j)\n\nA transformation formula::\n\n    >>> a,b1,b2,c1,c2,x,y = map(mpf, [1,2,0.5,0.25,1.625,-0.125,0.125])\n    >>> appellf2(a,b1,b2,c1,c2,x,y)\n    0.2299211717841180783309688\n    >>> (1-x)**(-a)*appellf2(a,c1-b1,b2,c1,c2,x/(x-1),y/(1-x))\n    0.2299211717841180783309688\n\nA system of partial differential equations satisfied by F2::\n\n    >>> a,b1,b2,c1,c2,x,y = map(mpf, [1,0.5,0.25,1.125,1.5,0.0625,-0.0625])\n    >>> F = lambda x,y: appellf2(a,b1,b2,c1,c2,x,y)\n    >>> chop(x*(1-x)*diff(F,(x,y),(2,0)) -\n    ...      x*y*diff(F,(x,y),(1,1)) +\n    ...      (c1-(a+b1+1)*x)*diff(F,(x,y),(1,0)) -\n    ...      b1*y*diff(F,(x,y),(0,1)) -\n    ...      a*b1*F(x,y))\n    0.0\n    >>> chop(y*(1-y)*diff(F,(x,y),(0,2)) -\n    ...      x*y*diff(F,(x,y),(1,1)) +\n    ...      (c2-(a+b2+1)*y)*diff(F,(x,y),(0,1)) -\n    ...      b2*x*diff(F,(x,y),(1,0)) -\n    ...      a*b2*F(x,y))\n    0.0\n\n**References**\n\nSee references for :func:`~mpmath.appellf1`.\n'
appellf3: str = '\nGives the Appell F3 hypergeometric function of two variables\n\n.. math ::\n\n    F_3(a_1,a_2,b_1,b_2,c,x,y) = \\sum_{m=0}^{\\infty} \\sum_{n=0}^{\\infty}\n        \\frac{(a_1)_m (a_2)_n (b_1)_m (b_2)_n}{(c)_{m+n}}\n        \\frac{x^m y^n}{m! n!}.\n\nThe series is generally absolutely convergent for `|x| < 1, |y| < 1`.\n\n**Examples**\n\nEvaluation for various parameters and variables::\n\n    >>> from mpmath import *\n    >>> mp.dps = 25; mp.pretty = True\n    >>> appellf3(1,2,3,4,5,0.5,0.25)\n    2.221557778107438938158705\n    >>> appellf3(1,2,3,4,5,6,0); hyp2f1(1,3,5,6)\n    (-0.5189554589089861284537389 - 0.1454441043328607980769742j)\n    (-0.5189554589089861284537389 - 0.1454441043328607980769742j)\n    >>> appellf3(1,-2,-3,1,1,4,6)\n    -17.4\n    >>> appellf3(1,2,-3,1,1,4,6)\n    (17.7876136773677356641825 + 19.54768762233649126154534j)\n    >>> appellf3(1,2,-3,1,1,6,4)\n    (85.02054175067929402953645 + 148.4402528821177305173599j)\n    >>> chop(appellf3(1+j,2,1-j,2,3,0.25,0.25))\n    1.719992169545200286696007\n\nMany transformations and evaluations for special combinations\nof the parameters are possible, e.g.:\n\n    >>> a,b,c,x,y = map(mpf, [0.5,0.25,0.125,0.125,-0.125])\n    >>> appellf3(a,c-a,b,c-b,c,x,y)\n    1.093432340896087107444363\n    >>> (1-y)**(a+b-c)*hyp2f1(a,b,c,x+y-x*y)\n    1.093432340896087107444363\n    >>> x**2*appellf3(1,1,1,1,3,x,-x)\n    0.01568646277445385390945083\n    >>> polylog(2,x**2)\n    0.01568646277445385390945083\n    >>> a1,a2,b1,b2,c,x = map(mpf, [0.5,0.25,0.125,0.5,4.25,0.125])\n    >>> appellf3(a1,a2,b1,b2,c,x,1)\n    1.03947361709111140096947\n    >>> gammaprod([c,c-a2-b2],[c-a2,c-b2])*hyp3f2(a1,b1,c-a2-b2,c-a2,c-b2,x)\n    1.03947361709111140096947\n\nThe Appell F3 function satisfies a pair of partial\ndifferential equations::\n\n    >>> a1,a2,b1,b2,c,x,y = map(mpf, [0.5,0.25,0.125,0.5,0.625,0.0625,-0.0625])\n    >>> F = lambda x,y: appellf3(a1,a2,b1,b2,c,x,y)\n    >>> chop(x*(1-x)*diff(F,(x,y),(2,0)) +\n    ...      y*diff(F,(x,y),(1,1)) +\n    ...     (c-(a1+b1+1)*x)*diff(F,(x,y),(1,0)) -\n    ...     a1*b1*F(x,y))\n    0.0\n    >>> chop(y*(1-y)*diff(F,(x,y),(0,2)) +\n    ...     x*diff(F,(x,y),(1,1)) +\n    ...     (c-(a2+b2+1)*y)*diff(F,(x,y),(0,1)) -\n    ...     a2*b2*F(x,y))\n    0.0\n\n**References**\n\nSee references for :func:`~mpmath.appellf1`.\n'
appellf4: str = '\nGives the Appell F4 hypergeometric function of two variables\n\n.. math ::\n\n    F_4(a,b,c_1,c_2,x,y) = \\sum_{m=0}^{\\infty} \\sum_{n=0}^{\\infty}\n        \\frac{(a)_{m+n} (b)_{m+n}}{(c_1)_m (c_2)_n}\n        \\frac{x^m y^n}{m! n!}.\n\nThe series is generally absolutely convergent for\n`\\sqrt{|x|} + \\sqrt{|y|} < 1`.\n\n**Examples**\n\nEvaluation for various parameters and arguments::\n\n    >>> from mpmath import *\n    >>> mp.dps = 25; mp.pretty = True\n    >>> appellf4(1,1,2,2,0.25,0.125)\n    1.286182069079718313546608\n    >>> appellf4(-2,-3,4,5,4,5)\n    34.8\n    >>> appellf4(5,4,2,3,0.25j,-0.125j)\n    (-0.2585967215437846642163352 + 2.436102233553582711818743j)\n\nReduction to `\\,_2F_1` in a special case::\n\n    >>> a,b,c,x,y = map(mpf, [0.5,0.25,0.125,0.125,-0.125])\n    >>> appellf4(a,b,c,a+b-c+1,x*(1-y),y*(1-x))\n    1.129143488466850868248364\n    >>> hyp2f1(a,b,c,x)*hyp2f1(a,b,a+b-c+1,y)\n    1.129143488466850868248364\n\nA system of partial differential equations satisfied by F4::\n\n    >>> a,b,c1,c2,x,y = map(mpf, [1,0.5,0.25,1.125,0.0625,-0.0625])\n    >>> F = lambda x,y: appellf4(a,b,c1,c2,x,y)\n    >>> chop(x*(1-x)*diff(F,(x,y),(2,0)) -\n    ...      y**2*diff(F,(x,y),(0,2)) -\n    ...      2*x*y*diff(F,(x,y),(1,1)) +\n    ...      (c1-(a+b+1)*x)*diff(F,(x,y),(1,0)) -\n    ...      ((a+b+1)*y)*diff(F,(x,y),(0,1)) -\n    ...      a*b*F(x,y))\n    0.0\n    >>> chop(y*(1-y)*diff(F,(x,y),(0,2)) -\n    ...      x**2*diff(F,(x,y),(2,0)) -\n    ...      2*x*y*diff(F,(x,y),(1,1)) +\n    ...      (c2-(a+b+1)*y)*diff(F,(x,y),(0,1)) -\n    ...      ((a+b+1)*x)*diff(F,(x,y),(1,0)) -\n    ...      a*b*F(x,y))\n    0.0\n\n**References**\n\nSee references for :func:`~mpmath.appellf1`.\n'
arg: str = '\nComputes the complex argument (phase) of `x`, defined as the\nsigned angle between the positive real axis and `x` in the\ncomplex plane::\n\n    >>> from mpmath import *\n    >>> mp.dps = 15; mp.pretty = True\n    >>> arg(3)\n    0.0\n    >>> arg(3+3j)\n    0.785398163397448\n    >>> arg(3j)\n    1.5707963267949\n    >>> arg(-3)\n    3.14159265358979\n    >>> arg(-3j)\n    -1.5707963267949\n\nThe angle is defined to satisfy `-\\pi < \\arg(x) \\le \\pi` and\nwith the sign convention that a nonnegative imaginary part\nresults in a nonnegative argument.\n\nThe value returned by :func:`~mpmath.arg` is an ``mpf`` instance.\n'
asec: str = 'Computes the inverse secant of `x`,\n`\\mathrm{sec}^{-1}(x) = \\cos^{-1}(1/x)`.'
asech: str = 'Computes the inverse hyperbolic secant of `x`,\n`\\mathrm{sech}^{-1}(x) = \\cosh^{-1}(1/x)`.'
asin: str = '\nComputes the inverse sine or arcsine of `x`, `\\sin^{-1}(x)`.\nSince `-1 \\le \\sin(x) \\le 1` for real `x`, the inverse\nsine is real-valued only for `-1 \\le x \\le 1`.\nOn this interval, it is defined to be a monotonically increasing\nfunction assuming values between `-\\pi/2` and `\\pi/2`.\n\nBasic values are::\n\n    >>> from mpmath import *\n    >>> mp.dps = 25; mp.pretty = True\n    >>> asin(-1)\n    -1.570796326794896619231322\n    >>> asin(0)\n    0.0\n    >>> asin(1)\n    1.570796326794896619231322\n    >>> nprint(chop(taylor(asin, 0, 6)))\n    [0.0, 1.0, 0.0, 0.166667, 0.0, 0.075, 0.0]\n\n:func:`~mpmath.asin` is defined so as to be a proper inverse function of\n`\\sin(\\theta)` for `-\\pi/2 < \\theta < \\pi/2`.\nWe have `\\sin(\\sin^{-1}(x)) = x` for all `x`, but\n`\\sin^{-1}(\\sin(x)) = x` only for `-\\pi/2 < \\Re[x] < \\pi/2`::\n\n    >>> for x in [1, 10, -1, 1+3j, -2+3j]:\n    ...     print("%s %s" % (chop(sin(asin(x))), asin(sin(x))))\n    ...\n    1.0 1.0\n    10.0 -0.5752220392306202846120698\n    -1.0 -1.0\n    (1.0 + 3.0j) (1.0 + 3.0j)\n    (-2.0 + 3.0j) (-1.141592653589793238462643 - 3.0j)\n\nThe inverse sine has two branch points: `x = \\pm 1`. :func:`~mpmath.asin`\nplaces the branch cuts along the line segments `(-\\infty, -1)` and\n`(+1, +\\infty)`. In general,\n\n.. math ::\n\n    \\sin^{-1}(x) = -i \\log\\left(ix + \\sqrt{1-x^2} \\right)\n\nwhere the principal-branch log and square root are implied.\n'
asinh: str = 'Computes the inverse hyperbolic sine of `x`,\n`\\mathrm{sinh}^{-1}(x) = \\log(x+\\sqrt{1+x^2})`.\n'
atan: str = '\nComputes the inverse tangent or arctangent of `x`, `\\tan^{-1}(x)`.\nThis is a real-valued function for all real `x`, with range\n`(-\\pi/2, \\pi/2)`.\n\nBasic values are::\n\n    >>> from mpmath import *\n    >>> mp.dps = 25; mp.pretty = True\n    >>> atan(-inf)\n    -1.570796326794896619231322\n    >>> atan(-1)\n    -0.7853981633974483096156609\n    >>> atan(0)\n    0.0\n    >>> atan(1)\n    0.7853981633974483096156609\n    >>> atan(inf)\n    1.570796326794896619231322\n    >>> nprint(chop(taylor(atan, 0, 6)))\n    [0.0, 1.0, 0.0, -0.333333, 0.0, 0.2, 0.0]\n\nThe inverse tangent is often used to compute angles. However,\nthe atan2 function is often better for this as it preserves sign\n(see :func:`~mpmath.atan2`).\n\n:func:`~mpmath.atan` is defined so as to be a proper inverse function of\n`\\tan(\\theta)` for `-\\pi/2 < \\theta < \\pi/2`.\nWe have `\\tan(\\tan^{-1}(x)) = x` for all `x`, but\n`\\tan^{-1}(\\tan(x)) = x` only for `-\\pi/2 < \\Re[x] < \\pi/2`::\n\n    >>> mp.dps = 25\n    >>> for x in [1, 10, -1, 1+3j, -2+3j]:\n    ...     print("%s %s" % (tan(atan(x)), atan(tan(x))))\n    ...\n    1.0 1.0\n    10.0 0.5752220392306202846120698\n    -1.0 -1.0\n    (1.0 + 3.0j) (1.000000000000000000000001 + 3.0j)\n    (-2.0 + 3.0j) (1.141592653589793238462644 + 3.0j)\n\nThe inverse tangent has two branch points: `x = \\pm i`. :func:`~mpmath.atan`\nplaces the branch cuts along the line segments `(-i \\infty, -i)` and\n`(+i, +i \\infty)`. In general,\n\n.. math ::\n\n    \\tan^{-1}(x) = \\frac{i}{2}\\left(\\log(1-ix)-\\log(1+ix)\\right)\n\nwhere the principal-branch log is implied.\n'
atan2: str = '\nComputes the two-argument arctangent, `\\mathrm{atan2}(y, x)`,\ngiving the signed angle between the positive `x`-axis and the\npoint `(x, y)` in the 2D plane. This function is defined for\nreal `x` and `y` only.\n\nThe two-argument arctangent essentially computes\n`\\mathrm{atan}(y/x)`, but accounts for the signs of both\n`x` and `y` to give the angle for the correct quadrant. The\nfollowing examples illustrate the difference::\n\n    >>> from mpmath import *\n    >>> mp.dps = 15; mp.pretty = True\n    >>> atan2(1,1), atan(1/1.)\n    (0.785398163397448, 0.785398163397448)\n    >>> atan2(1,-1), atan(1/-1.)\n    (2.35619449019234, -0.785398163397448)\n    >>> atan2(-1,1), atan(-1/1.)\n    (-0.785398163397448, -0.785398163397448)\n    >>> atan2(-1,-1), atan(-1/-1.)\n    (-2.35619449019234, 0.785398163397448)\n\nThe angle convention is the same as that used for the complex\nargument; see :func:`~mpmath.arg`.\n'
atanh: str = 'Computes the inverse hyperbolic tangent of `x`,\n`\\mathrm{tanh}^{-1}(x) = \\frac{1}{2}\\left(\\log(1+x)-\\log(1-x)\\right)`.\n'
barnesg: str = "\nEvaluates the Barnes G-function, which generalizes the\nsuperfactorial (:func:`~mpmath.superfac`) and by extension also the\nhyperfactorial (:func:`~mpmath.hyperfac`) to the complex numbers\nin an analogous way to how the gamma function generalizes\nthe ordinary factorial.\n\nThe Barnes G-function may be defined in terms of a Weierstrass\nproduct:\n\n.. math ::\n\n    G(z+1) = (2\\pi)^{z/2} e^{-[z(z+1)+\\gamma z^2]/2}\n    \\prod_{n=1}^\\infty\n    \\left[\\left(1+\\frac{z}{n}\\right)^ne^{-z+z^2/(2n)}\\right]\n\nFor positive integers `n`, we have have relation to superfactorials\n`G(n) = \\mathrm{sf}(n-2) = 0! \\cdot 1! \\cdots (n-2)!`.\n\n**Examples**\n\nSome elementary values and limits of the Barnes G-function::\n\n    >>> from mpmath import *\n    >>> mp.dps = 15; mp.pretty = True\n    >>> barnesg(1), barnesg(2), barnesg(3)\n    (1.0, 1.0, 1.0)\n    >>> barnesg(4)\n    2.0\n    >>> barnesg(5)\n    12.0\n    >>> barnesg(6)\n    288.0\n    >>> barnesg(7)\n    34560.0\n    >>> barnesg(8)\n    24883200.0\n    >>> barnesg(inf)\n    +inf\n    >>> barnesg(0), barnesg(-1), barnesg(-2)\n    (0.0, 0.0, 0.0)\n\nClosed-form values are known for some rational arguments::\n\n    >>> barnesg('1/2')\n    0.603244281209446\n    >>> sqrt(exp(0.25+log(2)/12)/sqrt(pi)/glaisher**3)\n    0.603244281209446\n    >>> barnesg('1/4')\n    0.29375596533861\n    >>> nthroot(exp('3/8')/exp(catalan/pi)/\n    ...      gamma(0.25)**3/sqrt(glaisher)**9, 4)\n    0.29375596533861\n\nThe Barnes G-function satisfies the functional equation\n`G(z+1) = \\Gamma(z) G(z)`::\n\n    >>> z = pi\n    >>> barnesg(z+1)\n    2.39292119327948\n    >>> gamma(z)*barnesg(z)\n    2.39292119327948\n\nThe asymptotic growth rate of the Barnes G-function is related to\nthe Glaisher-Kinkelin constant::\n\n    >>> limit(lambda n: barnesg(n+1)/(n**(n**2/2-mpf(1)/12)*\n    ...     (2*pi)**(n/2)*exp(-3*n**2/4)), inf)\n    0.847536694177301\n    >>> exp('1/12')/glaisher\n    0.847536694177301\n\nThe Barnes G-function can be differentiated in closed form::\n\n    >>> z = 3\n    >>> diff(barnesg, z)\n    0.264507203401607\n    >>> barnesg(z)*((z-1)*psi(0,z)-z+(log(2*pi)+1)/2)\n    0.264507203401607\n\nEvaluation is supported for arbitrary arguments and at arbitrary\nprecision::\n\n    >>> barnesg(6.5)\n    2548.7457695685\n    >>> barnesg(-pi)\n    0.00535976768353037\n    >>> barnesg(3+4j)\n    (-0.000676375932234244 - 4.42236140124728e-5j)\n    >>> mp.dps = 50\n    >>> barnesg(1/sqrt(2))\n    0.81305501090451340843586085064413533788206204124732\n    >>> q = barnesg(10j)\n    >>> q.real\n    0.000000000021852360840356557241543036724799812371995850552234\n    >>> q.imag\n    -0.00000000000070035335320062304849020654215545839053210041457588\n    >>> mp.dps = 15\n    >>> barnesg(100)\n    3.10361006263698e+6626\n    >>> barnesg(-101)\n    0.0\n    >>> barnesg(-10.5)\n    5.94463017605008e+25\n    >>> barnesg(-10000.5)\n    -6.14322868174828e+167480422\n    >>> barnesg(1000j)\n    (5.21133054865546e-1173597 + 4.27461836811016e-1173597j)\n    >>> barnesg(-1000+1000j)\n    (2.43114569750291e+1026623 + 2.24851410674842e+1026623j)\n\n\n**References**\n\n1. Whittaker & Watson, *A Course of Modern Analysis*,\n   Cambridge University Press, 4th edition (1927), p.264\n2. http://en.wikipedia.org/wiki/Barnes_G-function\n3. http://mathworld.wolfram.com/BarnesG-Function.html\n\n"
bei: str = '\nComputes the Kelvin function bei, which for real arguments gives the\nimaginary part of the Bessel J function of a rotated argument.\nSee :func:`~mpmath.ber`.\n'
bell: str = "\nFor `n` a nonnegative integer, ``bell(n,x)`` evaluates the Bell\npolynomial `B_n(x)`, the first few of which are\n\n.. math ::\n\n    B_0(x) = 1\n\n    B_1(x) = x\n\n    B_2(x) = x^2+x\n\n    B_3(x) = x^3+3x^2+x\n\nIf `x = 1` or :func:`~mpmath.bell` is called with only one argument, it\ngives the `n`-th Bell number `B_n`, which is the number of\npartitions of a set with `n` elements. By setting the precision to\nat least `\\log_{10} B_n` digits, :func:`~mpmath.bell` provides fast\ncalculation of exact Bell numbers.\n\nIn general, :func:`~mpmath.bell` computes\n\n.. math ::\n\n    B_n(x) = e^{-x} \\left(\\mathrm{sinc}(\\pi n) + E_n(x)\\right)\n\nwhere `E_n(x)` is the generalized exponential function implemented\nby :func:`~mpmath.polyexp`. This is an extension of Dobinski's formula [1],\nwhere the modification is the sinc term ensuring that `B_n(x)` is\ncontinuous in `n`; :func:`~mpmath.bell` can thus be evaluated,\ndifferentiated, etc for arbitrary complex arguments.\n\n**Examples**\n\nSimple evaluations::\n\n    >>> from mpmath import *\n    >>> mp.dps = 25; mp.pretty = True\n    >>> bell(0, 2.5)\n    1.0\n    >>> bell(1, 2.5)\n    2.5\n    >>> bell(2, 2.5)\n    8.75\n\nEvaluation for arbitrary complex arguments::\n\n    >>> bell(5.75+1j, 2-3j)\n    (-10767.71345136587098445143 - 15449.55065599872579097221j)\n\nThe first few Bell polynomials::\n\n    >>> for k in range(7):\n    ...     nprint(taylor(lambda x: bell(k,x), 0, k))\n    ...\n    [1.0]\n    [0.0, 1.0]\n    [0.0, 1.0, 1.0]\n    [0.0, 1.0, 3.0, 1.0]\n    [0.0, 1.0, 7.0, 6.0, 1.0]\n    [0.0, 1.0, 15.0, 25.0, 10.0, 1.0]\n    [0.0, 1.0, 31.0, 90.0, 65.0, 15.0, 1.0]\n\nThe first few Bell numbers and complementary Bell numbers::\n\n    >>> [int(bell(k)) for k in range(10)]\n    [1, 1, 2, 5, 15, 52, 203, 877, 4140, 21147]\n    >>> [int(bell(k,-1)) for k in range(10)]\n    [1, -1, 0, 1, 1, -2, -9, -9, 50, 267]\n\nLarge Bell numbers::\n\n    >>> mp.dps = 50\n    >>> bell(50)\n    185724268771078270438257767181908917499221852770.0\n    >>> bell(50,-1)\n    -29113173035759403920216141265491160286912.0\n\nSome even larger values::\n\n    >>> mp.dps = 25\n    >>> bell(1000,-1)\n    -1.237132026969293954162816e+1869\n    >>> bell(1000)\n    2.989901335682408421480422e+1927\n    >>> bell(1000,2)\n    6.591553486811969380442171e+1987\n    >>> bell(1000,100.5)\n    9.101014101401543575679639e+2529\n\nA determinant identity satisfied by Bell numbers::\n\n    >>> mp.dps = 15\n    >>> N = 8\n    >>> det([[bell(k+j) for j in range(N)] for k in range(N)])\n    125411328000.0\n    >>> superfac(N-1)\n    125411328000.0\n\n**References**\n\n1. http://mathworld.wolfram.com/DobinskisFormula.html\n\n"
ber: str = '\nComputes the Kelvin function ber, which for real arguments gives the real part\nof the Bessel J function of a rotated argument\n\n.. math ::\n\n    J_n\\left(x e^{3\\pi i/4}\\right) = \\mathrm{ber}_n(x) + i \\mathrm{bei}_n(x).\n\nThe imaginary part is given by :func:`~mpmath.bei`.\n\n**Plots**\n\n.. literalinclude :: /plots/ber.py\n.. image :: /plots/ber.png\n\n**Examples**\n\nVerifying the defining relation::\n\n    >>> from mpmath import *\n    >>> mp.dps = 25; mp.pretty = True\n    >>> n, x = 2, 3.5\n    >>> ber(n,x)\n    1.442338852571888752631129\n    >>> bei(n,x)\n    -0.948359035324558320217678\n    >>> besselj(n, x*root(1,8,3))\n    (1.442338852571888752631129 - 0.948359035324558320217678j)\n\nThe ber and bei functions are also defined by analytic continuation\nfor complex arguments::\n\n    >>> ber(1+j, 2+3j)\n    (4.675445984756614424069563 - 15.84901771719130765656316j)\n    >>> bei(1+j, 2+3j)\n    (15.83886679193707699364398 + 4.684053288183046528703611j)\n\n'
bernoulli: str = '\nComputes the nth Bernoulli number, `B_n`, for any integer `n \\ge 0`.\n\nThe Bernoulli numbers are rational numbers, but this function\nreturns a floating-point approximation. To obtain an exact\nfraction, use :func:`~mpmath.bernfrac` instead.\n\n**Examples**\n\nNumerical values of the first few Bernoulli numbers::\n\n    >>> from mpmath import *\n    >>> mp.dps = 15; mp.pretty = True\n    >>> for n in range(15):\n    ...     print("%s %s" % (n, bernoulli(n)))\n    ...\n    0 1.0\n    1 -0.5\n    2 0.166666666666667\n    3 0.0\n    4 -0.0333333333333333\n    5 0.0\n    6 0.0238095238095238\n    7 0.0\n    8 -0.0333333333333333\n    9 0.0\n    10 0.0757575757575758\n    11 0.0\n    12 -0.253113553113553\n    13 0.0\n    14 1.16666666666667\n\nBernoulli numbers can be approximated with arbitrary precision::\n\n    >>> mp.dps = 50\n    >>> bernoulli(100)\n    -2.8382249570693706959264156336481764738284680928013e+78\n\nArbitrarily large `n` are supported::\n\n    >>> mp.dps = 15\n    >>> bernoulli(10**20 + 2)\n    3.09136296657021e+1876752564973863312327\n\nThe Bernoulli numbers are related to the Riemann zeta function\nat integer arguments::\n\n    >>> -bernoulli(8) * (2*pi)**8 / (2*fac(8))\n    1.00407735619794\n    >>> zeta(8)\n    1.00407735619794\n\n**Algorithm**\n\nFor small `n` (`n < 3000`) :func:`~mpmath.bernoulli` uses a recurrence\nformula due to Ramanujan. All results in this range are cached,\nso sequential computation of small Bernoulli numbers is\nguaranteed to be fast.\n\nFor larger `n`, `B_n` is evaluated in terms of the Riemann zeta\nfunction.\n'
bernpoly: str = '\nEvaluates the Bernoulli polynomial `B_n(z)`.\n\nThe first few Bernoulli polynomials are::\n\n    >>> from mpmath import *\n    >>> mp.dps = 15; mp.pretty = True\n    >>> for n in range(6):\n    ...     nprint(chop(taylor(lambda x: bernpoly(n,x), 0, n)))\n    ...\n    [1.0]\n    [-0.5, 1.0]\n    [0.166667, -1.0, 1.0]\n    [0.0, 0.5, -1.5, 1.0]\n    [-0.0333333, 0.0, 1.0, -2.0, 1.0]\n    [0.0, -0.166667, 0.0, 1.66667, -2.5, 1.0]\n\nAt `z = 0`, the Bernoulli polynomial evaluates to a\nBernoulli number (see :func:`~mpmath.bernoulli`)::\n\n    >>> bernpoly(12, 0), bernoulli(12)\n    (-0.253113553113553, -0.253113553113553)\n    >>> bernpoly(13, 0), bernoulli(13)\n    (0.0, 0.0)\n\nEvaluation is accurate for large `n` and small `z`::\n\n    >>> mp.dps = 25\n    >>> bernpoly(100, 0.5)\n    2.838224957069370695926416e+78\n    >>> bernpoly(1000, 10.5)\n    5.318704469415522036482914e+1769\n\n'
besseli: str = '\n``besseli(n, x, derivative=0)`` gives the modified Bessel function of the\nfirst kind,\n\n.. math ::\n\n    I_n(x) = i^{-n} J_n(ix).\n\nWith *derivative* = `m \\ne 0`, the `m`-th derivative\n\n.. math ::\n\n    \\frac{d^m}{dx^m} I_n(x)\n\nis computed.\n\n**Plots**\n\n.. literalinclude :: /plots/besseli.py\n.. image :: /plots/besseli.png\n.. literalinclude :: /plots/besseli_c.py\n.. image :: /plots/besseli_c.png\n\n**Examples**\n\nSome values of `I_n(x)`::\n\n    >>> from mpmath import *\n    >>> mp.dps = 25; mp.pretty = True\n    >>> besseli(0,0)\n    1.0\n    >>> besseli(1,0)\n    0.0\n    >>> besseli(0,1)\n    1.266065877752008335598245\n    >>> besseli(3.5, 2+3j)\n    (-0.2904369752642538144289025 - 0.4469098397654815837307006j)\n\nArguments may be large::\n\n    >>> besseli(2, 1000)\n    2.480717210191852440616782e+432\n    >>> besseli(2, 10**10)\n    4.299602851624027900335391e+4342944813\n    >>> besseli(2, 6000+10000j)\n    (-2.114650753239580827144204e+2603 + 4.385040221241629041351886e+2602j)\n\nFor integers `n`, the following integral representation holds::\n\n    >>> mp.dps = 15\n    >>> n = 3\n    >>> x = 2.3\n    >>> quad(lambda t: exp(x*cos(t))*cos(n*t), [0,pi])/pi\n    0.349223221159309\n    >>> besseli(n,x)\n    0.349223221159309\n\nDerivatives and antiderivatives of any order can be computed::\n\n    >>> mp.dps = 25\n    >>> besseli(2, 7.5, 1)\n    195.8229038931399062565883\n    >>> diff(lambda x: besseli(2,x), 7.5)\n    195.8229038931399062565883\n    >>> besseli(2, 7.5, 10)\n    153.3296508971734525525176\n    >>> diff(lambda x: besseli(2,x), 7.5, 10)\n    153.3296508971734525525176\n    >>> besseli(2,7.5,-1) - besseli(2,3.5,-1)\n    202.5043900051930141956876\n    >>> quad(lambda x: besseli(2,x), [3.5, 7.5])\n    202.5043900051930141956876\n\n'
besselj: str = "\n``besselj(n, x, derivative=0)`` gives the Bessel function of the first kind\n`J_n(x)`. Bessel functions of the first kind are defined as\nsolutions of the differential equation\n\n.. math ::\n\n    x^2 y'' + x y' + (x^2 - n^2) y = 0\n\nwhich appears, among other things, when solving the radial\npart of Laplace's equation in cylindrical coordinates. This\nequation has two solutions for given `n`, where the\n`J_n`-function is the solution that is nonsingular at `x = 0`.\nFor positive integer `n`, `J_n(x)` behaves roughly like a sine\n(odd `n`) or cosine (even `n`) multiplied by a magnitude factor\nthat decays slowly as `x \\to \\pm\\infty`.\n\nGenerally, `J_n` is a special case of the hypergeometric\nfunction `\\,_0F_1`:\n\n.. math ::\n\n    J_n(x) = \\frac{x^n}{2^n \\Gamma(n+1)}\n             \\,_0F_1\\left(n+1,-\\frac{x^2}{4}\\right)\n\nWith *derivative* = `m \\ne 0`, the `m`-th derivative\n\n.. math ::\n\n    \\frac{d^m}{dx^m} J_n(x)\n\nis computed.\n\n**Plots**\n\n.. literalinclude :: /plots/besselj.py\n.. image :: /plots/besselj.png\n.. literalinclude :: /plots/besselj_c.py\n.. image :: /plots/besselj_c.png\n\n**Examples**\n\nEvaluation is supported for arbitrary arguments, and at\narbitrary precision::\n\n    >>> from mpmath import *\n    >>> mp.dps = 15; mp.pretty = True\n    >>> besselj(2, 1000)\n    -0.024777229528606\n    >>> besselj(4, 0.75)\n    0.000801070086542314\n    >>> besselj(2, 1000j)\n    (-2.48071721019185e+432 + 6.41567059811949e-437j)\n    >>> mp.dps = 25\n    >>> besselj(0.75j, 3+4j)\n    (-2.778118364828153309919653 - 1.5863603889018621585533j)\n    >>> mp.dps = 50\n    >>> besselj(1, pi)\n    0.28461534317975275734531059968613140570981118184947\n\nArguments may be large::\n\n    >>> mp.dps = 25\n    >>> besselj(0, 10000)\n    -0.007096160353388801477265164\n    >>> besselj(0, 10**10)\n    0.000002175591750246891726859055\n    >>> besselj(2, 10**100)\n    7.337048736538615712436929e-51\n    >>> besselj(2, 10**5*j)\n    (-3.540725411970948860173735e+43426 + 4.4949812409615803110051e-43433j)\n\nThe Bessel functions of the first kind satisfy simple\nsymmetries around `x = 0`::\n\n    >>> mp.dps = 15\n    >>> nprint([besselj(n,0) for n in range(5)])\n    [1.0, 0.0, 0.0, 0.0, 0.0]\n    >>> nprint([besselj(n,pi) for n in range(5)])\n    [-0.304242, 0.284615, 0.485434, 0.333458, 0.151425]\n    >>> nprint([besselj(n,-pi) for n in range(5)])\n    [-0.304242, -0.284615, 0.485434, -0.333458, 0.151425]\n\nRoots of Bessel functions are often used::\n\n    >>> nprint([findroot(j0, k) for k in [2, 5, 8, 11, 14]])\n    [2.40483, 5.52008, 8.65373, 11.7915, 14.9309]\n    >>> nprint([findroot(j1, k) for k in [3, 7, 10, 13, 16]])\n    [3.83171, 7.01559, 10.1735, 13.3237, 16.4706]\n\nThe roots are not periodic, but the distance between successive\nroots asymptotically approaches `2 \\pi`. Bessel functions of\nthe first kind have the following normalization::\n\n    >>> quadosc(j0, [0, inf], period=2*pi)\n    1.0\n    >>> quadosc(j1, [0, inf], period=2*pi)\n    1.0\n\nFor `n = 1/2` or `n = -1/2`, the Bessel function reduces to a\ntrigonometric function::\n\n    >>> x = 10\n    >>> besselj(0.5, x), sqrt(2/(pi*x))*sin(x)\n    (-0.13726373575505, -0.13726373575505)\n    >>> besselj(-0.5, x), sqrt(2/(pi*x))*cos(x)\n    (-0.211708866331398, -0.211708866331398)\n\nDerivatives of any order can be computed (negative orders\ncorrespond to integration)::\n\n    >>> mp.dps = 25\n    >>> besselj(0, 7.5, 1)\n    -0.1352484275797055051822405\n    >>> diff(lambda x: besselj(0,x), 7.5)\n    -0.1352484275797055051822405\n    >>> besselj(0, 7.5, 10)\n    -0.1377811164763244890135677\n    >>> diff(lambda x: besselj(0,x), 7.5, 10)\n    -0.1377811164763244890135677\n    >>> besselj(0,7.5,-1) - besselj(0,3.5,-1)\n    -0.1241343240399987693521378\n    >>> quad(j0, [3.5, 7.5])\n    -0.1241343240399987693521378\n\nDifferentiation with a noninteger order gives the fractional derivative\nin the sense of the Riemann-Liouville differintegral, as computed by\n:func:`~mpmath.differint`::\n\n    >>> mp.dps = 15\n    >>> besselj(1, 3.5, 0.75)\n    -0.385977722939384\n    >>> differint(lambda x: besselj(1, x), 3.5, 0.75)\n    -0.385977722939384\n\n"
besselk: str = "\n``besselk(n, x)`` gives the modified Bessel function of the\nsecond kind,\n\n.. math ::\n\n    K_n(x) = \\frac{\\pi}{2} \\frac{I_{-n}(x)-I_{n}(x)}{\\sin(\\pi n)}\n\nFor `n` an integer, this formula should be understood as a\nlimit.\n\n**Plots**\n\n.. literalinclude :: /plots/besselk.py\n.. image :: /plots/besselk.png\n.. literalinclude :: /plots/besselk_c.py\n.. image :: /plots/besselk_c.png\n\n**Examples**\n\nEvaluation is supported for arbitrary complex arguments::\n\n    >>> from mpmath import *\n    >>> mp.dps = 25; mp.pretty = True\n    >>> besselk(0,1)\n    0.4210244382407083333356274\n    >>> besselk(0, -1)\n    (0.4210244382407083333356274 - 3.97746326050642263725661j)\n    >>> besselk(3.5, 2+3j)\n    (-0.02090732889633760668464128 + 0.2464022641351420167819697j)\n    >>> besselk(2+3j, 0.5)\n    (0.9615816021726349402626083 + 0.1918250181801757416908224j)\n\nArguments may be large::\n\n    >>> besselk(0, 100)\n    4.656628229175902018939005e-45\n    >>> besselk(1, 10**6)\n    4.131967049321725588398296e-434298\n    >>> besselk(1, 10**6*j)\n    (0.001140348428252385844876706 - 0.0005200017201681152909000961j)\n    >>> besselk(4.5, fmul(10**50, j, exact=True))\n    (1.561034538142413947789221e-26 + 1.243554598118700063281496e-25j)\n\nThe point `x = 0` is a singularity (logarithmic if `n = 0`)::\n\n    >>> besselk(0,0)\n    +inf\n    >>> besselk(1,0)\n    +inf\n    >>> for n in range(-4, 5):\n    ...     print(besselk(n, '1e-1000'))\n    ...\n    4.8e+4001\n    8.0e+3000\n    2.0e+2000\n    1.0e+1000\n    2302.701024509704096466802\n    1.0e+1000\n    2.0e+2000\n    8.0e+3000\n    4.8e+4001\n\n"
bessely: str = '\n``bessely(n, x, derivative=0)`` gives the Bessel function of the second kind,\n\n.. math ::\n\n    Y_n(x) = \\frac{J_n(x) \\cos(\\pi n) - J_{-n}(x)}{\\sin(\\pi n)}.\n\nFor `n` an integer, this formula should be understood as a\nlimit. With *derivative* = `m \\ne 0`, the `m`-th derivative\n\n.. math ::\n\n    \\frac{d^m}{dx^m} Y_n(x)\n\nis computed.\n\n**Plots**\n\n.. literalinclude :: /plots/bessely.py\n.. image :: /plots/bessely.png\n.. literalinclude :: /plots/bessely_c.py\n.. image :: /plots/bessely_c.png\n\n**Examples**\n\nSome values of `Y_n(x)`::\n\n    >>> from mpmath import *\n    >>> mp.dps = 25; mp.pretty = True\n    >>> bessely(0,0), bessely(1,0), bessely(2,0)\n    (-inf, -inf, -inf)\n    >>> bessely(1, pi)\n    0.3588729167767189594679827\n    >>> bessely(0.5, 3+4j)\n    (9.242861436961450520325216 - 3.085042824915332562522402j)\n\nArguments may be large::\n\n    >>> bessely(0, 10000)\n    0.00364780555898660588668872\n    >>> bessely(2.5, 10**50)\n    -4.8952500412050989295774e-26\n    >>> bessely(2.5, -10**50)\n    (0.0 + 4.8952500412050989295774e-26j)\n\nDerivatives and antiderivatives of any order can be computed::\n\n    >>> bessely(2, 3.5, 1)\n    0.3842618820422660066089231\n    >>> diff(lambda x: bessely(2, x), 3.5)\n    0.3842618820422660066089231\n    >>> bessely(0.5, 3.5, 1)\n    -0.2066598304156764337900417\n    >>> diff(lambda x: bessely(0.5, x), 3.5)\n    -0.2066598304156764337900417\n    >>> diff(lambda x: bessely(2, x), 0.5, 10)\n    -208173867409.5547350101511\n    >>> bessely(2, 0.5, 10)\n    -208173867409.5547350101511\n    >>> bessely(2, 100.5, 100)\n    0.02668487547301372334849043\n    >>> quad(lambda x: bessely(2,x), [1,3])\n    -1.377046859093181969213262\n    >>> bessely(2,3,-1) - bessely(2,1,-1)\n    -1.377046859093181969213262\n\n'
beta: str = '\nComputes the beta function,\n`B(x,y) = \\Gamma(x) \\Gamma(y) / \\Gamma(x+y)`.\nThe beta function is also commonly defined by the integral\nrepresentation\n\n.. math ::\n\n    B(x,y) = \\int_0^1 t^{x-1} (1-t)^{y-1} \\, dt\n\n**Examples**\n\nFor integer and half-integer arguments where all three gamma\nfunctions are finite, the beta function becomes either rational\nnumber or a rational multiple of `\\pi`::\n\n    >>> from mpmath import *\n    >>> mp.dps = 15; mp.pretty = True\n    >>> beta(5, 2)\n    0.0333333333333333\n    >>> beta(1.5, 2)\n    0.266666666666667\n    >>> 16*beta(2.5, 1.5)\n    3.14159265358979\n\nWhere appropriate, :func:`~mpmath.beta` evaluates limits. A pole\nof the beta function is taken to result in ``+inf``::\n\n    >>> beta(-0.5, 0.5)\n    0.0\n    >>> beta(-3, 3)\n    -0.333333333333333\n    >>> beta(-2, 3)\n    +inf\n    >>> beta(inf, 1)\n    0.0\n    >>> beta(inf, 0)\n    nan\n\n:func:`~mpmath.beta` supports complex numbers and arbitrary precision\nevaluation::\n\n    >>> beta(1, 2+j)\n    (0.4 - 0.2j)\n    >>> mp.dps = 25\n    >>> beta(j,0.5)\n    (1.079424249270925780135675 - 1.410032405664160838288752j)\n    >>> mp.dps = 50\n    >>> beta(pi, e)\n    0.037890298781212201348153837138927165984170287886464\n\nVarious integrals can be computed by means of the\nbeta function::\n\n    >>> mp.dps = 15\n    >>> quad(lambda t: t**2.5*(1-t)**2, [0, 1])\n    0.0230880230880231\n    >>> beta(3.5, 3)\n    0.0230880230880231\n    >>> quad(lambda t: sin(t)**4 * sqrt(cos(t)), [0, pi/2])\n    0.319504062596158\n    >>> beta(2.5, 0.75)/2\n    0.319504062596158\n\n'
betainc: str = "\n``betainc(a, b, x1=0, x2=1, regularized=False)`` gives the generalized\nincomplete beta function,\n\n.. math ::\n\n    I_{x_1}^{x_2}(a,b) = \\int_{x_1}^{x_2} t^{a-1} (1-t)^{b-1} dt.\n\nWhen `x_1 = 0, x_2 = 1`, this reduces to the ordinary (complete)\nbeta function `B(a,b)`; see :func:`~mpmath.beta`.\n\nWith the keyword argument ``regularized=True``, :func:`~mpmath.betainc`\ncomputes the regularized incomplete beta function\n`I_{x_1}^{x_2}(a,b) / B(a,b)`. This is the cumulative distribution of the\nbeta distribution with parameters `a`, `b`.\n\n.. note :\n\n    Implementations of the incomplete beta function in some other\n    software uses a different argument order. For example, Mathematica uses the\n    reversed argument order ``Beta[x1,x2,a,b]``. For the equivalent of SciPy's\n    three-argument incomplete beta integral (implicitly with `x1 = 0`), use\n    ``betainc(a,b,0,x2,regularized=True)``.\n\n**Examples**\n\nVerifying that :func:`~mpmath.betainc` computes the integral in the\ndefinition::\n\n    >>> from mpmath import *\n    >>> mp.dps = 25; mp.pretty = True\n    >>> x,y,a,b = 3, 4, 0, 6\n    >>> betainc(x, y, a, b)\n    -4010.4\n    >>> quad(lambda t: t**(x-1) * (1-t)**(y-1), [a, b])\n    -4010.4\n\nThe arguments may be arbitrary complex numbers::\n\n    >>> betainc(0.75, 1-4j, 0, 2+3j)\n    (0.2241657956955709603655887 + 0.3619619242700451992411724j)\n\nWith regularization::\n\n    >>> betainc(1, 2, 0, 0.25, regularized=True)\n    0.4375\n    >>> betainc(pi, e, 0, 1, regularized=True)   # Complete\n    1.0\n\nThe beta integral satisfies some simple argument transformation\nsymmetries::\n\n    >>> mp.dps = 15\n    >>> betainc(2,3,4,5), -betainc(2,3,5,4), betainc(3,2,1-5,1-4)\n    (56.0833333333333, 56.0833333333333, 56.0833333333333)\n\nThe beta integral can often be evaluated analytically. For integer and\nrational arguments, the incomplete beta function typically reduces to a\nsimple algebraic-logarithmic expression::\n\n    >>> mp.dps = 25\n    >>> identify(chop(betainc(0, 0, 3, 4)))\n    '-(log((9/8)))'\n    >>> identify(betainc(2, 3, 4, 5))\n    '(673/12)'\n    >>> identify(betainc(1.5, 1, 1, 2))\n    '((-12+sqrt(1152))/18)'\n\n"
binomial: str = "\nComputes the binomial coefficient\n\n.. math ::\n\n    {n \\choose k} = \\frac{n!}{k!(n-k)!}.\n\nThe binomial coefficient gives the number of ways that `k` items\ncan be chosen from a set of `n` items. More generally, the binomial\ncoefficient is a well-defined function of arbitrary real or\ncomplex `n` and `k`, via the gamma function.\n\n**Examples**\n\nGenerate Pascal's triangle::\n\n    >>> from mpmath import *\n    >>> mp.dps = 15; mp.pretty = True\n    >>> for n in range(5):\n    ...     nprint([binomial(n,k) for k in range(n+1)])\n    ...\n    [1.0]\n    [1.0, 1.0]\n    [1.0, 2.0, 1.0]\n    [1.0, 3.0, 3.0, 1.0]\n    [1.0, 4.0, 6.0, 4.0, 1.0]\n\nThere is 1 way to select 0 items from the empty set, and 0 ways to\nselect 1 item from the empty set::\n\n    >>> binomial(0, 0)\n    1.0\n    >>> binomial(0, 1)\n    0.0\n\n:func:`~mpmath.binomial` supports large arguments::\n\n    >>> binomial(10**20, 10**20-5)\n    8.33333333333333e+97\n    >>> binomial(10**20, 10**10)\n    2.60784095465201e+104342944813\n\nNonintegral binomial coefficients find use in series\nexpansions::\n\n    >>> nprint(taylor(lambda x: (1+x)**0.25, 0, 4))\n    [1.0, 0.25, -0.09375, 0.0546875, -0.0375977]\n    >>> nprint([binomial(0.25, k) for k in range(5)])\n    [1.0, 0.25, -0.09375, 0.0546875, -0.0375977]\n\nAn integral representation::\n\n    >>> n, k = 5, 3\n    >>> f = lambda t: exp(-j*k*t)*(1+exp(j*t))**n\n    >>> chop(quad(f, [-pi,pi])/(2*pi))\n    10.0\n    >>> binomial(n,k)\n    10.0\n\n"
catalan: str = "\nCatalan's constant `K` = 0.91596559... is given by the infinite\nseries\n\n.. math ::\n\n    K = \\sum_{k=0}^{\\infty} \\frac{(-1)^k}{(2k+1)^2}.\n\nMpmath can evaluate it to arbitrary precision::\n\n    >>> from mpmath import *\n    >>> mp.dps = 50; mp.pretty = True\n    >>> +catalan\n    0.91596559417721901505460351493238411077414937428167\n\nOne can also compute `K` directly from the definition, although\nthis is significantly less efficient::\n\n    >>> nsum(lambda k: (-1)**k/(2*k+1)**2, [0, inf])\n    0.91596559417721901505460351493238411077414937428167\n\nThis shows digits 9991-10000 of `K` (the last digit is actually\na 3 when the decimal expansion is truncated, but here the nearest\nrounding is used)::\n\n    >>> mp.dps = 10000\n    >>> str(catalan)[-10:]\n    '9537871504'\n\nCatalan's constant has numerous integral representations::\n\n    >>> mp.dps = 50\n    >>> quad(lambda x: -log(x)/(1+x**2), [0, 1])\n    0.91596559417721901505460351493238411077414937428167\n    >>> quad(lambda x: atan(x)/x, [0, 1])\n    0.91596559417721901505460351493238411077414937428167\n    >>> quad(lambda x: ellipk(x**2)/2, [0, 1])\n    0.91596559417721901505460351493238411077414937428167\n    >>> quad(lambda x,y: 1/(1+(x*y)**2), [0, 1], [0, 1])\n    0.91596559417721901505460351493238411077414937428167\n\nAs well as series representations::\n\n    >>> pi*log(sqrt(3)+2)/8 + 3*nsum(lambda n:\n    ...  (fac(n)/(2*n+1))**2/fac(2*n), [0, inf])/8\n    0.91596559417721901505460351493238411077414937428167\n    >>> 1-nsum(lambda n: n*zeta(2*n+1)/16**n, [1,inf])\n    0.91596559417721901505460351493238411077414937428167\n"
cbrt: str = "\n``cbrt(x)`` computes the cube root of `x`, `x^{1/3}`. This\nfunction is faster and more accurate than raising to a floating-point\nfraction::\n\n    >>> from mpmath import *\n    >>> mp.dps = 15; mp.pretty = False\n    >>> 125**(mpf(1)/3)\n    mpf('4.9999999999999991')\n    >>> cbrt(125)\n    mpf('5.0')\n\nEvery nonzero complex number has three cube roots. This function\nreturns the cube root defined by `\\exp(\\log(x)/3)` where the\nprincipal branch of the natural logarithm is used. Note that this\ndoes not give a real cube root for negative real numbers::\n\n    >>> mp.pretty = True\n    >>> cbrt(-1)\n    (0.5 + 0.866025403784439j)\n"
ceil: str = "\nComputes the ceiling of `x`, `\\lceil x \\rceil`, defined as\nthe smallest integer greater than or equal to `x`::\n\n    >>> from mpmath import *\n    >>> mp.pretty = False\n    >>> ceil(3.5)\n    mpf('4.0')\n\nThe ceiling function is defined for complex numbers and\nacts on the real and imaginary parts separately::\n\n    >>> ceil(3.25+4.75j)\n    mpc(real='4.0', imag='5.0')\n\nSee notes about rounding for :func:`~mpmath.floor`.\n"
chebyt: str = '\n``chebyt(n, x)`` evaluates the Chebyshev polynomial of the first\nkind `T_n(x)`, defined by the identity\n\n.. math ::\n\n    T_n(\\cos x) = \\cos(n x).\n\nThe Chebyshev polynomials of the first kind are a special\ncase of the Jacobi polynomials, and by extension of the\nhypergeometric function `\\,_2F_1`. They can thus also be\nevaluated for nonintegral `n`.\n\n**Plots**\n\n.. literalinclude :: /plots/chebyt.py\n.. image :: /plots/chebyt.png\n\n**Basic evaluation**\n\nThe coefficients of the `n`-th polynomial can be recovered\nusing using degree-`n` Taylor expansion::\n\n    >>> from mpmath import *\n    >>> mp.dps = 15; mp.pretty = True\n    >>> for n in range(5):\n    ...     nprint(chop(taylor(lambda x: chebyt(n, x), 0, n)))\n    ...\n    [1.0]\n    [0.0, 1.0]\n    [-1.0, 0.0, 2.0]\n    [0.0, -3.0, 0.0, 4.0]\n    [1.0, 0.0, -8.0, 0.0, 8.0]\n\n**Orthogonality**\n\nThe Chebyshev polynomials of the first kind are orthogonal\non the interval `[-1, 1]` with respect to the weight\nfunction `w(x) = 1/\\sqrt{1-x^2}`::\n\n    >>> f = lambda x: chebyt(m,x)*chebyt(n,x)/sqrt(1-x**2)\n    >>> m, n = 3, 4\n    >>> nprint(quad(f, [-1, 1]),1)\n    0.0\n    >>> m, n = 4, 4\n    >>> quad(f, [-1, 1])\n    1.57079632596448\n\n'
chebyu: str = '\n``chebyu(n, x)`` evaluates the Chebyshev polynomial of the second\nkind `U_n(x)`, defined by the identity\n\n.. math ::\n\n    U_n(\\cos x) = \\frac{\\sin((n+1)x)}{\\sin(x)}.\n\nThe Chebyshev polynomials of the second kind are a special\ncase of the Jacobi polynomials, and by extension of the\nhypergeometric function `\\,_2F_1`. They can thus also be\nevaluated for nonintegral `n`.\n\n**Plots**\n\n.. literalinclude :: /plots/chebyu.py\n.. image :: /plots/chebyu.png\n\n**Basic evaluation**\n\nThe coefficients of the `n`-th polynomial can be recovered\nusing using degree-`n` Taylor expansion::\n\n    >>> from mpmath import *\n    >>> mp.dps = 15; mp.pretty = True\n    >>> for n in range(5):\n    ...     nprint(chop(taylor(lambda x: chebyu(n, x), 0, n)))\n    ...\n    [1.0]\n    [0.0, 2.0]\n    [-1.0, 0.0, 4.0]\n    [0.0, -4.0, 0.0, 8.0]\n    [1.0, 0.0, -12.0, 0.0, 16.0]\n\n**Orthogonality**\n\nThe Chebyshev polynomials of the second kind are orthogonal\non the interval `[-1, 1]` with respect to the weight\nfunction `w(x) = \\sqrt{1-x^2}`::\n\n    >>> f = lambda x: chebyu(m,x)*chebyu(n,x)*sqrt(1-x**2)\n    >>> m, n = 3, 4\n    >>> quad(f, [-1, 1])\n    0.0\n    >>> m, n = 4, 4\n    >>> quad(f, [-1, 1])\n    1.5707963267949\n'
chi: str = '\nComputes the hyperbolic cosine integral, defined\nin analogy with the cosine integral (see :func:`~mpmath.ci`) as\n\n.. math ::\n\n    \\mathrm{Chi}(x) = -\\int_x^{\\infty} \\frac{\\cosh t}{t}\\,dt\n    = \\gamma + \\log x + \\int_0^x \\frac{\\cosh t - 1}{t}\\,dt\n\nSome values and limits::\n\n    >>> from mpmath import *\n    >>> mp.dps = 25; mp.pretty = True\n    >>> chi(0)\n    -inf\n    >>> chi(1)\n    0.8378669409802082408946786\n    >>> chi(inf)\n    +inf\n    >>> findroot(chi, 0.5)\n    0.5238225713898644064509583\n    >>> chi(2+3j)\n    (-0.1683628683277204662429321 + 2.625115880451325002151688j)\n\nEvaluation is supported for `z` anywhere in the complex plane::\n\n    >>> chi(10**6*(1+j))\n    (4.449410587611035724984376e+434287 - 9.75744874290013526417059e+434287j)\n\n'
ci: str = '\nComputes the cosine integral,\n\n.. math ::\n\n    \\mathrm{Ci}(x) = -\\int_x^{\\infty} \\frac{\\cos t}{t}\\,dt\n    = \\gamma + \\log x + \\int_0^x \\frac{\\cos t - 1}{t}\\,dt\n\n**Examples**\n\nSome values and limits::\n\n    >>> from mpmath import *\n    >>> mp.dps = 25; mp.pretty = True\n    >>> ci(0)\n    -inf\n    >>> ci(1)\n    0.3374039229009681346626462\n    >>> ci(pi)\n    0.07366791204642548599010096\n    >>> ci(inf)\n    0.0\n    >>> ci(-inf)\n    (0.0 + 3.141592653589793238462643j)\n    >>> ci(2+3j)\n    (1.408292501520849518759125 - 2.983617742029605093121118j)\n\nThe cosine integral behaves roughly like the sinc function\n(see :func:`~mpmath.sinc`) for large real `x`::\n\n    >>> ci(10**10)\n    -4.875060251748226537857298e-11\n    >>> sinc(10**10)\n    -4.875060250875106915277943e-11\n    >>> chop(limit(ci, inf))\n    0.0\n\nIt has infinitely many roots on the positive real axis::\n\n    >>> findroot(ci, 1)\n    0.6165054856207162337971104\n    >>> findroot(ci, 2)\n    3.384180422551186426397851\n\nEvaluation is supported for `z` anywhere in the complex plane::\n\n    >>> ci(10**6*(1+j))\n    (4.449410587611035724984376e+434287 + 9.75744874290013526417059e+434287j)\n\nWe can evaluate the defining integral as a reference::\n\n    >>> mp.dps = 15\n    >>> -quadosc(lambda t: cos(t)/t, [5, inf], omega=1)\n    -0.190029749656644\n    >>> ci(5)\n    -0.190029749656644\n\nSome infinite series can be evaluated using the\ncosine integral::\n\n    >>> nsum(lambda k: (-1)**k/(fac(2*k)*(2*k)), [1,inf])\n    -0.239811742000565\n    >>> ci(1) - euler\n    -0.239811742000565\n\n'
clcos: str = '\nComputes the Clausen cosine function, defined formally by the series\n\n.. math ::\n\n    \\mathrm{\\widetilde{Cl}}_s(z) = \\sum_{k=1}^{\\infty} \\frac{\\cos(kz)}{k^s}.\n\nThis function is complementary to the Clausen sine function\n:func:`~mpmath.clsin`. In terms of the polylogarithm,\n\n.. math ::\n\n    \\mathrm{\\widetilde{Cl}}_s(z) =\n        \\frac{1}{2}\\left(\\mathrm{Li}_s\\left(e^{iz}\\right) +\n        \\mathrm{Li}_s\\left(e^{-iz}\\right)\\right)\n\n    = \\mathrm{Re}\\left[\\mathrm{Li}_s(e^{iz})\\right] \\quad (s, z \\in \\mathbb{R}).\n\n**Examples**\n\nEvaluation for arbitrarily chosen `s` and `z`::\n\n    >>> from mpmath import *\n    >>> mp.dps = 25; mp.pretty = True\n    >>> s, z = 3, 4\n    >>> clcos(s, z); nsum(lambda k: cos(z*k)/k**s, [1,inf])\n    -0.6518926267198991308332759\n    -0.6518926267198991308332759\n\nUsing `z + \\pi` instead of `z` gives an alternating series::\n\n    >>> s, z = 3, 0.5\n    >>> clcos(s, z+pi)\n    -0.8155530586502260817855618\n    >>> nsum(lambda k: (-1)**k*cos(z*k)/k**s, [1,inf])\n    -0.8155530586502260817855618\n\nWith `s = 1`, the sum can be expressed in closed form\nusing elementary functions::\n\n    >>> z = 1 + sqrt(3)\n    >>> clcos(1, z)\n    -0.6720334373369714849797918\n    >>> chop(-0.5*(log(1-exp(j*z))+log(1-exp(-j*z))))\n    -0.6720334373369714849797918\n    >>> -log(abs(2*sin(0.5*z)))    # Equivalent to above when z is real\n    -0.6720334373369714849797918\n    >>> nsum(lambda k: cos(k*z)/k, [1,inf])\n    -0.6720334373369714849797918\n\nIt can also be expressed in closed form when `s` is an even integer.\nFor example,\n\n    >>> clcos(2,z)\n    -0.7805359025135583118863007\n    >>> pi**2/6 - pi*z/2 + z**2/4\n    -0.7805359025135583118863007\n\nThe case `s = 0` gives the renormalized sum of\n`\\cos(z) + \\cos(2z) + \\cos(3z) + \\ldots` (which happens to be the same for\nany value of `z`)::\n\n    >>> clcos(0, z)\n    -0.5\n    >>> nsum(lambda k: cos(k*z), [1,inf])\n    -0.5\n\nAlso the sums\n\n.. math ::\n\n    \\cos(z) + 2\\cos(2z) + 3\\cos(3z) + \\ldots\n\nand\n\n.. math ::\n\n    \\cos(z) + 2^n \\cos(2z) + 3^n \\cos(3z) + \\ldots\n\nfor higher integer powers `n = -s` can be done in closed form. They are zero\nwhen `n` is positive and even (`s` negative and even)::\n\n    >>> clcos(-1, z); 1/(2*cos(z)-2)\n    -0.2607829375240542480694126\n    -0.2607829375240542480694126\n    >>> clcos(-3, z); (2+cos(z))*csc(z/2)**4/8\n    0.1472635054979944390848006\n    0.1472635054979944390848006\n    >>> clcos(-2, z); clcos(-4, z); clcos(-6, z)\n    0.0\n    0.0\n    0.0\n\nWith `z = \\pi`, the series reduces to that of the Riemann zeta function\n(more generally, if `z = p \\pi/q`, it is a finite sum over Hurwitz zeta\nfunction values)::\n\n    >>> clcos(2.5, 0); zeta(2.5)\n    1.34148725725091717975677\n    1.34148725725091717975677\n    >>> clcos(2.5, pi); -altzeta(2.5)\n    -0.8671998890121841381913472\n    -0.8671998890121841381913472\n\nCall with ``pi=True`` to multiply `z` by `\\pi` exactly::\n\n    >>> clcos(-3, 2*pi)\n    2.997921055881167659267063e+102\n    >>> clcos(-3, 2, pi=True)\n    0.008333333333333333333333333\n\nEvaluation for complex `s`, `z` in a nonconvergent case::\n\n    >>> s, z = -1-j, 1+2j\n    >>> clcos(s, z)\n    (0.9407430121562251476136807 + 0.715826296033590204557054j)\n    >>> extraprec(20)(nsum)(lambda k: cos(k*z)/k**s, [1,inf])\n    (0.9407430121562251476136807 + 0.715826296033590204557054j)\n\n'
clsin: str = '\nComputes the Clausen sine function, defined formally by the series\n\n.. math ::\n\n    \\mathrm{Cl}_s(z) = \\sum_{k=1}^{\\infty} \\frac{\\sin(kz)}{k^s}.\n\nThe special case `\\mathrm{Cl}_2(z)` (i.e. ``clsin(2,z)``) is the classical\n"Clausen function". More generally, the Clausen function is defined for\ncomplex `s` and `z`, even when the series does not converge. The\nClausen function is related to the polylogarithm (:func:`~mpmath.polylog`) as\n\n.. math ::\n\n    \\mathrm{Cl}_s(z) = \\frac{1}{2i}\\left(\\mathrm{Li}_s\\left(e^{iz}\\right) -\n                       \\mathrm{Li}_s\\left(e^{-iz}\\right)\\right)\n\n    = \\mathrm{Im}\\left[\\mathrm{Li}_s(e^{iz})\\right] \\quad (s, z \\in \\mathbb{R}),\n\nand this representation can be taken to provide the analytic continuation of the\nseries. The complementary function :func:`~mpmath.clcos` gives the corresponding\ncosine sum.\n\n**Examples**\n\nEvaluation for arbitrarily chosen `s` and `z`::\n\n    >>> from mpmath import *\n    >>> mp.dps = 25; mp.pretty = True\n    >>> s, z = 3, 4\n    >>> clsin(s, z); nsum(lambda k: sin(z*k)/k**s, [1,inf])\n    -0.6533010136329338746275795\n    -0.6533010136329338746275795\n\nUsing `z + \\pi` instead of `z` gives an alternating series::\n\n    >>> clsin(s, z+pi)\n    0.8860032351260589402871624\n    >>> nsum(lambda k: (-1)**k*sin(z*k)/k**s, [1,inf])\n    0.8860032351260589402871624\n\nWith `s = 1`, the sum can be expressed in closed form\nusing elementary functions::\n\n    >>> z = 1 + sqrt(3)\n    >>> clsin(1, z)\n    0.2047709230104579724675985\n    >>> chop((log(1-exp(-j*z)) - log(1-exp(j*z)))/(2*j))\n    0.2047709230104579724675985\n    >>> nsum(lambda k: sin(k*z)/k, [1,inf])\n    0.2047709230104579724675985\n\nThe classical Clausen function `\\mathrm{Cl}_2(\\theta)` gives the\nvalue of the integral `\\int_0^{\\theta} -\\ln(2\\sin(x/2)) dx` for\n`0 < \\theta < 2 \\pi`::\n\n    >>> cl2 = lambda t: clsin(2, t)\n    >>> cl2(3.5)\n    -0.2465045302347694216534255\n    >>> -quad(lambda x: ln(2*sin(0.5*x)), [0, 3.5])\n    -0.2465045302347694216534255\n\nThis function is symmetric about `\\theta = \\pi` with zeros and extreme\npoints::\n\n    >>> cl2(0); cl2(pi/3); chop(cl2(pi)); cl2(5*pi/3); chop(cl2(2*pi))\n    0.0\n    1.014941606409653625021203\n    0.0\n    -1.014941606409653625021203\n    0.0\n\nCatalan\'s constant is a special value::\n\n    >>> cl2(pi/2)\n    0.9159655941772190150546035\n    >>> +catalan\n    0.9159655941772190150546035\n\nThe Clausen sine function can be expressed in closed form when\n`s` is an odd integer (becoming zero when `s` < 0)::\n\n    >>> z = 1 + sqrt(2)\n    >>> clsin(1, z); (pi-z)/2\n    0.3636895456083490948304773\n    0.3636895456083490948304773\n    >>> clsin(3, z); pi**2/6*z - pi*z**2/4 + z**3/12\n    0.5661751584451144991707161\n    0.5661751584451144991707161\n    >>> clsin(-1, z)\n    0.0\n    >>> clsin(-3, z)\n    0.0\n\nIt can also be expressed in closed form for even integer `s \\le 0`,\nproviding a finite sum for series such as\n`\\sin(z) + \\sin(2z) + \\sin(3z) + \\ldots`::\n\n    >>> z = 1 + sqrt(2)\n    >>> clsin(0, z)\n    0.1903105029507513881275865\n    >>> cot(z/2)/2\n    0.1903105029507513881275865\n    >>> clsin(-2, z)\n    -0.1089406163841548817581392\n    >>> -cot(z/2)*csc(z/2)**2/4\n    -0.1089406163841548817581392\n\nCall with ``pi=True`` to multiply `z` by `\\pi` exactly::\n\n    >>> clsin(3, 3*pi)\n    -8.892316224968072424732898e-26\n    >>> clsin(3, 3, pi=True)\n    0.0\n\nEvaluation for complex `s`, `z` in a nonconvergent case::\n\n    >>> s, z = -1-j, 1+2j\n    >>> clsin(s, z)\n    (-0.593079480117379002516034 + 0.9038644233367868273362446j)\n    >>> extraprec(20)(nsum)(lambda k: sin(k*z)/k**s, [1,inf])\n    (-0.593079480117379002516034 + 0.9038644233367868273362446j)\n\n'
conj: str = "\nReturns the complex conjugate of `x`, `\\overline{x}`. Unlike\n``x.conjugate()``, :func:`~mpmath.im` converts `x` to a mpmath number::\n\n    >>> from mpmath import *\n    >>> mp.dps = 15; mp.pretty = False\n    >>> conj(3)\n    mpf('3.0')\n    >>> conj(-1+4j)\n    mpc(real='-1.0', imag='-4.0')\n"
cos: str = '\nComputes the cosine of `x`, `\\cos(x)`.\n\n    >>> from mpmath import *\n    >>> mp.dps = 25; mp.pretty = True\n    >>> cos(pi/3)\n    0.5\n    >>> cos(100000001)\n    -0.9802850113244713353133243\n    >>> cos(2+3j)\n    (-4.189625690968807230132555 - 9.109227893755336597979197j)\n    >>> cos(inf)\n    nan\n    >>> nprint(chop(taylor(cos, 0, 6)))\n    [1.0, 0.0, -0.5, 0.0, 0.0416667, 0.0, -0.00138889]\n\nIntervals are supported via :func:`mpmath.iv.cos`::\n\n    >>> iv.dps = 25; iv.pretty = True\n    >>> iv.cos([0,1])\n    [0.540302305868139717400936602301, 1.0]\n    >>> iv.cos([0,2])\n    [-0.41614683654714238699756823214, 1.0]\n'
cosh: str = '\nComputes the hyperbolic cosine of `x`,\n`\\cosh(x) = (e^x + e^{-x})/2`. Values and limits include::\n\n    >>> from mpmath import *\n    >>> mp.dps = 25; mp.pretty = True\n    >>> cosh(0)\n    1.0\n    >>> cosh(1)\n    1.543080634815243778477906\n    >>> cosh(-inf), cosh(+inf)\n    (+inf, +inf)\n\nThe hyperbolic cosine is an even, convex function with\na global minimum at `x = 0`, having a Maclaurin series\nthat starts::\n\n    >>> nprint(chop(taylor(cosh, 0, 5)))\n    [1.0, 0.0, 0.5, 0.0, 0.0416667, 0.0]\n\nGeneralized to complex numbers, the hyperbolic cosine is\nequivalent to a cosine with the argument rotated\nin the imaginary direction, or `\\cosh x = \\cos ix`::\n\n    >>> cosh(2+3j)\n    (-3.724545504915322565473971 + 0.5118225699873846088344638j)\n    >>> cos(3-2j)\n    (-3.724545504915322565473971 + 0.5118225699873846088344638j)\n'
cospi: str = '\nComputes `\\cos(\\pi x)`, more accurately than the expression\n``cos(pi*x)``::\n\n    >>> from mpmath import *\n    >>> mp.dps = 15; mp.pretty = True\n    >>> cospi(10**10), cos(pi*(10**10))\n    (1.0, 0.999999999997493)\n    >>> cospi(10**10+0.5), cos(pi*(10**10+0.5))\n    (0.0, 1.59960492420134e-6)\n'
cot: str = '\nComputes the cotangent of `x`,\n`\\mathrm{cot}(x) = \\frac{1}{\\tan(x)} = \\frac{\\cos(x)}{\\sin(x)}`.\nThis cotangent function is singular at `x = n \\pi`, but with the\nexception of the point `x = 0`, ``cot(x)`` returns a finite result\nsince `n \\pi` cannot be represented exactly using floating-point\narithmetic.\n\n    >>> from mpmath import *\n    >>> mp.dps = 25; mp.pretty = True\n    >>> cot(pi/3)\n    0.5773502691896257645091488\n    >>> cot(10000001)\n    1.574131876209625656003562\n    >>> cot(2+3j)\n    (-0.003739710376336956660117409 - 0.9967577965693583104609688j)\n    >>> cot(inf)\n    nan\n\nIntervals are supported via :func:`mpmath.iv.cot`::\n\n    >>> iv.dps = 25; iv.pretty = True\n    >>> iv.cot([0,1])  # Interval includes a singularity\n    [0.642092615934330703006419974862, +inf]\n    >>> iv.cot([1,2])\n    [-inf, +inf]\n'
coth: str = 'Computes the hyperbolic cotangent of `x`,\n`\\mathrm{coth}(x) = \\frac{\\cosh(x)}{\\sinh(x)}`.\n'
coulombc: str = '\nGives the normalizing Gamow constant for Coulomb wave functions,\n\n.. math ::\n\n    C_l(\\eta) = 2^l \\exp\\left(-\\pi \\eta/2 + [\\ln \\Gamma(1+l+i\\eta) +\n        \\ln \\Gamma(1+l-i\\eta)]/2 - \\ln \\Gamma(2l+2)\\right),\n\nwhere the log gamma function with continuous imaginary part\naway from the negative half axis (see :func:`~mpmath.loggamma`) is implied.\n\nThis function is used internally for the calculation of\nCoulomb wave functions, and automatically cached to make multiple\nevaluations with fixed `l`, `\\eta` fast.\n'
coulombf: str = '\nCalculates the regular Coulomb wave function\n\n.. math ::\n\n    F_l(\\eta,z) = C_l(\\eta) z^{l+1} e^{-iz} \\,_1F_1(l+1-i\\eta, 2l+2, 2iz)\n\nwhere the normalization constant `C_l(\\eta)` is as calculated by\n:func:`~mpmath.coulombc`. This function solves the differential equation\n\n.. math ::\n\n    f\'\'(z) + \\left(1-\\frac{2\\eta}{z}-\\frac{l(l+1)}{z^2}\\right) f(z) = 0.\n\nA second linearly independent solution is given by the irregular\nCoulomb wave function `G_l(\\eta,z)` (see :func:`~mpmath.coulombg`)\nand thus the general solution is\n`f(z) = C_1 F_l(\\eta,z) + C_2 G_l(\\eta,z)` for arbitrary\nconstants `C_1`, `C_2`.\nPhysically, the Coulomb wave functions give the radial solution\nto the Schrodinger equation for a point particle in a `1/z` potential; `z` is\nthen the radius and `l`, `\\eta` are quantum numbers.\n\nThe Coulomb wave functions with real parameters are defined\nin Abramowitz & Stegun, section 14. However, all parameters are permitted\nto be complex in this implementation (see references).\n\n**Plots**\n\n.. literalinclude :: /plots/coulombf.py\n.. image :: /plots/coulombf.png\n.. literalinclude :: /plots/coulombf_c.py\n.. image :: /plots/coulombf_c.png\n\n**Examples**\n\nEvaluation is supported for arbitrary magnitudes of `z`::\n\n    >>> from mpmath import *\n    >>> mp.dps = 25; mp.pretty = True\n    >>> coulombf(2, 1.5, 3.5)\n    0.4080998961088761187426445\n    >>> coulombf(-2, 1.5, 3.5)\n    0.7103040849492536747533465\n    >>> coulombf(2, 1.5, \'1e-10\')\n    4.143324917492256448770769e-33\n    >>> coulombf(2, 1.5, 1000)\n    0.4482623140325567050716179\n    >>> coulombf(2, 1.5, 10**10)\n    -0.066804196437694360046619\n\nVerifying the differential equation::\n\n    >>> l, eta, z = 2, 3, mpf(2.75)\n    >>> A, B = 1, 2\n    >>> f = lambda z: A*coulombf(l,eta,z) + B*coulombg(l,eta,z)\n    >>> chop(diff(f,z,2) + (1-2*eta/z - l*(l+1)/z**2)*f(z))\n    0.0\n\nA Wronskian relation satisfied by the Coulomb wave functions::\n\n    >>> l = 2\n    >>> eta = 1.5\n    >>> F = lambda z: coulombf(l,eta,z)\n    >>> G = lambda z: coulombg(l,eta,z)\n    >>> for z in [3.5, -1, 2+3j]:\n    ...     chop(diff(F,z)*G(z) - F(z)*diff(G,z))\n    ...\n    1.0\n    1.0\n    1.0\n\nAnother Wronskian relation::\n\n    >>> F = coulombf\n    >>> G = coulombg\n    >>> for z in [3.5, -1, 2+3j]:\n    ...     chop(F(l-1,eta,z)*G(l,eta,z)-F(l,eta,z)*G(l-1,eta,z) - l/sqrt(l**2+eta**2))\n    ...\n    0.0\n    0.0\n    0.0\n\nAn integral identity connecting the regular and irregular wave functions::\n\n    >>> l, eta, z = 4+j, 2-j, 5+2j\n    >>> coulombf(l,eta,z) + j*coulombg(l,eta,z)\n    (0.7997977752284033239714479 + 0.9294486669502295512503127j)\n    >>> g = lambda t: exp(-t)*t**(l-j*eta)*(t+2*j*z)**(l+j*eta)\n    >>> j*exp(-j*z)*z**(-l)/fac(2*l+1)/coulombc(l,eta)*quad(g, [0,inf])\n    (0.7997977752284033239714479 + 0.9294486669502295512503127j)\n\nSome test case with complex parameters, taken from Michel [2]::\n\n    >>> mp.dps = 15\n    >>> coulombf(1+0.1j, 50+50j, 100.156)\n    (-1.02107292320897e+15 - 2.83675545731519e+15j)\n    >>> coulombg(1+0.1j, 50+50j, 100.156)\n    (2.83675545731519e+15 - 1.02107292320897e+15j)\n    >>> coulombf(1e-5j, 10+1e-5j, 0.1+1e-6j)\n    (4.30566371247811e-14 - 9.03347835361657e-19j)\n    >>> coulombg(1e-5j, 10+1e-5j, 0.1+1e-6j)\n    (778709182061.134 + 18418936.2660553j)\n\nThe following reproduces a table in Abramowitz & Stegun, at twice\nthe precision::\n\n    >>> mp.dps = 10\n    >>> eta = 2; z = 5\n    >>> for l in [5, 4, 3, 2, 1, 0]:\n    ...     print("%s %s %s" % (l, coulombf(l,eta,z),\n    ...         diff(lambda z: coulombf(l,eta,z), z)))\n    ...\n    5 0.09079533488 0.1042553261\n    4 0.2148205331 0.2029591779\n    3 0.4313159311 0.320534053\n    2 0.7212774133 0.3952408216\n    1 0.9935056752 0.3708676452\n    0 1.143337392 0.2937960375\n\n**References**\n\n1. I.J. Thompson & A.R. Barnett, "Coulomb and Bessel Functions of Complex\n   Arguments and Order", J. Comp. Phys., vol 64, no. 2, June 1986.\n\n2. N. Michel, "Precise Coulomb wave functions for a wide range of\n   complex `l`, `\\eta` and `z`", http://arxiv.org/abs/physics/0702051v1\n\n'
coulombg: str = '\nCalculates the irregular Coulomb wave function\n\n.. math ::\n\n    G_l(\\eta,z) = \\frac{F_l(\\eta,z) \\cos(\\chi) - F_{-l-1}(\\eta,z)}{\\sin(\\chi)}\n\nwhere `\\chi = \\sigma_l - \\sigma_{-l-1} - (l+1/2) \\pi`\nand `\\sigma_l(\\eta) = (\\ln \\Gamma(1+l+i\\eta)-\\ln \\Gamma(1+l-i\\eta))/(2i)`.\n\nSee :func:`~mpmath.coulombf` for additional information.\n\n**Plots**\n\n.. literalinclude :: /plots/coulombg.py\n.. image :: /plots/coulombg.png\n.. literalinclude :: /plots/coulombg_c.py\n.. image :: /plots/coulombg_c.png\n\n**Examples**\n\nEvaluation is supported for arbitrary magnitudes of `z`::\n\n    >>> from mpmath import *\n    >>> mp.dps = 25; mp.pretty = True\n    >>> coulombg(-2, 1.5, 3.5)\n    1.380011900612186346255524\n    >>> coulombg(2, 1.5, 3.5)\n    1.919153700722748795245926\n    >>> coulombg(-2, 1.5, \'1e-10\')\n    201126715824.7329115106793\n    >>> coulombg(-2, 1.5, 1000)\n    0.1802071520691149410425512\n    >>> coulombg(-2, 1.5, 10**10)\n    0.652103020061678070929794\n\nThe following reproduces a table in Abramowitz & Stegun,\nat twice the precision::\n\n    >>> mp.dps = 10\n    >>> eta = 2; z = 5\n    >>> for l in [1, 2, 3, 4, 5]:\n    ...     print("%s %s %s" % (l, coulombg(l,eta,z),\n    ...         -diff(lambda z: coulombg(l,eta,z), z)))\n    ...\n    1 1.08148276 0.6028279961\n    2 1.496877075 0.5661803178\n    3 2.048694714 0.7959909551\n    4 3.09408669 1.731802374\n    5 5.629840456 4.549343289\n\nEvaluation close to the singularity at `z = 0`::\n\n    >>> mp.dps = 15\n    >>> coulombg(0,10,1)\n    3088184933.67358\n    >>> coulombg(0,10,\'1e-10\')\n    5554866000719.8\n    >>> coulombg(0,10,\'1e-100\')\n    5554866221524.1\n\nEvaluation with a half-integer value for `l`::\n\n    >>> coulombg(1.5, 1, 10)\n    0.852320038297334\n'
csc: str = '\nComputes the cosecant of `x`, `\\mathrm{csc}(x) = \\frac{1}{\\sin(x)}`.\nThis cosecant function is singular at `x = n \\pi`, but with the\nexception of the point `x = 0`, ``csc(x)`` returns a finite result\nsince `n \\pi` cannot be represented exactly using floating-point\narithmetic.\n\n    >>> from mpmath import *\n    >>> mp.dps = 25; mp.pretty = True\n    >>> csc(pi/3)\n    1.154700538379251529018298\n    >>> csc(10000001)\n    -1.864910497503629858938891\n    >>> csc(2+3j)\n    (0.09047320975320743980579048 + 0.04120098628857412646300981j)\n    >>> csc(inf)\n    nan\n\nIntervals are supported via :func:`mpmath.iv.csc`::\n\n    >>> iv.dps = 25; iv.pretty = True\n    >>> iv.csc([0,1])  # Interval includes a singularity\n    [1.18839510577812121626159943988, +inf]\n    >>> iv.csc([0,2])\n    [1.0, +inf]\n'
csch: str = 'Computes the hyperbolic cosecant of `x`,\n`\\mathrm{csch}(x) = \\frac{1}{\\sinh(x)}`.\n'
cyclotomic: str = '\nEvaluates the cyclotomic polynomial `\\Phi_n(x)`, defined by\n\n.. math ::\n\n    \\Phi_n(x) = \\prod_{\\zeta} (x - \\zeta)\n\nwhere `\\zeta` ranges over all primitive `n`-th roots of unity\n(see :func:`~mpmath.unitroots`). An equivalent representation, used\nfor computation, is\n\n.. math ::\n\n    \\Phi_n(x) = \\prod_{d\\mid n}(x^d-1)^{\\mu(n/d)} = \\Phi_n(x)\n\nwhere `\\mu(m)` denotes the Moebius function. The cyclotomic\npolynomials are integer polynomials, the first of which can be\nwritten explicitly as\n\n.. math ::\n\n    \\Phi_0(x) = 1\n\n    \\Phi_1(x) = x - 1\n\n    \\Phi_2(x) = x + 1\n\n    \\Phi_3(x) = x^3 + x^2 + 1\n\n    \\Phi_4(x) = x^2 + 1\n\n    \\Phi_5(x) = x^4 + x^3 + x^2 + x + 1\n\n    \\Phi_6(x) = x^2 - x + 1\n\n**Examples**\n\nThe coefficients of low-order cyclotomic polynomials can be recovered\nusing Taylor expansion::\n\n    >>> from mpmath import *\n    >>> mp.dps = 15; mp.pretty = True\n    >>> for n in range(9):\n    ...     p = chop(taylor(lambda x: cyclotomic(n,x), 0, 10))\n    ...     print("%s %s" % (n, nstr(p[:10+1-p[::-1].index(1)])))\n    ...\n    0 [1.0]\n    1 [-1.0, 1.0]\n    2 [1.0, 1.0]\n    3 [1.0, 1.0, 1.0]\n    4 [1.0, 0.0, 1.0]\n    5 [1.0, 1.0, 1.0, 1.0, 1.0]\n    6 [1.0, -1.0, 1.0]\n    7 [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n    8 [1.0, 0.0, 0.0, 0.0, 1.0]\n\nThe definition as a product over primitive roots may be checked\nby computing the product explicitly (for a real argument, this\nmethod will generally introduce numerical noise in the imaginary\npart)::\n\n    >>> mp.dps = 25\n    >>> z = 3+4j\n    >>> cyclotomic(10, z)\n    (-419.0 - 360.0j)\n    >>> fprod(z-r for r in unitroots(10, primitive=True))\n    (-419.0 - 360.0j)\n    >>> z = 3\n    >>> cyclotomic(10, z)\n    61.0\n    >>> fprod(z-r for r in unitroots(10, primitive=True))\n    (61.0 - 3.146045605088568607055454e-25j)\n\nUp to permutation, the roots of a given cyclotomic polynomial\ncan be checked to agree with the list of primitive roots::\n\n    >>> p = taylor(lambda x: cyclotomic(6,x), 0, 6)[:3]\n    >>> for r in polyroots(p[::-1]):\n    ...     print(r)\n    ...\n    (0.5 - 0.8660254037844386467637232j)\n    (0.5 + 0.8660254037844386467637232j)\n    >>>\n    >>> for r in unitroots(6, primitive=True):\n    ...     print(r)\n    ...\n    (0.5 + 0.8660254037844386467637232j)\n    (0.5 - 0.8660254037844386467637232j)\n\n'
degree: str = '\nRepresents one degree of angle, `1^{\\circ} = \\pi/180`, or\nabout 0.01745329. This constant may be evaluated to arbitrary\nprecision::\n\n    >>> from mpmath import *\n    >>> mp.dps = 50; mp.pretty = True\n    >>> +degree\n    0.017453292519943295769236907684886127134428718885417\n\nThe :data:`degree` object is convenient for conversion\nto radians::\n\n    >>> sin(30 * degree)\n    0.5\n    >>> asin(0.5) / degree\n    30.0\n'
degrees: str = '\nConverts the radian angle `x` to a degree angle::\n\n    >>> from mpmath import *\n    >>> mp.dps = 15; mp.pretty = True\n    >>> degrees(pi/3)\n    60.0\n'
digamma: str = '\nShortcut for ``psi(0,z)``.\n'
dirichlet: str = '\nEvaluates the Dirichlet L-function\n\n.. math ::\n\n    L(s,\\chi) = \\sum_{k=1}^\\infty \\frac{\\chi(k)}{k^s}.\n\nwhere `\\chi` is a periodic sequence of length `q` which should be supplied\nin the form of a list `[\\chi(0), \\chi(1), \\ldots, \\chi(q-1)]`.\nStrictly, `\\chi` should be a Dirichlet character, but any periodic\nsequence will work.\n\nFor example, ``dirichlet(s, [1])`` gives the ordinary\nRiemann zeta function and ``dirichlet(s, [-1,1])`` gives\nthe alternating zeta function (Dirichlet eta function).\n\nAlso the derivative with respect to `s` (currently only a first\nderivative) can be evaluated.\n\n**Examples**\n\nThe ordinary Riemann zeta function::\n\n    >>> from mpmath import *\n    >>> mp.dps = 25; mp.pretty = True\n    >>> dirichlet(3, [1]); zeta(3)\n    1.202056903159594285399738\n    1.202056903159594285399738\n    >>> dirichlet(1, [1])\n    +inf\n\nThe alternating zeta function::\n\n    >>> dirichlet(1, [-1,1]); ln(2)\n    0.6931471805599453094172321\n    0.6931471805599453094172321\n\nThe following defines the Dirichlet beta function\n`\\beta(s) = \\sum_{k=0}^\\infty \\frac{(-1)^k}{(2k+1)^s}` and verifies\nseveral values of this function::\n\n    >>> B = lambda s, d=0: dirichlet(s, [0, 1, 0, -1], d)\n    >>> B(0); 1./2\n    0.5\n    0.5\n    >>> B(1); pi/4\n    0.7853981633974483096156609\n    0.7853981633974483096156609\n    >>> B(2); +catalan\n    0.9159655941772190150546035\n    0.9159655941772190150546035\n    >>> B(2,1); diff(B, 2)\n    0.08158073611659279510291217\n    0.08158073611659279510291217\n    >>> B(-1,1); 2*catalan/pi\n    0.5831218080616375602767689\n    0.5831218080616375602767689\n    >>> B(0,1); log(gamma(0.25)**2/(2*pi*sqrt(2)))\n    0.3915943927068367764719453\n    0.3915943927068367764719454\n    >>> B(1,1); 0.25*pi*(euler+2*ln2+3*ln(pi)-4*ln(gamma(0.25)))\n    0.1929013167969124293631898\n    0.1929013167969124293631898\n\nA custom L-series of period 3::\n\n    >>> dirichlet(2, [2,0,1])\n    0.7059715047839078092146831\n    >>> 2*nsum(lambda k: (3*k)**-2, [1,inf]) + \\\n    ...   nsum(lambda k: (3*k+2)**-2, [0,inf])\n    0.7059715047839078092146831\n\n'
e: str = "\nThe transcendental number `e` = 2.718281828... is the base of the\nnatural logarithm (:func:`~mpmath.ln`) and of the exponential function\n(:func:`~mpmath.exp`).\n\nMpmath can be evaluate `e` to arbitrary precision::\n\n    >>> from mpmath import *\n    >>> mp.dps = 50; mp.pretty = True\n    >>> +e\n    2.7182818284590452353602874713526624977572470937\n\nThis shows digits 99991-100000 of `e` (the last digit is actually\na 5 when the decimal expansion is truncated, but here the nearest\nrounding is used)::\n\n    >>> mp.dps = 100000\n    >>> str(e)[-10:]\n    '2100427166'\n\n**Possible issues**\n\n:data:`e` always rounds to the nearest floating-point number\nwhen used, and mathematical identities involving `e` may not\nhold in floating-point arithmetic. For example, ``ln(e)``\nmight not evaluate exactly to 1.\n\nIn particular, don't use ``e**x`` to compute the exponential\nfunction. Use ``exp(x)`` instead; this is both faster and more\naccurate.\n"
e1: str = '\nComputes the exponential integral `\\mathrm{E}_1(z)`, given by\n\n.. math ::\n\n    \\mathrm{E}_1(z) = \\int_z^{\\infty} \\frac{e^{-t}}{t} dt.\n\nThis is equivalent to :func:`~mpmath.expint` with `n = 1`.\n\n**Examples**\n\nTwo ways to evaluate this function::\n\n    >>> from mpmath import *\n    >>> mp.dps = 25; mp.pretty = True\n    >>> e1(6.25)\n    0.0002704758872637179088496194\n    >>> expint(1,6.25)\n    0.0002704758872637179088496194\n\nThe E1-function is essentially the same as the Ei-function (:func:`~mpmath.ei`)\nwith negated argument, except for an imaginary branch cut term::\n\n    >>> e1(2.5)\n    0.02491491787026973549562801\n    >>> -ei(-2.5)\n    0.02491491787026973549562801\n    >>> e1(-2.5)\n    (-7.073765894578600711923552 - 3.141592653589793238462643j)\n    >>> -ei(2.5)\n    -7.073765894578600711923552\n\n'
ei: str = '\nComputes the exponential integral or Ei-function, `\\mathrm{Ei}(x)`.\nThe exponential integral is defined as\n\n.. math ::\n\n  \\mathrm{Ei}(x) = \\int_{-\\infty\\,}^x \\frac{e^t}{t} \\, dt.\n\nWhen the integration range includes `t = 0`, the exponential\nintegral is interpreted as providing the Cauchy principal value.\n\nFor real `x`, the Ei-function behaves roughly like\n`\\mathrm{Ei}(x) \\approx \\exp(x) + \\log(|x|)`.\n\nThe Ei-function is related to the more general family of exponential\nintegral functions denoted by `E_n`, which are available as :func:`~mpmath.expint`.\n\n**Basic examples**\n\nSome basic values and limits are::\n\n    >>> from mpmath import *\n    >>> mp.dps = 15; mp.pretty = True\n    >>> ei(0)\n    -inf\n    >>> ei(1)\n    1.89511781635594\n    >>> ei(inf)\n    +inf\n    >>> ei(-inf)\n    0.0\n\nFor `x < 0`, the defining integral can be evaluated\nnumerically as a reference::\n\n    >>> ei(-4)\n    -0.00377935240984891\n    >>> quad(lambda t: exp(t)/t, [-inf, -4])\n    -0.00377935240984891\n\n:func:`~mpmath.ei` supports complex arguments and arbitrary\nprecision evaluation::\n\n    >>> mp.dps = 50\n    >>> ei(pi)\n    10.928374389331410348638445906907535171566338835056\n    >>> mp.dps = 25\n    >>> ei(3+4j)\n    (-4.154091651642689822535359 + 4.294418620024357476985535j)\n\n**Related functions**\n\nThe exponential integral is closely related to the logarithmic\nintegral. See :func:`~mpmath.li` for additional information.\n\nThe exponential integral is related to the hyperbolic\nand trigonometric integrals (see :func:`~mpmath.chi`, :func:`~mpmath.shi`,\n:func:`~mpmath.ci`, :func:`~mpmath.si`) similarly to how the ordinary\nexponential function is related to the hyperbolic and\ntrigonometric functions::\n\n    >>> mp.dps = 15\n    >>> ei(3)\n    9.93383257062542\n    >>> chi(3) + shi(3)\n    9.93383257062542\n    >>> chop(ci(3j) - j*si(3j) - pi*j/2)\n    9.93383257062542\n\nBeware that logarithmic corrections, as in the last example\nabove, are required to obtain the correct branch in general.\nFor details, see [1].\n\nThe exponential integral is also a special case of the\nhypergeometric function `\\,_2F_2`::\n\n    >>> z = 0.6\n    >>> z*hyper([1,1],[2,2],z) + (ln(z)-ln(1/z))/2 + euler\n    0.769881289937359\n    >>> ei(z)\n    0.769881289937359\n\n**References**\n\n1. Relations between Ei and other functions:\n   http://functions.wolfram.com/GammaBetaErf/ExpIntegralEi/27/01/\n\n2. Abramowitz & Stegun, section 5:\n   http://people.math.sfu.ca/~cbm/aands/page_228.htm\n\n3. Asymptotic expansion for Ei:\n   http://mathworld.wolfram.com/En-Function.html\n'
ellipfun: str = "\nComputes any of the Jacobi elliptic functions, defined\nin terms of Jacobi theta functions as\n\n.. math ::\n\n    \\mathrm{sn}(u,m) = \\frac{\\vartheta_3(0,q)}{\\vartheta_2(0,q)}\n        \\frac{\\vartheta_1(t,q)}{\\vartheta_4(t,q)}\n\n    \\mathrm{cn}(u,m) = \\frac{\\vartheta_4(0,q)}{\\vartheta_2(0,q)}\n        \\frac{\\vartheta_2(t,q)}{\\vartheta_4(t,q)}\n\n    \\mathrm{dn}(u,m) = \\frac{\\vartheta_4(0,q)}{\\vartheta_3(0,q)}\n        \\frac{\\vartheta_3(t,q)}{\\vartheta_4(t,q)},\n\nor more generally computes a ratio of two such functions. Here\n`t = u/\\vartheta_3(0,q)^2`, and `q = q(m)` denotes the nome (see\n:func:`~mpmath.nome`). Optionally, you can specify the nome directly\ninstead of `m` by passing ``q=<value>``, or you can directly\nspecify the elliptic parameter `k` with ``k=<value>``.\n\nThe first argument should be a two-character string specifying the\nfunction using any combination of ``'s'``, ``'c'``, ``'d'``, ``'n'``. These\nletters respectively denote the basic functions\n`\\mathrm{sn}(u,m)`, `\\mathrm{cn}(u,m)`, `\\mathrm{dn}(u,m)`, and `1`.\nThe identifier specifies the ratio of two such functions.\nFor example, ``'ns'`` identifies the function\n\n.. math ::\n\n    \\mathrm{ns}(u,m) = \\frac{1}{\\mathrm{sn}(u,m)}\n\nand ``'cd'`` identifies the function\n\n.. math ::\n\n    \\mathrm{cd}(u,m) = \\frac{\\mathrm{cn}(u,m)}{\\mathrm{dn}(u,m)}.\n\nIf called with only the first argument, a function object\nevaluating the chosen function for given arguments is returned.\n\n**Examples**\n\nBasic evaluation::\n\n    >>> from mpmath import *\n    >>> mp.dps = 25; mp.pretty = True\n    >>> ellipfun('cd', 3.5, 0.5)\n    -0.9891101840595543931308394\n    >>> ellipfun('cd', 3.5, q=0.25)\n    0.07111979240214668158441418\n\nThe sn-function is doubly periodic in the complex plane with periods\n`4 K(m)` and `2 i K(1-m)` (see :func:`~mpmath.ellipk`)::\n\n    >>> sn = ellipfun('sn')\n    >>> sn(2, 0.25)\n    0.9628981775982774425751399\n    >>> sn(2+4*ellipk(0.25), 0.25)\n    0.9628981775982774425751399\n    >>> chop(sn(2+2*j*ellipk(1-0.25), 0.25))\n    0.9628981775982774425751399\n\nThe cn-function is doubly periodic with periods `4 K(m)` and `2 K(m) + 2 i K(1-m)`::\n\n    >>> cn = ellipfun('cn')\n    >>> cn(2, 0.25)\n    -0.2698649654510865792581416\n    >>> cn(2+4*ellipk(0.25), 0.25)\n    -0.2698649654510865792581416\n    >>> chop(cn(2+2*ellipk(0.25)+2*j*ellipk(1-0.25), 0.25))\n    -0.2698649654510865792581416\n\nThe dn-function is doubly periodic with periods `2 K(m)` and `4 i K(1-m)`::\n\n    >>> dn = ellipfun('dn')\n    >>> dn(2, 0.25)\n    0.8764740583123262286931578\n    >>> dn(2+2*ellipk(0.25), 0.25)\n    0.8764740583123262286931578\n    >>> chop(dn(2+4*j*ellipk(1-0.25), 0.25))\n    0.8764740583123262286931578\n\n"
ellipk: str = '\nEvaluates the complete elliptic integral of the first kind,\n`K(m)`, defined by\n\n.. math ::\n\n    K(m) = \\int_0^{\\pi/2} \\frac{dt}{\\sqrt{1-m \\sin^2 t}} \\, = \\,\n    \\frac{\\pi}{2} \\,_2F_1\\left(\\frac{1}{2}, \\frac{1}{2}, 1, m\\right).\n\nNote that the argument is the parameter `m = k^2`,\nnot the modulus `k` which is sometimes used.\n\n**Plots**\n\n.. literalinclude :: /plots/ellipk.py\n.. image :: /plots/ellipk.png\n\n**Examples**\n\nValues and limits include::\n\n    >>> from mpmath import *\n    >>> mp.dps = 25; mp.pretty = True\n    >>> ellipk(0)\n    1.570796326794896619231322\n    >>> ellipk(inf)\n    (0.0 + 0.0j)\n    >>> ellipk(-inf)\n    0.0\n    >>> ellipk(1)\n    +inf\n    >>> ellipk(-1)\n    1.31102877714605990523242\n    >>> ellipk(2)\n    (1.31102877714605990523242 - 1.31102877714605990523242j)\n\nVerifying the defining integral and hypergeometric\nrepresentation::\n\n    >>> ellipk(0.5)\n    1.85407467730137191843385\n    >>> quad(lambda t: (1-0.5*sin(t)**2)**-0.5, [0, pi/2])\n    1.85407467730137191843385\n    >>> pi/2*hyp2f1(0.5,0.5,1,0.5)\n    1.85407467730137191843385\n\nEvaluation is supported for arbitrary complex `m`::\n\n    >>> ellipk(3+4j)\n    (0.9111955638049650086562171 + 0.6313342832413452438845091j)\n\nA definite integral::\n\n    >>> quad(ellipk, [0, 1])\n    2.0\n'
erf: str = "\nComputes the error function, `\\mathrm{erf}(x)`. The error\nfunction is the normalized antiderivative of the Gaussian function\n`\\exp(-t^2)`. More precisely,\n\n.. math::\n\n  \\mathrm{erf}(x) = \\frac{2}{\\sqrt \\pi} \\int_0^x \\exp(-t^2) \\,dt\n\n**Basic examples**\n\nSimple values and limits include::\n\n    >>> from mpmath import *\n    >>> mp.dps = 15; mp.pretty = True\n    >>> erf(0)\n    0.0\n    >>> erf(1)\n    0.842700792949715\n    >>> erf(-1)\n    -0.842700792949715\n    >>> erf(inf)\n    1.0\n    >>> erf(-inf)\n    -1.0\n\nFor large real `x`, `\\mathrm{erf}(x)` approaches 1 very\nrapidly::\n\n    >>> erf(3)\n    0.999977909503001\n    >>> erf(5)\n    0.999999999998463\n\nThe error function is an odd function::\n\n    >>> nprint(chop(taylor(erf, 0, 5)))\n    [0.0, 1.12838, 0.0, -0.376126, 0.0, 0.112838]\n\n:func:`~mpmath.erf` implements arbitrary-precision evaluation and\nsupports complex numbers::\n\n    >>> mp.dps = 50\n    >>> erf(0.5)\n    0.52049987781304653768274665389196452873645157575796\n    >>> mp.dps = 25\n    >>> erf(1+j)\n    (1.316151281697947644880271 + 0.1904534692378346862841089j)\n\nEvaluation is supported for large arguments::\n\n    >>> mp.dps = 25\n    >>> erf('1e1000')\n    1.0\n    >>> erf('-1e1000')\n    -1.0\n    >>> erf('1e-1000')\n    1.128379167095512573896159e-1000\n    >>> erf('1e7j')\n    (0.0 + 8.593897639029319267398803e+43429448190317j)\n    >>> erf('1e7+1e7j')\n    (0.9999999858172446172631323 + 3.728805278735270407053139e-8j)\n\n**Related functions**\n\nSee also :func:`~mpmath.erfc`, which is more accurate for large `x`,\nand :func:`~mpmath.erfi` which gives the antiderivative of\n`\\exp(t^2)`.\n\nThe Fresnel integrals :func:`~mpmath.fresnels` and :func:`~mpmath.fresnelc`\nare also related to the error function.\n"
erfc: str = '\nComputes the complementary error function,\n`\\mathrm{erfc}(x) = 1-\\mathrm{erf}(x)`.\nThis function avoids cancellation that occurs when naively\ncomputing the complementary error function as ``1-erf(x)``::\n\n    >>> from mpmath import *\n    >>> mp.dps = 15; mp.pretty = True\n    >>> 1 - erf(10)\n    0.0\n    >>> erfc(10)\n    2.08848758376254e-45\n\n:func:`~mpmath.erfc` works accurately even for ludicrously large\narguments::\n\n    >>> erfc(10**10)\n    4.3504398860243e-43429448190325182776\n\nComplex arguments are supported::\n\n    >>> erfc(500+50j)\n    (1.19739830969552e-107492 + 1.46072418957528e-107491j)\n\n'
erfi: str = '\nComputes the imaginary error function, `\\mathrm{erfi}(x)`.\nThe imaginary error function is defined in analogy with the\nerror function, but with a positive sign in the integrand:\n\n.. math ::\n\n  \\mathrm{erfi}(x) = \\frac{2}{\\sqrt \\pi} \\int_0^x \\exp(t^2) \\,dt\n\nWhereas the error function rapidly converges to 1 as `x` grows,\nthe imaginary error function rapidly diverges to infinity.\nThe functions are related as\n`\\mathrm{erfi}(x) = -i\\,\\mathrm{erf}(ix)` for all complex\nnumbers `x`.\n\n**Examples**\n\nBasic values and limits::\n\n    >>> from mpmath import *\n    >>> mp.dps = 15; mp.pretty = True\n    >>> erfi(0)\n    0.0\n    >>> erfi(1)\n    1.65042575879754\n    >>> erfi(-1)\n    -1.65042575879754\n    >>> erfi(inf)\n    +inf\n    >>> erfi(-inf)\n    -inf\n\nNote the symmetry between erf and erfi::\n\n    >>> erfi(3j)\n    (0.0 + 0.999977909503001j)\n    >>> erf(3)\n    0.999977909503001\n    >>> erf(1+2j)\n    (-0.536643565778565 - 5.04914370344703j)\n    >>> erfi(2+1j)\n    (-5.04914370344703 - 0.536643565778565j)\n\nLarge arguments are supported::\n\n    >>> erfi(1000)\n    1.71130938718796e+434291\n    >>> erfi(10**10)\n    7.3167287567024e+43429448190325182754\n    >>> erfi(-10**10)\n    -7.3167287567024e+43429448190325182754\n    >>> erfi(1000-500j)\n    (2.49895233563961e+325717 + 2.6846779342253e+325717j)\n    >>> erfi(100000j)\n    (0.0 + 1.0j)\n    >>> erfi(-100000j)\n    (0.0 - 1.0j)\n\n\n'
erfinv: str = '\nComputes the inverse error function, satisfying\n\n.. math ::\n\n    \\mathrm{erf}(\\mathrm{erfinv}(x)) =\n    \\mathrm{erfinv}(\\mathrm{erf}(x)) = x.\n\nThis function is defined only for `-1 \\le x \\le 1`.\n\n**Examples**\n\nSpecial values include::\n\n    >>> from mpmath import *\n    >>> mp.dps = 15; mp.pretty = True\n    >>> erfinv(0)\n    0.0\n    >>> erfinv(1)\n    +inf\n    >>> erfinv(-1)\n    -inf\n\nThe domain is limited to the standard interval::\n\n    >>> erfinv(2)\n    Traceback (most recent call last):\n      ...\n    ValueError: erfinv(x) is defined only for -1 <= x <= 1\n\nIt is simple to check that :func:`~mpmath.erfinv` computes inverse values of\n:func:`~mpmath.erf` as promised::\n\n    >>> erf(erfinv(0.75))\n    0.75\n    >>> erf(erfinv(-0.995))\n    -0.995\n\n:func:`~mpmath.erfinv` supports arbitrary-precision evaluation::\n\n    >>> mp.dps = 50\n    >>> x = erf(2)\n    >>> x\n    0.99532226501895273416206925636725292861089179704006\n    >>> erfinv(x)\n    2.0\n\nA definite integral involving the inverse error function::\n\n    >>> mp.dps = 15\n    >>> quad(erfinv, [0, 1])\n    0.564189583547756\n    >>> 1/sqrt(pi)\n    0.564189583547756\n\nThe inverse error function can be used to generate random numbers\nwith a Gaussian distribution (although this is a relatively\ninefficient algorithm)::\n\n    >>> nprint([erfinv(2*rand()-1) for n in range(6)]) # doctest: +SKIP\n    [-0.586747, 1.10233, -0.376796, 0.926037, -0.708142, -0.732012]\n\n'
euler: str = "\nEuler's constant or the Euler-Mascheroni constant `\\gamma`\n= 0.57721566... is a number of central importance to\nnumber theory and special functions. It is defined as the limit\n\n.. math ::\n\n    \\gamma = \\lim_{n\\to\\infty} H_n - \\log n\n\nwhere `H_n = 1 + \\frac{1}{2} + \\ldots + \\frac{1}{n}` is a harmonic\nnumber (see :func:`~mpmath.harmonic`).\n\nEvaluation of `\\gamma` is supported at arbitrary precision::\n\n    >>> from mpmath import *\n    >>> mp.dps = 50; mp.pretty = True\n    >>> +euler\n    0.57721566490153286060651209008240243104215933593992\n\nWe can also compute `\\gamma` directly from the definition,\nalthough this is less efficient::\n\n    >>> limit(lambda n: harmonic(n)-log(n), inf)\n    0.57721566490153286060651209008240243104215933593992\n\nThis shows digits 9991-10000 of `\\gamma` (the last digit is actually\na 5 when the decimal expansion is truncated, but here the nearest\nrounding is used)::\n\n    >>> mp.dps = 10000\n    >>> str(euler)[-10:]\n    '4679858166'\n\nIntegrals, series, and representations for `\\gamma` in terms of\nspecial functions include the following (there are many others)::\n\n    >>> mp.dps = 25\n    >>> -quad(lambda x: exp(-x)*log(x), [0,inf])\n    0.5772156649015328606065121\n    >>> quad(lambda x,y: (x-1)/(1-x*y)/log(x*y), [0,1], [0,1])\n    0.5772156649015328606065121\n    >>> nsum(lambda k: 1/k-log(1+1/k), [1,inf])\n    0.5772156649015328606065121\n    >>> nsum(lambda k: (-1)**k*zeta(k)/k, [2,inf])\n    0.5772156649015328606065121\n    >>> -diff(gamma, 1)\n    0.5772156649015328606065121\n    >>> limit(lambda x: 1/x-gamma(x), 0)\n    0.5772156649015328606065121\n    >>> limit(lambda x: zeta(x)-1/(x-1), 1)\n    0.5772156649015328606065121\n    >>> (log(2*pi*nprod(lambda n:\n    ...     exp(-2+2/n)*(1+2/n)**n, [1,inf]))-3)/2\n    0.5772156649015328606065121\n\nFor generalizations of the identities `\\gamma = -\\Gamma'(1)`\nand `\\gamma = \\lim_{x\\to1} \\zeta(x)-1/(x-1)`, see\n:func:`~mpmath.psi` and :func:`~mpmath.stieltjes` respectively.\n\n**References**\n\n* [BorweinBailey]_\n\n"
eulernum: str = '\nGives the `n`-th Euler number, defined as the `n`-th derivative of\n`\\mathrm{sech}(t) = 1/\\cosh(t)` evaluated at `t = 0`. Equivalently, the\nEuler numbers give the coefficients of the Taylor series\n\n.. math ::\n\n    \\mathrm{sech}(t) = \\sum_{n=0}^{\\infty} \\frac{E_n}{n!} t^n.\n\nThe Euler numbers are closely related to Bernoulli numbers\nand Bernoulli polynomials. They can also be evaluated in terms of\nEuler polynomials (see :func:`~mpmath.eulerpoly`) as `E_n = 2^n E_n(1/2)`.\n\n**Examples**\n\nComputing the first few Euler numbers and verifying that they\nagree with the Taylor series::\n\n    >>> from mpmath import *\n    >>> mp.dps = 25; mp.pretty = True\n    >>> [eulernum(n) for n in range(11)]\n    [1.0, 0.0, -1.0, 0.0, 5.0, 0.0, -61.0, 0.0, 1385.0, 0.0, -50521.0]\n    >>> chop(diffs(sech, 0, 10))\n    [1.0, 0.0, -1.0, 0.0, 5.0, 0.0, -61.0, 0.0, 1385.0, 0.0, -50521.0]\n\nEuler numbers grow very rapidly. :func:`~mpmath.eulernum` efficiently\ncomputes numerical approximations for large indices::\n\n    >>> eulernum(50)\n    -6.053285248188621896314384e+54\n    >>> eulernum(1000)\n    3.887561841253070615257336e+2371\n    >>> eulernum(10**20)\n    4.346791453661149089338186e+1936958564106659551331\n\nComparing with an asymptotic formula for the Euler numbers::\n\n    >>> n = 10**5\n    >>> (-1)**(n//2) * 8 * sqrt(n/(2*pi)) * (2*n/(pi*e))**n\n    3.69919063017432362805663e+436961\n    >>> eulernum(n)\n    3.699193712834466537941283e+436961\n\nPass ``exact=True`` to obtain exact values of Euler numbers as integers::\n\n    >>> print(eulernum(50, exact=True))\n    -6053285248188621896314383785111649088103498225146815121\n    >>> print(eulernum(200, exact=True) % 10**10)\n    1925859625\n    >>> eulernum(1001, exact=True)\n    0\n'
eulerpoly: str = "\nEvaluates the Euler polynomial `E_n(z)`, defined by the generating function\nrepresentation\n\n.. math ::\n\n    \\frac{2e^{zt}}{e^t+1} = \\sum_{n=0}^\\infty E_n(z) \\frac{t^n}{n!}.\n\nThe Euler polynomials may also be represented in terms of\nBernoulli polynomials (see :func:`~mpmath.bernpoly`) using various formulas, for\nexample\n\n.. math ::\n\n    E_n(z) = \\frac{2}{n+1} \\left(\n        B_n(z)-2^{n+1}B_n\\left(\\frac{z}{2}\\right)\n    \\right).\n\nSpecial values include the Euler numbers `E_n = 2^n E_n(1/2)` (see\n:func:`~mpmath.eulernum`).\n\n**Examples**\n\nComputing the coefficients of the first few Euler polynomials::\n\n    >>> from mpmath import *\n    >>> mp.dps = 25; mp.pretty = True\n    >>> for n in range(6):\n    ...     chop(taylor(lambda z: eulerpoly(n,z), 0, n))\n    ...\n    [1.0]\n    [-0.5, 1.0]\n    [0.0, -1.0, 1.0]\n    [0.25, 0.0, -1.5, 1.0]\n    [0.0, 1.0, 0.0, -2.0, 1.0]\n    [-0.5, 0.0, 2.5, 0.0, -2.5, 1.0]\n\nEvaluation for arbitrary `z`::\n\n    >>> eulerpoly(2,3)\n    6.0\n    >>> eulerpoly(5,4)\n    423.5\n    >>> eulerpoly(35, 11111111112)\n    3.994957561486776072734601e+351\n    >>> eulerpoly(4, 10+20j)\n    (-47990.0 - 235980.0j)\n    >>> eulerpoly(2, '-3.5e-5')\n    0.000035001225\n    >>> eulerpoly(3, 0.5)\n    0.0\n    >>> eulerpoly(55, -10**80)\n    -1.0e+4400\n    >>> eulerpoly(5, -inf)\n    -inf\n    >>> eulerpoly(6, -inf)\n    +inf\n\nComputing Euler numbers::\n\n    >>> 2**26 * eulerpoly(26,0.5)\n    -4087072509293123892361.0\n    >>> eulernum(26)\n    -4087072509293123892361.0\n\nEvaluation is accurate for large `n` and small `z`::\n\n    >>> eulerpoly(100, 0.5)\n    2.29047999988194114177943e+108\n    >>> eulerpoly(1000, 10.5)\n    3.628120031122876847764566e+2070\n    >>> eulerpoly(10000, 10.5)\n    1.149364285543783412210773e+30688\n"
exp: str = "\nComputes the exponential function,\n\n.. math ::\n\n    \\exp(x) = e^x = \\sum_{k=0}^{\\infty} \\frac{x^k}{k!}.\n\nFor complex numbers, the exponential function also satisfies\n\n.. math ::\n\n    \\exp(x+yi) = e^x (\\cos y + i \\sin y).\n\n**Basic examples**\n\nSome values of the exponential function::\n\n    >>> from mpmath import *\n    >>> mp.dps = 25; mp.pretty = True\n    >>> exp(0)\n    1.0\n    >>> exp(1)\n    2.718281828459045235360287\n    >>> exp(-1)\n    0.3678794411714423215955238\n    >>> exp(inf)\n    +inf\n    >>> exp(-inf)\n    0.0\n\nArguments can be arbitrarily large::\n\n    >>> exp(10000)\n    8.806818225662921587261496e+4342\n    >>> exp(-10000)\n    1.135483865314736098540939e-4343\n\nEvaluation is supported for interval arguments via\n:func:`mpmath.iv.exp`::\n\n    >>> iv.dps = 25; iv.pretty = True\n    >>> iv.exp([-inf,0])\n    [0.0, 1.0]\n    >>> iv.exp([0,1])\n    [1.0, 2.71828182845904523536028749558]\n\nThe exponential function can be evaluated efficiently to arbitrary\nprecision::\n\n    >>> mp.dps = 10000\n    >>> exp(pi)  #doctest: +ELLIPSIS\n    23.140692632779269005729...8984304016040616\n\n**Functional properties**\n\nNumerical verification of Euler's identity for the complex\nexponential function::\n\n    >>> mp.dps = 15\n    >>> exp(j*pi)+1\n    (0.0 + 1.22464679914735e-16j)\n    >>> chop(exp(j*pi)+1)\n    0.0\n\nThis recovers the coefficients (reciprocal factorials) in the\nMaclaurin series expansion of exp::\n\n    >>> nprint(taylor(exp, 0, 5))\n    [1.0, 1.0, 0.5, 0.166667, 0.0416667, 0.00833333]\n\nThe exponential function is its own derivative and antiderivative::\n\n    >>> exp(pi)\n    23.1406926327793\n    >>> diff(exp, pi)\n    23.1406926327793\n    >>> quad(exp, [-inf, pi])\n    23.1406926327793\n\nThe exponential function can be evaluated using various methods,\nincluding direct summation of the series, limits, and solving\nthe defining differential equation::\n\n    >>> nsum(lambda k: pi**k/fac(k), [0,inf])\n    23.1406926327793\n    >>> limit(lambda k: (1+pi/k)**k, inf)\n    23.1406926327793\n    >>> odefun(lambda t, x: x, 0, 1)(pi)\n    23.1406926327793\n"
expint: str = '\n:func:`~mpmath.expint(n,z)` gives the generalized exponential integral\nor En-function,\n\n.. math ::\n\n    \\mathrm{E}_n(z) = \\int_1^{\\infty} \\frac{e^{-zt}}{t^n} dt,\n\nwhere `n` and `z` may both be complex numbers. The case with `n = 1` is\nalso given by :func:`~mpmath.e1`.\n\n**Examples**\n\nEvaluation at real and complex arguments::\n\n    >>> from mpmath import *\n    >>> mp.dps = 25; mp.pretty = True\n    >>> expint(1, 6.25)\n    0.0002704758872637179088496194\n    >>> expint(-3, 2+3j)\n    (0.00299658467335472929656159 + 0.06100816202125885450319632j)\n    >>> expint(2+3j, 4-5j)\n    (0.001803529474663565056945248 - 0.002235061547756185403349091j)\n\nAt negative integer values of `n`, `E_n(z)` reduces to a\nrational-exponential function::\n\n    >>> f = lambda n, z: fac(n)*sum(z**k/fac(k-1) for k in range(1,n+2))/\\\n    ...     exp(z)/z**(n+2)\n    >>> n = 3\n    >>> z = 1/pi\n    >>> expint(-n,z)\n    584.2604820613019908668219\n    >>> f(n,z)\n    584.2604820613019908668219\n    >>> n = 5\n    >>> expint(-n,z)\n    115366.5762594725451811138\n    >>> f(n,z)\n    115366.5762594725451811138\n'
expj: str = '\nConvenience function for computing `e^{ix}`::\n\n    >>> from mpmath import *\n    >>> mp.dps = 25; mp.pretty = True\n    >>> expj(0)\n    (1.0 + 0.0j)\n    >>> expj(-1)\n    (0.5403023058681397174009366 - 0.8414709848078965066525023j)\n    >>> expj(j)\n    (0.3678794411714423215955238 + 0.0j)\n    >>> expj(1+j)\n    (0.1987661103464129406288032 + 0.3095598756531121984439128j)\n'
expjpi: str = '\nConvenience function for computing `e^{i \\pi x}`.\nEvaluation is accurate near zeros (see also :func:`~mpmath.cospi`,\n:func:`~mpmath.sinpi`)::\n\n    >>> from mpmath import *\n    >>> mp.dps = 25; mp.pretty = True\n    >>> expjpi(0)\n    (1.0 + 0.0j)\n    >>> expjpi(1)\n    (-1.0 + 0.0j)\n    >>> expjpi(0.5)\n    (0.0 + 1.0j)\n    >>> expjpi(-1)\n    (-1.0 + 0.0j)\n    >>> expjpi(j)\n    (0.04321391826377224977441774 + 0.0j)\n    >>> expjpi(1+j)\n    (-0.04321391826377224977441774 + 0.0j)\n'
expm1: str = "\nComputes `e^x - 1`, accurately for small `x`.\n\nUnlike the expression ``exp(x) - 1``, ``expm1(x)`` does not suffer from\npotentially catastrophic cancellation::\n\n    >>> from mpmath import *\n    >>> mp.dps = 15; mp.pretty = True\n    >>> exp(1e-10)-1; print(expm1(1e-10))\n    1.00000008274037e-10\n    1.00000000005e-10\n    >>> exp(1e-20)-1; print(expm1(1e-20))\n    0.0\n    1.0e-20\n    >>> 1/(exp(1e-20)-1)\n    Traceback (most recent call last):\n      ...\n    ZeroDivisionError\n    >>> 1/expm1(1e-20)\n    1.0e+20\n\nEvaluation works for extremely tiny values::\n\n    >>> expm1(0)\n    0.0\n    >>> expm1('1e-10000000')\n    1.0e-10000000\n\n"
fabs: str = "\nReturns the absolute value of `x`, `|x|`. Unlike :func:`abs`,\n:func:`~mpmath.fabs` converts non-mpmath numbers (such as ``int``)\ninto mpmath numbers::\n\n    >>> from mpmath import *\n    >>> mp.dps = 15; mp.pretty = False\n    >>> fabs(3)\n    mpf('3.0')\n    >>> fabs(-3)\n    mpf('3.0')\n    >>> fabs(3+4j)\n    mpf('5.0')\n"
fac2: str = "\nComputes the double factorial `x!!`, defined for integers\n`x > 0` by\n\n.. math ::\n\n    x!! = \\begin{cases}\n        1 \\cdot 3 \\cdots (x-2) \\cdot x & x \\;\\mathrm{odd} \\\\\n        2 \\cdot 4 \\cdots (x-2) \\cdot x & x \\;\\mathrm{even}\n    \\end{cases}\n\nand more generally by [1]\n\n.. math ::\n\n    x!! = 2^{x/2} \\left(\\frac{\\pi}{2}\\right)^{(\\cos(\\pi x)-1)/4}\n          \\Gamma\\left(\\frac{x}{2}+1\\right).\n\n**Examples**\n\nThe integer sequence of double factorials begins::\n\n    >>> from mpmath import *\n    >>> mp.dps = 15; mp.pretty = True\n    >>> nprint([fac2(n) for n in range(10)])\n    [1.0, 1.0, 2.0, 3.0, 8.0, 15.0, 48.0, 105.0, 384.0, 945.0]\n\nFor large `x`, double factorials follow a Stirling-like asymptotic\napproximation::\n\n    >>> x = mpf(10000)\n    >>> fac2(x)\n    5.97272691416282e+17830\n    >>> sqrt(pi)*x**((x+1)/2)*exp(-x/2)\n    5.97262736954392e+17830\n\nThe recurrence formula `x!! = x (x-2)!!` can be reversed to\ndefine the double factorial of negative odd integers (but\nnot negative even integers)::\n\n    >>> fac2(-1), fac2(-3), fac2(-5), fac2(-7)\n    (1.0, -1.0, 0.333333333333333, -0.0666666666666667)\n    >>> fac2(-2)\n    Traceback (most recent call last):\n      ...\n    ValueError: gamma function pole\n\nWith the exception of the poles at negative even integers,\n:func:`~mpmath.fac2` supports evaluation for arbitrary complex arguments.\nThe recurrence formula is valid generally::\n\n    >>> fac2(pi+2j)\n    (-1.3697207890154e-12 + 3.93665300979176e-12j)\n    >>> (pi+2j)*fac2(pi-2+2j)\n    (-1.3697207890154e-12 + 3.93665300979176e-12j)\n\nDouble factorials should not be confused with nested factorials,\nwhich are immensely larger::\n\n    >>> fac(fac(20))\n    5.13805976125208e+43675043585825292774\n    >>> fac2(20)\n    3715891200.0\n\nDouble factorials appear, among other things, in series expansions\nof Gaussian functions and the error function. Infinite series\ninclude::\n\n    >>> nsum(lambda k: 1/fac2(k), [0, inf])\n    3.05940740534258\n    >>> sqrt(e)*(1+sqrt(pi/2)*erf(sqrt(2)/2))\n    3.05940740534258\n    >>> nsum(lambda k: 2**k/fac2(2*k-1), [1, inf])\n    4.06015693855741\n    >>> e * erf(1) * sqrt(pi)\n    4.06015693855741\n\nA beautiful Ramanujan sum::\n\n    >>> nsum(lambda k: (-1)**k*(fac2(2*k-1)/fac2(2*k))**3, [0,inf])\n    0.90917279454693\n    >>> (gamma('9/8')/gamma('5/4')/gamma('7/8'))**2\n    0.90917279454693\n\n**References**\n\n1. http://functions.wolfram.com/GammaBetaErf/Factorial2/27/01/0002/\n\n2. http://mathworld.wolfram.com/DoubleFactorial.html\n\n"
factorial: str = '\nComputes the factorial, `x!`. For integers `n \\ge 0`, we have\n`n! = 1 \\cdot 2 \\cdots (n-1) \\cdot n` and more generally the factorial\nis defined for real or complex `x` by `x! = \\Gamma(x+1)`.\n\n**Examples**\n\nBasic values and limits::\n\n    >>> from mpmath import *\n    >>> mp.dps = 15; mp.pretty = True\n    >>> for k in range(6):\n    ...     print("%s %s" % (k, fac(k)))\n    ...\n    0 1.0\n    1 1.0\n    2 2.0\n    3 6.0\n    4 24.0\n    5 120.0\n    >>> fac(inf)\n    +inf\n    >>> fac(0.5), sqrt(pi)/2\n    (0.886226925452758, 0.886226925452758)\n\nFor large positive `x`, `x!` can be approximated by\nStirling\'s formula::\n\n    >>> x = 10**10\n    >>> fac(x)\n    2.32579620567308e+95657055186\n    >>> sqrt(2*pi*x)*(x/e)**x\n    2.32579597597705e+95657055186\n\n:func:`~mpmath.fac` supports evaluation for astronomically large values::\n\n    >>> fac(10**30)\n    6.22311232304258e+29565705518096748172348871081098\n\nReciprocal factorials appear in the Taylor series of the\nexponential function (among many other contexts)::\n\n    >>> nsum(lambda k: 1/fac(k), [0, inf]), exp(1)\n    (2.71828182845905, 2.71828182845905)\n    >>> nsum(lambda k: pi**k/fac(k), [0, inf]), exp(pi)\n    (23.1406926327793, 23.1406926327793)\n\n'
ff: str = '\nComputes the falling factorial,\n\n.. math ::\n\n    (x)_n = x (x-1) \\cdots (x-n+1) = \\frac{\\Gamma(x+1)}{\\Gamma(x-n+1)}\n\nwhere the rightmost expression is valid for nonintegral `n`.\n\n**Examples**\n\nFor integral `n`, the falling factorial is a polynomial::\n\n    >>> from mpmath import *\n    >>> mp.dps = 15; mp.pretty = True\n    >>> for n in range(5):\n    ...     nprint(taylor(lambda x: ff(x,n), 0, n))\n    ...\n    [1.0]\n    [0.0, 1.0]\n    [0.0, -1.0, 1.0]\n    [0.0, 2.0, -3.0, 1.0]\n    [0.0, -6.0, 11.0, -6.0, 1.0]\n\nEvaluation is supported for arbitrary arguments::\n\n    >>> ff(2+3j, 5.5)\n    (-720.41085888203 + 316.101124983878j)\n'
fibonacci: str = '\n``fibonacci(n)`` computes the `n`-th Fibonacci number, `F(n)`. The\nFibonacci numbers are defined by the recurrence `F(n) = F(n-1) + F(n-2)`\nwith the initial values `F(0) = 0`, `F(1) = 1`. :func:`~mpmath.fibonacci`\nextends this definition to arbitrary real and complex arguments\nusing the formula\n\n.. math ::\n\n  F(z) = \\frac{\\phi^z - \\cos(\\pi z) \\phi^{-z}}{\\sqrt 5}\n\nwhere `\\phi` is the golden ratio. :func:`~mpmath.fibonacci` also uses this\ncontinuous formula to compute `F(n)` for extremely large `n`, where\ncalculating the exact integer would be wasteful.\n\nFor convenience, :func:`~mpmath.fib` is available as an alias for\n:func:`~mpmath.fibonacci`.\n\n**Basic examples**\n\nSome small Fibonacci numbers are::\n\n    >>> from mpmath import *\n    >>> mp.dps = 15; mp.pretty = True\n    >>> for i in range(10):\n    ...     print(fibonacci(i))\n    ...\n    0.0\n    1.0\n    1.0\n    2.0\n    3.0\n    5.0\n    8.0\n    13.0\n    21.0\n    34.0\n    >>> fibonacci(50)\n    12586269025.0\n\nThe recurrence for `F(n)` extends backwards to negative `n`::\n\n    >>> for i in range(10):\n    ...     print(fibonacci(-i))\n    ...\n    0.0\n    1.0\n    -1.0\n    2.0\n    -3.0\n    5.0\n    -8.0\n    13.0\n    -21.0\n    34.0\n\nLarge Fibonacci numbers will be computed approximately unless\nthe precision is set high enough::\n\n    >>> fib(200)\n    2.8057117299251e+41\n    >>> mp.dps = 45\n    >>> fib(200)\n    280571172992510140037611932413038677189525.0\n\n:func:`~mpmath.fibonacci` can compute approximate Fibonacci numbers\nof stupendous size::\n\n    >>> mp.dps = 15\n    >>> fibonacci(10**25)\n    3.49052338550226e+2089876402499787337692720\n\n**Real and complex arguments**\n\nThe extended Fibonacci function is an analytic function. The\nproperty `F(z) = F(z-1) + F(z-2)` holds for arbitrary `z`::\n\n    >>> mp.dps = 15\n    >>> fib(pi)\n    2.1170270579161\n    >>> fib(pi-1) + fib(pi-2)\n    2.1170270579161\n    >>> fib(3+4j)\n    (-5248.51130728372 - 14195.962288353j)\n    >>> fib(2+4j) + fib(1+4j)\n    (-5248.51130728372 - 14195.962288353j)\n\nThe Fibonacci function has infinitely many roots on the\nnegative half-real axis. The first root is at 0, the second is\nclose to -0.18, and then there are infinitely many roots that\nasymptotically approach `-n+1/2`::\n\n    >>> findroot(fib, -0.2)\n    -0.183802359692956\n    >>> findroot(fib, -2)\n    -1.57077646820395\n    >>> findroot(fib, -17)\n    -16.4999999596115\n    >>> findroot(fib, -24)\n    -23.5000000000479\n\n**Mathematical relationships**\n\nFor large `n`, `F(n+1)/F(n)` approaches the golden ratio::\n\n    >>> mp.dps = 50\n    >>> fibonacci(101)/fibonacci(100)\n    1.6180339887498948482045868343656381177203127439638\n    >>> +phi\n    1.6180339887498948482045868343656381177203091798058\n\nThe sum of reciprocal Fibonacci numbers converges to an irrational\nnumber for which no closed form expression is known::\n\n    >>> mp.dps = 15\n    >>> nsum(lambda n: 1/fib(n), [1, inf])\n    3.35988566624318\n\nAmazingly, however, the sum of odd-index reciprocal Fibonacci\nnumbers can be expressed in terms of a Jacobi theta function::\n\n    >>> nsum(lambda n: 1/fib(2*n+1), [0, inf])\n    1.82451515740692\n    >>> sqrt(5)*jtheta(2,0,(3-sqrt(5))/2)**2/4\n    1.82451515740692\n\nSome related sums can be done in closed form::\n\n    >>> nsum(lambda k: 1/(1+fib(2*k+1)), [0, inf])\n    1.11803398874989\n    >>> phi - 0.5\n    1.11803398874989\n    >>> f = lambda k:(-1)**(k+1) / sum(fib(n)**2 for n in range(1,int(k+1)))\n    >>> nsum(f, [1, inf])\n    0.618033988749895\n    >>> phi-1\n    0.618033988749895\n\n**References**\n\n1. http://mathworld.wolfram.com/FibonacciNumber.html\n'
floor: str = "\nComputes the floor of `x`, `\\lfloor x \\rfloor`, defined as\nthe largest integer less than or equal to `x`::\n\n    >>> from mpmath import *\n    >>> mp.pretty = False\n    >>> floor(3.5)\n    mpf('3.0')\n\n.. note ::\n\n    :func:`~mpmath.floor`, :func:`~mpmath.ceil` and :func:`~mpmath.nint` return a\n    floating-point number, not a Python ``int``. If `\\lfloor x \\rfloor` is\n    too large to be represented exactly at the present working precision,\n    the result will be rounded, not necessarily in the direction\n    implied by the mathematical definition of the function.\n\nTo avoid rounding, use *prec=0*::\n\n    >>> mp.dps = 15\n    >>> print(int(floor(10**30+1)))\n    1000000000000000019884624838656\n    >>> print(int(floor(10**30+1, prec=0)))\n    1000000000000000000000000000001\n\nThe floor function is defined for complex numbers and\nacts on the real and imaginary parts separately::\n\n    >>> floor(3.25+4.75j)\n    mpc(real='3.0', imag='4.0')\n"
fmod: str = '\nConverts `x` and `y` to mpmath numbers and returns `x \\mod y`.\nFor mpmath numbers, this is equivalent to ``x % y``.\n\n    >>> from mpmath import *\n    >>> mp.dps = 15; mp.pretty = True\n    >>> fmod(100, pi)\n    2.61062773871641\n\nYou can use :func:`~mpmath.fmod` to compute fractional parts of numbers::\n\n    >>> fmod(10.25, 1)\n    0.25\n\n'
frac: str = "\nGives the fractional part of `x`, defined as\n`\\mathrm{frac}(x) = x - \\lfloor x \\rfloor` (see :func:`~mpmath.floor`).\nIn effect, this computes `x` modulo 1, or `x+n` where\n`n \\in \\mathbb{Z}` is such that `x+n \\in [0,1)`::\n\n    >>> from mpmath import *\n    >>> mp.pretty = False\n    >>> frac(1.25)\n    mpf('0.25')\n    >>> frac(3)\n    mpf('0.0')\n    >>> frac(-1.25)\n    mpf('0.75')\n\nFor a complex number, the fractional part function applies to\nthe real and imaginary parts separately::\n\n    >>> frac(2.25+3.75j)\n    mpc(real='0.25', imag='0.75')\n\nPlotted, the fractional part function gives a sawtooth\nwave. The Fourier series coefficients have a simple\nform::\n\n    >>> mp.dps = 15\n    >>> nprint(fourier(lambda x: frac(x)-0.5, [0,1], 4))\n    ([0.0, 0.0, 0.0, 0.0, 0.0], [0.0, -0.31831, -0.159155, -0.106103, -0.0795775])\n    >>> nprint([-1/(pi*k) for k in range(1,5)])\n    [-0.31831, -0.159155, -0.106103, -0.0795775]\n\n.. note::\n\n    The fractional part is sometimes defined as a symmetric\n    function, i.e. returning `-\\mathrm{frac}(-x)` if `x < 0`.\n    This convention is used, for instance, by Mathematica's\n    ``FractionalPart``.\n\n"
fresnelc: str = '\nComputes the Fresnel cosine integral\n\n.. math ::\n\n    C(x) = \\int_0^x \\cos\\left(\\frac{\\pi t^2}{2}\\right) \\,dt\n\nNote that some sources define this function\nwithout the normalization factor `\\pi/2`.\n\n**Examples**\n\nSome basic values and limits::\n\n    >>> from mpmath import *\n    >>> mp.dps = 25; mp.pretty = True\n    >>> fresnelc(0)\n    0.0\n    >>> fresnelc(inf)\n    0.5\n    >>> fresnelc(-inf)\n    -0.5\n    >>> fresnelc(1)\n    0.7798934003768228294742064\n    >>> fresnelc(1+2j)\n    (16.08787137412548041729489 - 36.22568799288165021578758j)\n\nComparing with the definition::\n\n    >>> fresnelc(3)\n    0.6057207892976856295561611\n    >>> quad(lambda t: cos(pi*t**2/2), [0,3])\n    0.6057207892976856295561611\n'
fresnels: str = '\nComputes the Fresnel sine integral\n\n.. math ::\n\n    S(x) = \\int_0^x \\sin\\left(\\frac{\\pi t^2}{2}\\right) \\,dt\n\nNote that some sources define this function\nwithout the normalization factor `\\pi/2`.\n\n**Examples**\n\nSome basic values and limits::\n\n    >>> from mpmath import *\n    >>> mp.dps = 25; mp.pretty = True\n    >>> fresnels(0)\n    0.0\n    >>> fresnels(inf)\n    0.5\n    >>> fresnels(-inf)\n    -0.5\n    >>> fresnels(1)\n    0.4382591473903547660767567\n    >>> fresnels(1+2j)\n    (36.72546488399143842838788 + 15.58775110440458732748279j)\n\nComparing with the definition::\n\n    >>> fresnels(3)\n    0.4963129989673750360976123\n    >>> quad(lambda t: sin(pi*t**2/2), [0,3])\n    0.4963129989673750360976123\n'
gamma: str = '\nComputes the gamma function, `\\Gamma(x)`. The gamma function is a\nshifted version of the ordinary factorial, satisfying\n`\\Gamma(n) = (n-1)!` for integers `n > 0`. More generally, it\nis defined by\n\n.. math ::\n\n    \\Gamma(x) = \\int_0^{\\infty} t^{x-1} e^{-t}\\, dt\n\nfor any real or complex `x` with `\\Re(x) > 0` and for `\\Re(x) < 0`\nby analytic continuation.\n\n**Examples**\n\nBasic values and limits::\n\n    >>> from mpmath import *\n    >>> mp.dps = 15; mp.pretty = True\n    >>> for k in range(1, 6):\n    ...     print("%s %s" % (k, gamma(k)))\n    ...\n    1 1.0\n    2 1.0\n    3 2.0\n    4 6.0\n    5 24.0\n    >>> gamma(inf)\n    +inf\n    >>> gamma(0)\n    Traceback (most recent call last):\n      ...\n    ValueError: gamma function pole\n\nThe gamma function of a half-integer is a rational multiple of\n`\\sqrt{\\pi}`::\n\n    >>> gamma(0.5), sqrt(pi)\n    (1.77245385090552, 1.77245385090552)\n    >>> gamma(1.5), sqrt(pi)/2\n    (0.886226925452758, 0.886226925452758)\n\nWe can check the integral definition::\n\n    >>> gamma(3.5)\n    3.32335097044784\n    >>> quad(lambda t: t**2.5*exp(-t), [0,inf])\n    3.32335097044784\n\n:func:`~mpmath.gamma` supports arbitrary-precision evaluation and\ncomplex arguments::\n\n    >>> mp.dps = 50\n    >>> gamma(sqrt(3))\n    0.91510229697308632046045539308226554038315280564184\n    >>> mp.dps = 25\n    >>> gamma(2j)\n    (0.009902440080927490985955066 - 0.07595200133501806872408048j)\n\nArguments can also be large. Note that the gamma function grows\nvery quickly::\n\n    >>> mp.dps = 15\n    >>> gamma(10**20)\n    1.9328495143101e+1956570551809674817225\n\n**References**\n\n* [Spouge]_\n\n'
gammainc: str = '\n``gammainc(z, a=0, b=inf)`` computes the (generalized) incomplete\ngamma function with integration limits `[a, b]`:\n\n.. math ::\n\n  \\Gamma(z,a,b) = \\int_a^b t^{z-1} e^{-t} \\, dt\n\nThe generalized incomplete gamma function reduces to the\nfollowing special cases when one or both endpoints are fixed:\n\n* `\\Gamma(z,0,\\infty)` is the standard ("complete")\n  gamma function, `\\Gamma(z)` (available directly\n  as the mpmath function :func:`~mpmath.gamma`)\n* `\\Gamma(z,a,\\infty)` is the "upper" incomplete gamma\n  function, `\\Gamma(z,a)`\n* `\\Gamma(z,0,b)` is the "lower" incomplete gamma\n  function, `\\gamma(z,b)`.\n\nOf course, we have\n`\\Gamma(z,0,x) + \\Gamma(z,x,\\infty) = \\Gamma(z)`\nfor all `z` and `x`.\n\nNote however that some authors reverse the order of the\narguments when defining the lower and upper incomplete\ngamma function, so one should be careful to get the correct\ndefinition.\n\nIf also given the keyword argument ``regularized=True``,\n:func:`~mpmath.gammainc` computes the "regularized" incomplete gamma\nfunction\n\n.. math ::\n\n  P(z,a,b) = \\frac{\\Gamma(z,a,b)}{\\Gamma(z)}.\n\n**Examples**\n\nWe can compare with numerical quadrature to verify that\n:func:`~mpmath.gammainc` computes the integral in the definition::\n\n    >>> from mpmath import *\n    >>> mp.dps = 25; mp.pretty = True\n    >>> gammainc(2+3j, 4, 10)\n    (0.00977212668627705160602312 - 0.0770637306312989892451977j)\n    >>> quad(lambda t: t**(2+3j-1) * exp(-t), [4, 10])\n    (0.00977212668627705160602312 - 0.0770637306312989892451977j)\n\nArgument symmetries follow directly from the integral definition::\n\n    >>> gammainc(3, 4, 5) + gammainc(3, 5, 4)\n    0.0\n    >>> gammainc(3,0,2) + gammainc(3,2,4); gammainc(3,0,4)\n    1.523793388892911312363331\n    1.523793388892911312363331\n    >>> findroot(lambda z: gammainc(2,z,3), 1)\n    3.0\n\nEvaluation for arbitrarily large arguments::\n\n    >>> gammainc(10, 100)\n    4.083660630910611272288592e-26\n    >>> gammainc(10, 10000000000000000)\n    5.290402449901174752972486e-4342944819032375\n    >>> gammainc(3+4j, 1000000+1000000j)\n    (-1.257913707524362408877881e-434284 + 2.556691003883483531962095e-434284j)\n\nEvaluation of a generalized incomplete gamma function automatically chooses\nthe representation that gives a more accurate result, depending on which\nparameter is larger::\n\n    >>> gammainc(10000000, 3) - gammainc(10000000, 2)   # Bad\n    0.0\n    >>> gammainc(10000000, 2, 3)   # Good\n    1.755146243738946045873491e+4771204\n    >>> gammainc(2, 0, 100000001) - gammainc(2, 0, 100000000)   # Bad\n    0.0\n    >>> gammainc(2, 100000000, 100000001)   # Good\n    4.078258353474186729184421e-43429441\n\nThe incomplete gamma functions satisfy simple recurrence\nrelations::\n\n    >>> mp.dps = 25\n    >>> z, a = mpf(3.5), mpf(2)\n    >>> gammainc(z+1, a); z*gammainc(z,a) + a**z*exp(-a)\n    10.60130296933533459267329\n    10.60130296933533459267329\n    >>> gammainc(z+1,0,a); z*gammainc(z,0,a) - a**z*exp(-a)\n    1.030425427232114336470932\n    1.030425427232114336470932\n\nEvaluation at integers and poles::\n\n    >>> gammainc(-3, -4, -5)\n    (-0.2214577048967798566234192 + 0.0j)\n    >>> gammainc(-3, 0, 5)\n    +inf\n\nIf `z` is an integer, the recurrence reduces the incomplete gamma\nfunction to `P(a) \\exp(-a) + Q(b) \\exp(-b)` where `P` and\n`Q` are polynomials::\n\n    >>> gammainc(1, 2); exp(-2)\n    0.1353352832366126918939995\n    0.1353352832366126918939995\n    >>> mp.dps = 50\n    >>> identify(gammainc(6, 1, 2), [\'exp(-1)\', \'exp(-2)\'])\n    \'(326*exp(-1) + (-872)*exp(-2))\'\n\nThe incomplete gamma functions reduce to functions such as\nthe exponential integral Ei and the error function for special\narguments::\n\n    >>> mp.dps = 25\n    >>> gammainc(0, 4); -ei(-4)\n    0.00377935240984890647887486\n    0.00377935240984890647887486\n    >>> gammainc(0.5, 0, 2); sqrt(pi)*erf(sqrt(2))\n    1.691806732945198336509541\n    1.691806732945198336509541\n\n'
gammaprod: str = '\nGiven iterables `a` and `b`, ``gammaprod(a, b)`` computes the\nproduct / quotient of gamma functions:\n\n.. math ::\n\n    \\frac{\\Gamma(a_0) \\Gamma(a_1) \\cdots \\Gamma(a_p)}\n         {\\Gamma(b_0) \\Gamma(b_1) \\cdots \\Gamma(b_q)}\n\nUnlike direct calls to :func:`~mpmath.gamma`, :func:`~mpmath.gammaprod` considers\nthe entire product as a limit and evaluates this limit properly if\nany of the numerator or denominator arguments are nonpositive\nintegers such that poles of the gamma function are encountered.\nThat is, :func:`~mpmath.gammaprod` evaluates\n\n.. math ::\n\n    \\lim_{\\epsilon \\to 0}\n    \\frac{\\Gamma(a_0+\\epsilon) \\Gamma(a_1+\\epsilon) \\cdots\n        \\Gamma(a_p+\\epsilon)}\n         {\\Gamma(b_0+\\epsilon) \\Gamma(b_1+\\epsilon) \\cdots\n        \\Gamma(b_q+\\epsilon)}\n\nIn particular:\n\n* If there are equally many poles in the numerator and the\n  denominator, the limit is a rational number times the remaining,\n  regular part of the product.\n\n* If there are more poles in the numerator, :func:`~mpmath.gammaprod`\n  returns ``+inf``.\n\n* If there are more poles in the denominator, :func:`~mpmath.gammaprod`\n  returns 0.\n\n**Examples**\n\nThe reciprocal gamma function `1/\\Gamma(x)` evaluated at `x = 0`::\n\n    >>> from mpmath import *\n    >>> mp.dps = 15\n    >>> gammaprod([], [0])\n    0.0\n\nA limit::\n\n    >>> gammaprod([-4], [-3])\n    -0.25\n    >>> limit(lambda x: gamma(x-1)/gamma(x), -3, direction=1)\n    -0.25\n    >>> limit(lambda x: gamma(x-1)/gamma(x), -3, direction=-1)\n    -0.25\n\n'
gegenbauer: str = '\nEvaluates the Gegenbauer polynomial, or ultraspherical polynomial,\n\n.. math ::\n\n    C_n^{(a)}(z) = {n+2a-1 \\choose n} \\,_2F_1\\left(-n, n+2a;\n        a+\\frac{1}{2}; \\frac{1}{2}(1-z)\\right).\n\nWhen `n` is a nonnegative integer, this formula gives a polynomial\nin `z` of degree `n`, but all parameters are permitted to be\ncomplex numbers. With `a = 1/2`, the Gegenbauer polynomial\nreduces to a Legendre polynomial.\n\n**Examples**\n\nEvaluation for arbitrary arguments::\n\n    >>> from mpmath import *\n    >>> mp.dps = 25; mp.pretty = True\n    >>> gegenbauer(3, 0.5, -10)\n    -2485.0\n    >>> gegenbauer(1000, 10, 100)\n    3.012757178975667428359374e+2322\n    >>> gegenbauer(2+3j, -0.75, -1000j)\n    (-5038991.358609026523401901 + 9414549.285447104177860806j)\n\nEvaluation at negative integer orders::\n\n    >>> gegenbauer(-4, 2, 1.75)\n    -1.0\n    >>> gegenbauer(-4, 3, 1.75)\n    0.0\n    >>> gegenbauer(-4, 2j, 1.75)\n    0.0\n    >>> gegenbauer(-7, 0.5, 3)\n    8989.0\n\nThe Gegenbauer polynomials solve the differential equation::\n\n    >>> n, a = 4.5, 1+2j\n    >>> f = lambda z: gegenbauer(n, a, z)\n    >>> for z in [0, 0.75, -0.5j]:\n    ...     chop((1-z**2)*diff(f,z,2) - (2*a+1)*z*diff(f,z) + n*(n+2*a)*f(z))\n    ...\n    0.0\n    0.0\n    0.0\n\nThe Gegenbauer polynomials have generating function\n`(1-2zt+t^2)^{-a}`::\n\n    >>> a, z = 2.5, 1\n    >>> taylor(lambda t: (1-2*z*t+t**2)**(-a), 0, 3)\n    [1.0, 5.0, 15.0, 35.0]\n    >>> [gegenbauer(n,a,z) for n in range(4)]\n    [1.0, 5.0, 15.0, 35.0]\n\nThe Gegenbauer polynomials are orthogonal on `[-1, 1]` with respect\nto the weight `(1-z^2)^{a-\\frac{1}{2}}`::\n\n    >>> a, n, m = 2.5, 4, 5\n    >>> Cn = lambda z: gegenbauer(n, a, z, zeroprec=1000)\n    >>> Cm = lambda z: gegenbauer(m, a, z, zeroprec=1000)\n    >>> chop(quad(lambda z: Cn(z)*Cm(z)*(1-z**2)*(a-0.5), [-1, 1]))\n    0.0\n'
glaisher: str = "\nGlaisher's constant `A`, also known as the Glaisher-Kinkelin\nconstant, is a number approximately equal to 1.282427129 that\nsometimes appears in formulas related to gamma and zeta functions.\nIt is also related to the Barnes G-function (see :func:`~mpmath.barnesg`).\n\nThe constant is defined  as `A = \\exp(1/12-\\zeta'(-1))` where\n`\\zeta'(s)` denotes the derivative of the Riemann zeta function\n(see :func:`~mpmath.zeta`).\n\nMpmath can evaluate Glaisher's constant to arbitrary precision:\n\n    >>> from mpmath import *\n    >>> mp.dps = 50; mp.pretty = True\n    >>> +glaisher\n    1.282427129100622636875342568869791727767688927325\n\nWe can verify that the value computed by :data:`glaisher` is\ncorrect using mpmath's facilities for numerical\ndifferentiation and arbitrary evaluation of the zeta function:\n\n    >>> exp(mpf(1)/12 - diff(zeta, -1))\n    1.282427129100622636875342568869791727767688927325\n\nHere is an example of an integral that can be evaluated in\nterms of Glaisher's constant:\n\n    >>> mp.dps = 15\n    >>> quad(lambda x: log(gamma(x)), [1, 1.5])\n    -0.0428537406502909\n    >>> -0.5 - 7*log(2)/24 + log(pi)/4 + 3*log(glaisher)/2\n    -0.042853740650291\n\nMpmath computes Glaisher's constant by applying Euler-Maclaurin\nsummation to a slowly convergent series. The implementation is\nreasonably efficient up to about 10,000 digits. See the source\ncode for additional details.\n\nReferences:\nhttp://mathworld.wolfram.com/Glaisher-KinkelinConstant.html\n"
grampoint: str = '\nGives the `n`-th Gram point `g_n`, defined as the solution\nto the equation `\\theta(g_n) = \\pi n` where `\\theta(t)`\nis the Riemann-Siegel theta function (:func:`~mpmath.siegeltheta`).\n\nThe first few Gram points are::\n\n    >>> from mpmath import *\n    >>> mp.dps = 25; mp.pretty = True\n    >>> grampoint(0)\n    17.84559954041086081682634\n    >>> grampoint(1)\n    23.17028270124630927899664\n    >>> grampoint(2)\n    27.67018221781633796093849\n    >>> grampoint(3)\n    31.71797995476405317955149\n\nChecking the definition::\n\n    >>> siegeltheta(grampoint(3))\n    9.42477796076937971538793\n    >>> 3*pi\n    9.42477796076937971538793\n\nA large Gram point::\n\n    >>> grampoint(10**10)\n    3293531632.728335454561153\n\nGram points are useful when studying the Z-function\n(:func:`~mpmath.siegelz`). See the documentation of that function\nfor additional examples.\n\n:func:`~mpmath.grampoint` can solve the defining equation for\nnonintegral `n`. There is a fixed point where `g(x) = x`::\n\n    >>> findroot(lambda x: grampoint(x) - x, 10000)\n    9146.698193171459265866198\n\n**References**\n\n1. http://mathworld.wolfram.com/GramPoint.html\n\n'
hankel1: str = '\n``hankel1(n,x)`` computes the Hankel function of the first kind,\nwhich is the complex combination of Bessel functions given by\n\n.. math ::\n\n    H_n^{(1)}(x) = J_n(x) + i Y_n(x).\n\n**Plots**\n\n.. literalinclude :: /plots/hankel1.py\n.. image :: /plots/hankel1.png\n.. literalinclude :: /plots/hankel1_c.py\n.. image :: /plots/hankel1_c.png\n\n**Examples**\n\nThe Hankel function is generally complex-valued::\n\n    >>> from mpmath import *\n    >>> mp.dps = 25; mp.pretty = True\n    >>> hankel1(2, pi)\n    (0.4854339326315091097054957 - 0.0999007139290278787734903j)\n    >>> hankel1(3.5, pi)\n    (0.2340002029630507922628888 - 0.6419643823412927142424049j)\n'
hankel2: str = '\n``hankel2(n,x)`` computes the Hankel function of the second kind,\nwhich is the complex combination of Bessel functions given by\n\n.. math ::\n\n    H_n^{(2)}(x) = J_n(x) - i Y_n(x).\n\n**Plots**\n\n.. literalinclude :: /plots/hankel2.py\n.. image :: /plots/hankel2.png\n.. literalinclude :: /plots/hankel2_c.py\n.. image :: /plots/hankel2_c.png\n\n**Examples**\n\nThe Hankel function is generally complex-valued::\n\n    >>> from mpmath import *\n    >>> mp.dps = 25; mp.pretty = True\n    >>> hankel2(2, pi)\n    (0.4854339326315091097054957 + 0.0999007139290278787734903j)\n    >>> hankel2(3.5, pi)\n    (0.2340002029630507922628888 + 0.6419643823412927142424049j)\n'
harmonic: str = '\nIf `n` is an integer, ``harmonic(n)`` gives a floating-point\napproximation of the `n`-th harmonic number `H(n)`, defined as\n\n.. math ::\n\n    H(n) = 1 + \\frac{1}{2} + \\frac{1}{3} + \\ldots + \\frac{1}{n}\n\nThe first few harmonic numbers are::\n\n    >>> from mpmath import *\n    >>> mp.dps = 15; mp.pretty = True\n    >>> for n in range(8):\n    ...     print("%s %s" % (n, harmonic(n)))\n    ...\n    0 0.0\n    1 1.0\n    2 1.5\n    3 1.83333333333333\n    4 2.08333333333333\n    5 2.28333333333333\n    6 2.45\n    7 2.59285714285714\n\nThe infinite harmonic series `1 + 1/2 + 1/3 + \\ldots` diverges::\n\n    >>> harmonic(inf)\n    +inf\n\n:func:`~mpmath.harmonic` is evaluated using the digamma function rather\nthan by summing the harmonic series term by term. It can therefore\nbe computed quickly for arbitrarily large `n`, and even for\nnonintegral arguments::\n\n    >>> harmonic(10**100)\n    230.835724964306\n    >>> harmonic(0.5)\n    0.613705638880109\n    >>> harmonic(3+4j)\n    (2.24757548223494 + 0.850502209186044j)\n\n:func:`~mpmath.harmonic` supports arbitrary precision evaluation::\n\n    >>> mp.dps = 50\n    >>> harmonic(11)\n    3.0198773448773448773448773448773448773448773448773\n    >>> harmonic(pi)\n    1.8727388590273302654363491032336134987519132374152\n\nThe harmonic series diverges, but at a glacial pace. It is possible\nto calculate the exact number of terms required before the sum\nexceeds a given amount, say 100::\n\n    >>> mp.dps = 50\n    >>> v = 10**findroot(lambda x: harmonic(10**x) - 100, 10)\n    >>> v\n    15092688622113788323693563264538101449859496.864101\n    >>> v = int(ceil(v))\n    >>> print(v)\n    15092688622113788323693563264538101449859497\n    >>> harmonic(v-1)\n    99.999999999999999999999999999999999999999999942747\n    >>> harmonic(v)\n    100.000000000000000000000000000000000000000000009\n\n'
hermite: str = '\nEvaluates the Hermite polynomial `H_n(z)`, which may be defined using\nthe recurrence\n\n.. math ::\n\n    H_0(z) = 1\n\n    H_1(z) = 2z\n\n    H_{n+1} = 2z H_n(z) - 2n H_{n-1}(z).\n\nThe Hermite polynomials are orthogonal on `(-\\infty, \\infty)` with\nrespect to the weight `e^{-z^2}`. More generally, allowing arbitrary complex\nvalues of `n`, the Hermite function `H_n(z)` is defined as\n\n.. math ::\n\n    H_n(z) = (2z)^n \\,_2F_0\\left(-\\frac{n}{2}, \\frac{1-n}{2},\n        -\\frac{1}{z^2}\\right)\n\nfor `\\Re{z} > 0`, or generally\n\n.. math ::\n\n    H_n(z) = 2^n \\sqrt{\\pi} \\left(\n        \\frac{1}{\\Gamma\\left(\\frac{1-n}{2}\\right)}\n        \\,_1F_1\\left(-\\frac{n}{2}, \\frac{1}{2}, z^2\\right) -\n        \\frac{2z}{\\Gamma\\left(-\\frac{n}{2}\\right)}\n        \\,_1F_1\\left(\\frac{1-n}{2}, \\frac{3}{2}, z^2\\right)\n    \\right).\n\n**Plots**\n\n.. literalinclude :: /plots/hermite.py\n.. image :: /plots/hermite.png\n\n**Examples**\n\nEvaluation for arbitrary arguments::\n\n    >>> from mpmath import *\n    >>> mp.dps = 25; mp.pretty = True\n    >>> hermite(0, 10)\n    1.0\n    >>> hermite(1, 10); hermite(2, 10)\n    20.0\n    398.0\n    >>> hermite(10000, 2)\n    4.950440066552087387515653e+19334\n    >>> hermite(3, -10**8)\n    -7999999999999998800000000.0\n    >>> hermite(-3, -10**8)\n    1.675159751729877682920301e+4342944819032534\n    >>> hermite(2+3j, -1+2j)\n    (-0.07652130602993513389421901 - 0.1084662449961914580276007j)\n\nCoefficients of the first few Hermite polynomials are::\n\n    >>> for n in range(7):\n    ...     chop(taylor(lambda z: hermite(n, z), 0, n))\n    ...\n    [1.0]\n    [0.0, 2.0]\n    [-2.0, 0.0, 4.0]\n    [0.0, -12.0, 0.0, 8.0]\n    [12.0, 0.0, -48.0, 0.0, 16.0]\n    [0.0, 120.0, 0.0, -160.0, 0.0, 32.0]\n    [-120.0, 0.0, 720.0, 0.0, -480.0, 0.0, 64.0]\n\nValues at `z = 0`::\n\n    >>> for n in range(-5, 9):\n    ...     hermite(n, 0)\n    ...\n    0.02769459142039868792653387\n    0.08333333333333333333333333\n    0.2215567313631895034122709\n    0.5\n    0.8862269254527580136490837\n    1.0\n    0.0\n    -2.0\n    0.0\n    12.0\n    0.0\n    -120.0\n    0.0\n    1680.0\n\nHermite functions satisfy the differential equation::\n\n    >>> n = 4\n    >>> f = lambda z: hermite(n, z)\n    >>> z = 1.5\n    >>> chop(diff(f,z,2) - 2*z*diff(f,z) + 2*n*f(z))\n    0.0\n\nVerifying orthogonality::\n\n    >>> chop(quad(lambda t: hermite(2,t)*hermite(4,t)*exp(-t**2), [-inf,inf]))\n    0.0\n\n'
hyp0f1: str = "\nGives the hypergeometric function `\\,_0F_1`, sometimes known as the\nconfluent limit function, defined as\n\n.. math ::\n\n    \\,_0F_1(a,z) = \\sum_{k=0}^{\\infty} \\frac{1}{(a)_k} \\frac{z^k}{k!}.\n\nThis function satisfies the differential equation `z f''(z) + a f'(z) = f(z)`,\nand is related to the Bessel function of the first kind (see :func:`~mpmath.besselj`).\n\n``hyp0f1(a,z)`` is equivalent to ``hyper([],[a],z)``; see documentation for\n:func:`~mpmath.hyper` for more information.\n\n**Examples**\n\nEvaluation for arbitrary arguments::\n\n    >>> from mpmath import *\n    >>> mp.dps = 25; mp.pretty = True\n    >>> hyp0f1(2, 0.25)\n    1.130318207984970054415392\n    >>> hyp0f1((1,2), 1234567)\n    6.27287187546220705604627e+964\n    >>> hyp0f1(3+4j, 1000000j)\n    (3.905169561300910030267132e+606 + 3.807708544441684513934213e+606j)\n\nEvaluation is supported for arbitrarily large values of `z`,\nusing asymptotic expansions::\n\n    >>> hyp0f1(1, 10**50)\n    2.131705322874965310390701e+8685889638065036553022565\n    >>> hyp0f1(1, -10**50)\n    1.115945364792025420300208e-13\n\nVerifying the differential equation::\n\n    >>> a = 2.5\n    >>> f = lambda z: hyp0f1(a,z)\n    >>> for z in [0, 10, 3+4j]:\n    ...     chop(z*diff(f,z,2) + a*diff(f,z) - f(z))\n    ...\n    0.0\n    0.0\n    0.0\n\n"
hyp1f1: str = "\nGives the confluent hypergeometric function of the first kind,\n\n.. math ::\n\n    \\,_1F_1(a,b,z) = \\sum_{k=0}^{\\infty} \\frac{(a)_k}{(b)_k} \\frac{z^k}{k!},\n\nalso known as Kummer's function and sometimes denoted by `M(a,b,z)`. This\nfunction gives one solution to the confluent (Kummer's) differential equation\n\n.. math ::\n\n    z f''(z) + (b-z) f'(z) - af(z) = 0.\n\nA second solution is given by the `U` function; see :func:`~mpmath.hyperu`.\nSolutions are also given in an alternate form by the Whittaker\nfunctions (:func:`~mpmath.whitm`, :func:`~mpmath.whitw`).\n\n``hyp1f1(a,b,z)`` is equivalent\nto ``hyper([a],[b],z)``; see documentation for :func:`~mpmath.hyper` for more\ninformation.\n\n**Examples**\n\nEvaluation for real and complex values of the argument `z`, with\nfixed parameters `a = 2, b = -1/3`::\n\n    >>> from mpmath import *\n    >>> mp.dps = 25; mp.pretty = True\n    >>> hyp1f1(2, (-1,3), 3.25)\n    -2815.956856924817275640248\n    >>> hyp1f1(2, (-1,3), -3.25)\n    -1.145036502407444445553107\n    >>> hyp1f1(2, (-1,3), 1000)\n    -8.021799872770764149793693e+441\n    >>> hyp1f1(2, (-1,3), -1000)\n    0.000003131987633006813594535331\n    >>> hyp1f1(2, (-1,3), 100+100j)\n    (-3.189190365227034385898282e+48 - 1.106169926814270418999315e+49j)\n\nParameters may be complex::\n\n    >>> hyp1f1(2+3j, -1+j, 10j)\n    (261.8977905181045142673351 + 160.8930312845682213562172j)\n\nArbitrarily large values of `z` are supported::\n\n    >>> hyp1f1(3, 4, 10**20)\n    3.890569218254486878220752e+43429448190325182745\n    >>> hyp1f1(3, 4, -10**20)\n    6.0e-60\n    >>> hyp1f1(3, 4, 10**20*j)\n    (-1.935753855797342532571597e-20 - 2.291911213325184901239155e-20j)\n\nVerifying the differential equation::\n\n    >>> a, b = 1.5, 2\n    >>> f = lambda z: hyp1f1(a,b,z)\n    >>> for z in [0, -10, 3, 3+4j]:\n    ...     chop(z*diff(f,z,2) + (b-z)*diff(f,z) - a*f(z))\n    ...\n    0.0\n    0.0\n    0.0\n    0.0\n\nAn integral representation::\n\n    >>> a, b = 1.5, 3\n    >>> z = 1.5\n    >>> hyp1f1(a,b,z)\n    2.269381460919952778587441\n    >>> g = lambda t: exp(z*t)*t**(a-1)*(1-t)**(b-a-1)\n    >>> gammaprod([b],[a,b-a])*quad(g, [0,1])\n    2.269381460919952778587441\n\n\n"
hyp1f2: str = '\nGives the hypergeometric function `\\,_1F_2(a_1,a_2;b_1,b_2; z)`.\nThe call ``hyp1f2(a1,b1,b2,z)`` is equivalent to\n``hyper([a1],[b1,b2],z)``.\n\nEvaluation works for complex and arbitrarily large arguments::\n\n    >>> from mpmath import *\n    >>> mp.dps = 25; mp.pretty = True\n    >>> a, b, c = 1.5, (-1,3), 2.25\n    >>> hyp1f2(a, b, c, 10**20)\n    -1.159388148811981535941434e+8685889639\n    >>> hyp1f2(a, b, c, -10**20)\n    -12.60262607892655945795907\n    >>> hyp1f2(a, b, c, 10**20*j)\n    (4.237220401382240876065501e+6141851464 - 2.950930337531768015892987e+6141851464j)\n    >>> hyp1f2(2+3j, -2j, 0.5j, 10-20j)\n    (135881.9905586966432662004 - 86681.95885418079535738828j)\n\n'
hyp2f0: str = "\nGives the hypergeometric function `\\,_2F_0`, defined formally by the\nseries\n\n.. math ::\n\n    \\,_2F_0(a,b;;z) = \\sum_{n=0}^{\\infty} (a)_n (b)_n \\frac{z^n}{n!}.\n\nThis series usually does not converge. For small enough `z`, it can be viewed\nas an asymptotic series that may be summed directly with an appropriate\ntruncation. When this is not the case, :func:`~mpmath.hyp2f0` gives a regularized sum,\nor equivalently, it uses a representation in terms of the\nhypergeometric U function [1]. The series also converges when either `a` or `b`\nis a nonpositive integer, as it then terminates into a polynomial\nafter `-a` or `-b` terms.\n\n**Examples**\n\nEvaluation is supported for arbitrary complex arguments::\n\n    >>> from mpmath import *\n    >>> mp.dps = 25; mp.pretty = True\n    >>> hyp2f0((2,3), 1.25, -100)\n    0.07095851870980052763312791\n    >>> hyp2f0((2,3), 1.25, 100)\n    (-0.03254379032170590665041131 + 0.07269254613282301012735797j)\n    >>> hyp2f0(-0.75, 1-j, 4j)\n    (-0.3579987031082732264862155 - 3.052951783922142735255881j)\n\nEven with real arguments, the regularized value of 2F0 is often complex-valued,\nbut the imaginary part decreases exponentially as `z \\to 0`. In the following\nexample, the first call uses complex evaluation while the second has a small\nenough `z` to evaluate using the direct series and thus the returned value\nis strictly real (this should be taken to indicate that the imaginary\npart is less than ``eps``)::\n\n    >>> mp.dps = 15\n    >>> hyp2f0(1.5, 0.5, 0.05)\n    (1.04166637647907 + 8.34584913683906e-8j)\n    >>> hyp2f0(1.5, 0.5, 0.0005)\n    1.00037535207621\n\nThe imaginary part can be retrieved by increasing the working precision::\n\n    >>> mp.dps = 80\n    >>> nprint(hyp2f0(1.5, 0.5, 0.009).imag)\n    1.23828e-46\n\nIn the polynomial case (the series terminating), 2F0 can evaluate exactly::\n\n    >>> mp.dps = 15\n    >>> hyp2f0(-6,-6,2)\n    291793.0\n    >>> identify(hyp2f0(-2,1,0.25))\n    '(5/8)'\n\nThe coefficients of the polynomials can be recovered using Taylor expansion::\n\n    >>> nprint(taylor(lambda x: hyp2f0(-3,0.5,x), 0, 10))\n    [1.0, -1.5, 2.25, -1.875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n    >>> nprint(taylor(lambda x: hyp2f0(-4,0.5,x), 0, 10))\n    [1.0, -2.0, 4.5, -7.5, 6.5625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n\n\n[1] http://people.math.sfu.ca/~cbm/aands/page_504.htm\n"
hyp2f1: str = "\nGives the Gauss hypergeometric function `\\,_2F_1` (often simply referred to as\n*the* hypergeometric function), defined for `|z| < 1` as\n\n.. math ::\n\n    \\,_2F_1(a,b,c,z) = \\sum_{k=0}^{\\infty}\n        \\frac{(a)_k (b)_k}{(c)_k} \\frac{z^k}{k!}.\n\nand for `|z| \\ge 1` by analytic continuation, with a branch cut on `(1, \\infty)`\nwhen necessary.\n\nSpecial cases of this function include many of the orthogonal polynomials as\nwell as the incomplete beta function and other functions. Properties of the\nGauss hypergeometric function are documented comprehensively in many references,\nfor example Abramowitz & Stegun, section 15.\n\nThe implementation supports the analytic continuation as well as evaluation\nclose to the unit circle where `|z| \\approx 1`. The syntax ``hyp2f1(a,b,c,z)``\nis equivalent to ``hyper([a,b],[c],z)``.\n\n**Examples**\n\nEvaluation with `z` inside, outside and on the unit circle, for\nfixed parameters::\n\n    >>> from mpmath import *\n    >>> mp.dps = 25; mp.pretty = True\n    >>> hyp2f1(2, (1,2), 4, 0.75)\n    1.303703703703703703703704\n    >>> hyp2f1(2, (1,2), 4, -1.75)\n    0.7431290566046919177853916\n    >>> hyp2f1(2, (1,2), 4, 1.75)\n    (1.418075801749271137026239 - 1.114976146679907015775102j)\n    >>> hyp2f1(2, (1,2), 4, 1)\n    1.6\n    >>> hyp2f1(2, (1,2), 4, -1)\n    0.8235498012182875315037882\n    >>> hyp2f1(2, (1,2), 4, j)\n    (0.9144026291433065674259078 + 0.2050415770437884900574923j)\n    >>> hyp2f1(2, (1,2), 4, 2+j)\n    (0.9274013540258103029011549 + 0.7455257875808100868984496j)\n    >>> hyp2f1(2, (1,2), 4, 0.25j)\n    (0.9931169055799728251931672 + 0.06154836525312066938147793j)\n\nEvaluation with complex parameter values::\n\n    >>> hyp2f1(1+j, 0.75, 10j, 1+5j)\n    (0.8834833319713479923389638 + 0.7053886880648105068343509j)\n\nEvaluation with `z = 1`::\n\n    >>> hyp2f1(-2.5, 3.5, 1.5, 1)\n    0.0\n    >>> hyp2f1(-2.5, 3, 4, 1)\n    0.06926406926406926406926407\n    >>> hyp2f1(2, 3, 4, 1)\n    +inf\n\nEvaluation for huge arguments::\n\n    >>> hyp2f1((-1,3), 1.75, 4, '1e100')\n    (7.883714220959876246415651e+32 + 1.365499358305579597618785e+33j)\n    >>> hyp2f1((-1,3), 1.75, 4, '1e1000000')\n    (7.883714220959876246415651e+333332 + 1.365499358305579597618785e+333333j)\n    >>> hyp2f1((-1,3), 1.75, 4, '1e1000000j')\n    (1.365499358305579597618785e+333333 - 7.883714220959876246415651e+333332j)\n\nAn integral representation::\n\n    >>> a,b,c,z = -0.5, 1, 2.5, 0.25\n    >>> g = lambda t: t**(b-1) * (1-t)**(c-b-1) * (1-t*z)**(-a)\n    >>> gammaprod([c],[b,c-b]) * quad(g, [0,1])\n    0.9480458814362824478852618\n    >>> hyp2f1(a,b,c,z)\n    0.9480458814362824478852618\n\nVerifying the hypergeometric differential equation::\n\n    >>> f = lambda z: hyp2f1(a,b,c,z)\n    >>> chop(z*(1-z)*diff(f,z,2) + (c-(a+b+1)*z)*diff(f,z) - a*b*f(z))\n    0.0\n\n"
hyp2f2: str = '\nGives the hypergeometric function `\\,_2F_2(a_1,a_2;b_1,b_2; z)`.\nThe call ``hyp2f2(a1,a2,b1,b2,z)`` is equivalent to\n``hyper([a1,a2],[b1,b2],z)``.\n\nEvaluation works for complex and arbitrarily large arguments::\n\n    >>> from mpmath import *\n    >>> mp.dps = 25; mp.pretty = True\n    >>> a, b, c, d = 1.5, (-1,3), 2.25, 4\n    >>> hyp2f2(a, b, c, d, 10**20)\n    -5.275758229007902299823821e+43429448190325182663\n    >>> hyp2f2(a, b, c, d, -10**20)\n    2561445.079983207701073448\n    >>> hyp2f2(a, b, c, d, 10**20*j)\n    (2218276.509664121194836667 - 1280722.539991603850462856j)\n    >>> hyp2f2(2+3j, -2j, 0.5j, 4j, 10-20j)\n    (80500.68321405666957342788 - 20346.82752982813540993502j)\n\n'
hyp2f3: str = '\nGives the hypergeometric function `\\,_2F_3(a_1,a_2;b_1,b_2,b_3; z)`.\nThe call ``hyp2f3(a1,a2,b1,b2,b3,z)`` is equivalent to\n``hyper([a1,a2],[b1,b2,b3],z)``.\n\nEvaluation works for arbitrarily large arguments::\n\n    >>> from mpmath import *\n    >>> mp.dps = 25; mp.pretty = True\n    >>> a1,a2,b1,b2,b3 = 1.5, (-1,3), 2.25, 4, (1,5)\n    >>> hyp2f3(a1,a2,b1,b2,b3,10**20)\n    -4.169178177065714963568963e+8685889590\n    >>> hyp2f3(a1,a2,b1,b2,b3,-10**20)\n    7064472.587757755088178629\n    >>> hyp2f3(a1,a2,b1,b2,b3,10**20*j)\n    (-5.163368465314934589818543e+6141851415 + 1.783578125755972803440364e+6141851416j)\n    >>> hyp2f3(2+3j, -2j, 0.5j, 4j, -1-j, 10-20j)\n    (-2280.938956687033150740228 + 13620.97336609573659199632j)\n    >>> hyp2f3(2+3j, -2j, 0.5j, 4j, -1-j, 10000000-20000000j)\n    (4.849835186175096516193e+3504 - 3.365981529122220091353633e+3504j)\n\n'
hyp3f2: str = "\nGives the generalized hypergeometric function `\\,_3F_2`, defined for `|z| < 1`\nas\n\n.. math ::\n\n    \\,_3F_2(a_1,a_2,a_3,b_1,b_2,z) = \\sum_{k=0}^{\\infty}\n        \\frac{(a_1)_k (a_2)_k (a_3)_k}{(b_1)_k (b_2)_k} \\frac{z^k}{k!}.\n\nand for `|z| \\ge 1` by analytic continuation. The analytic structure of this\nfunction is similar to that of `\\,_2F_1`, generally with a singularity at\n`z = 1` and a branch cut on `(1, \\infty)`.\n\nEvaluation is supported inside, on, and outside\nthe circle of convergence `|z| = 1`::\n\n    >>> from mpmath import *\n    >>> mp.dps = 25; mp.pretty = True\n    >>> hyp3f2(1,2,3,4,5,0.25)\n    1.083533123380934241548707\n    >>> hyp3f2(1,2+2j,3,4,5,-10+10j)\n    (0.1574651066006004632914361 - 0.03194209021885226400892963j)\n    >>> hyp3f2(1,2,3,4,5,-10)\n    0.3071141169208772603266489\n    >>> hyp3f2(1,2,3,4,5,10)\n    (-0.4857045320523947050581423 - 0.5988311440454888436888028j)\n    >>> hyp3f2(0.25,1,1,2,1.5,1)\n    1.157370995096772047567631\n    >>> (8-pi-2*ln2)/3\n    1.157370995096772047567631\n    >>> hyp3f2(1+j,0.5j,2,1,-2j,-1)\n    (1.74518490615029486475959 + 0.1454701525056682297614029j)\n    >>> hyp3f2(1+j,0.5j,2,1,-2j,sqrt(j))\n    (0.9829816481834277511138055 - 0.4059040020276937085081127j)\n    >>> hyp3f2(-3,2,1,-5,4,1)\n    1.41\n    >>> hyp3f2(-3,2,1,-5,4,2)\n    2.12\n\nEvaluation very close to the unit circle::\n\n    >>> hyp3f2(1,2,3,4,5,'1.0001')\n    (1.564877796743282766872279 - 3.76821518787438186031973e-11j)\n    >>> hyp3f2(1,2,3,4,5,'1+0.0001j')\n    (1.564747153061671573212831 + 0.0001305757570366084557648482j)\n    >>> hyp3f2(1,2,3,4,5,'0.9999')\n    1.564616644881686134983664\n    >>> hyp3f2(1,2,3,4,5,'-0.9999')\n    0.7823896253461678060196207\n\n.. note ::\n\n    Evaluation for `|z-1|` small can currently be inaccurate or slow\n    for some parameter combinations.\n\nFor various parameter combinations, `\\,_3F_2` admits representation in terms\nof hypergeometric functions of lower degree, or in terms of\nsimpler functions::\n\n    >>> for a, b, z in [(1,2,-1), (2,0.5,1)]:\n    ...     hyp2f1(a,b,a+b+0.5,z)**2\n    ...     hyp3f2(2*a,a+b,2*b,a+b+0.5,2*a+2*b,z)\n    ...\n    0.4246104461966439006086308\n    0.4246104461966439006086308\n    7.111111111111111111111111\n    7.111111111111111111111111\n\n    >>> z = 2+3j\n    >>> hyp3f2(0.5,1,1.5,2,2,z)\n    (0.7621440939243342419729144 + 0.4249117735058037649915723j)\n    >>> 4*(pi-2*ellipe(z))/(pi*z)\n    (0.7621440939243342419729144 + 0.4249117735058037649915723j)\n\n"
hyper: str = "\nEvaluates the generalized hypergeometric function\n\n.. math ::\n\n    \\,_pF_q(a_1,\\ldots,a_p; b_1,\\ldots,b_q; z) =\n    \\sum_{n=0}^\\infty \\frac{(a_1)_n (a_2)_n \\ldots (a_p)_n}\n       {(b_1)_n(b_2)_n\\ldots(b_q)_n} \\frac{z^n}{n!}\n\nwhere `(x)_n` denotes the rising factorial (see :func:`~mpmath.rf`).\n\nThe parameters lists ``a_s`` and ``b_s`` may contain integers,\nreal numbers, complex numbers, as well as exact fractions given in\nthe form of tuples `(p, q)`. :func:`~mpmath.hyper` is optimized to handle\nintegers and fractions more efficiently than arbitrary\nfloating-point parameters (since rational parameters are by\nfar the most common).\n\n**Examples**\n\nVerifying that :func:`~mpmath.hyper` gives the sum in the definition, by\ncomparison with :func:`~mpmath.nsum`::\n\n    >>> from mpmath import *\n    >>> mp.dps = 25; mp.pretty = True\n    >>> a,b,c,d = 2,3,4,5\n    >>> x = 0.25\n    >>> hyper([a,b],[c,d],x)\n    1.078903941164934876086237\n    >>> fn = lambda n: rf(a,n)*rf(b,n)/rf(c,n)/rf(d,n)*x**n/fac(n)\n    >>> nsum(fn, [0, inf])\n    1.078903941164934876086237\n\nThe parameters can be any combination of integers, fractions,\nfloats and complex numbers::\n\n    >>> a, b, c, d, e = 1, (-1,2), pi, 3+4j, (2,3)\n    >>> x = 0.2j\n    >>> hyper([a,b],[c,d,e],x)\n    (0.9923571616434024810831887 - 0.005753848733883879742993122j)\n    >>> b, e = -0.5, mpf(2)/3\n    >>> fn = lambda n: rf(a,n)*rf(b,n)/rf(c,n)/rf(d,n)/rf(e,n)*x**n/fac(n)\n    >>> nsum(fn, [0, inf])\n    (0.9923571616434024810831887 - 0.005753848733883879742993122j)\n\nThe `\\,_0F_0` and `\\,_1F_0` series are just elementary functions::\n\n    >>> a, z = sqrt(2), +pi\n    >>> hyper([],[],z)\n    23.14069263277926900572909\n    >>> exp(z)\n    23.14069263277926900572909\n    >>> hyper([a],[],z)\n    (-0.09069132879922920160334114 + 0.3283224323946162083579656j)\n    >>> (1-z)**(-a)\n    (-0.09069132879922920160334114 + 0.3283224323946162083579656j)\n\nIf any `a_k` coefficient is a nonpositive integer, the series terminates\ninto a finite polynomial::\n\n    >>> hyper([1,1,1,-3],[2,5],1)\n    0.7904761904761904761904762\n    >>> identify(_)\n    '(83/105)'\n\nIf any `b_k` is a nonpositive integer, the function is undefined (unless the\nseries terminates before the division by zero occurs)::\n\n    >>> hyper([1,1,1,-3],[-2,5],1)\n    Traceback (most recent call last):\n      ...\n    ZeroDivisionError: pole in hypergeometric series\n    >>> hyper([1,1,1,-1],[-2,5],1)\n    1.1\n\nExcept for polynomial cases, the radius of convergence `R` of the hypergeometric\nseries is either `R = \\infty` (if `p \\le q`), `R = 1` (if `p = q+1`), or\n`R = 0` (if `p > q+1`).\n\nThe analytic continuations of the functions with `p = q+1`, i.e. `\\,_2F_1`,\n`\\,_3F_2`,  `\\,_4F_3`, etc, are all implemented and therefore these functions\ncan be evaluated for `|z| \\ge 1`. The shortcuts :func:`~mpmath.hyp2f1`, :func:`~mpmath.hyp3f2`\nare available to handle the most common cases (see their documentation),\nbut functions of higher degree are also supported via :func:`~mpmath.hyper`::\n\n    >>> hyper([1,2,3,4], [5,6,7], 1)   # 4F3 at finite-valued branch point\n    1.141783505526870731311423\n    >>> hyper([4,5,6,7], [1,2,3], 1)   # 4F3 at pole\n    +inf\n    >>> hyper([1,2,3,4,5], [6,7,8,9], 10)    # 5F4\n    (1.543998916527972259717257 - 0.5876309929580408028816365j)\n    >>> hyper([1,2,3,4,5,6], [7,8,9,10,11], 1j)   # 6F5\n    (0.9996565821853579063502466 + 0.0129721075905630604445669j)\n\nNear `z = 1` with noninteger parameters::\n\n    >>> hyper(['1/3',1,'3/2',2], ['1/5','11/6','41/8'], 1)\n    2.219433352235586121250027\n    >>> hyper(['1/3',1,'3/2',2], ['1/5','11/6','5/4'], 1)\n    +inf\n    >>> eps1 = extradps(6)(lambda: 1 - mpf('1e-6'))()\n    >>> hyper(['1/3',1,'3/2',2], ['1/5','11/6','5/4'], eps1)\n    2923978034.412973409330956\n\nPlease note that, as currently implemented, evaluation of `\\,_pF_{p-1}`\nwith `p \\ge 3` may be slow or inaccurate when `|z-1|` is small,\nfor some parameter values.\n\nEvaluation may be aborted if convergence appears to be too slow.\nThe optional ``maxterms`` (limiting the number of series terms) and ``maxprec``\n(limiting the internal precision) keyword arguments can be used\nto control evaluation::\n\n    >>> hyper([1,2,3], [4,5,6], 10000)              # doctest: +IGNORE_EXCEPTION_DETAIL\n    Traceback (most recent call last):\n      ...\n    NoConvergence: Hypergeometric series converges too slowly. Try increasing maxterms.\n    >>> hyper([1,2,3], [4,5,6], 10000, maxterms=10**6)\n    7.622806053177969474396918e+4310\n\nAdditional options include ``force_series`` (which forces direct use of\na hypergeometric series even if another evaluation method might work better)\nand ``asymp_tol`` which controls the target tolerance for using\nasymptotic series.\n\nWhen `p > q+1`, ``hyper`` computes the (iterated) Borel sum of the divergent\nseries. For `\\,_2F_0` the Borel sum has an analytic solution and can be\ncomputed efficiently (see :func:`~mpmath.hyp2f0`). For higher degrees, the functions\nis evaluated first by attempting to sum it directly as an asymptotic\nseries (this only works for tiny `|z|`), and then by evaluating the Borel\nregularized sum using numerical integration. Except for\nspecial parameter combinations, this can be extremely slow.\n\n    >>> hyper([1,1], [], 0.5)          # regularization of 2F0\n    (1.340965419580146562086448 + 0.8503366631752726568782447j)\n    >>> hyper([1,1,1,1], [1], 0.5)     # regularization of 4F1\n    (1.108287213689475145830699 + 0.5327107430640678181200491j)\n\nWith the following magnitude of argument, the asymptotic series for `\\,_3F_1`\ngives only a few digits. Using Borel summation, ``hyper`` can produce\na value with full accuracy::\n\n    >>> mp.dps = 15\n    >>> hyper([2,0.5,4], [5.25], '0.08', force_series=True)             # doctest: +IGNORE_EXCEPTION_DETAIL\n    Traceback (most recent call last):\n      ...\n    NoConvergence: Hypergeometric series converges too slowly. Try increasing maxterms.\n    >>> hyper([2,0.5,4], [5.25], '0.08', asymp_tol=1e-4)\n    1.0725535790737\n    >>> hyper([2,0.5,4], [5.25], '0.08')\n    (1.07269542893559 + 5.54668863216891e-5j)\n    >>> hyper([2,0.5,4], [5.25], '-0.08', asymp_tol=1e-4)\n    0.946344925484879\n    >>> hyper([2,0.5,4], [5.25], '-0.08')\n    0.946312503737771\n    >>> mp.dps = 25\n    >>> hyper([2,0.5,4], [5.25], '-0.08')\n    0.9463125037377662296700858\n\nNote that with the positive `z` value, there is a complex part in the\ncorrect result, which falls below the tolerance of the asymptotic series.\n\nBy default, a parameter that appears in both ``a_s`` and ``b_s`` will be removed\nunless it is a nonpositive integer. This generally speeds up evaluation\nby producing a hypergeometric function of lower order.\nThis optimization can be disabled by passing ``eliminate=False``.\n\n    >>> hyper([1,2,3], [4,5,3], 10000)\n    1.268943190440206905892212e+4321\n    >>> hyper([1,2,3], [4,5,3], 10000, eliminate=False)             # doctest: +IGNORE_EXCEPTION_DETAIL\n    Traceback (most recent call last):\n      ...\n    NoConvergence: Hypergeometric series converges too slowly. Try increasing maxterms.\n    >>> hyper([1,2,3], [4,5,3], 10000, eliminate=False, maxterms=10**6)\n    1.268943190440206905892212e+4321\n\nIf a nonpositive integer `-n` appears in both ``a_s`` and ``b_s``, this parameter\ncannot be unambiguously removed since it creates a term 0 / 0.\nIn this case the hypergeometric series is understood to terminate before\nthe division by zero occurs. This convention is consistent with Mathematica.\nAn alternative convention of eliminating the parameters can be toggled\nwith ``eliminate_all=True``:\n\n    >>> hyper([2,-1], [-1], 3)\n    7.0\n    >>> hyper([2,-1], [-1], 3, eliminate_all=True)\n    0.25\n    >>> hyper([2], [], 3)\n    0.25\n\n"
hypercomb: str = '\nComputes a weighted combination of hypergeometric functions\n\n.. math ::\n\n    \\sum_{r=1}^N \\left[ \\prod_{k=1}^{l_r} {w_{r,k}}^{c_{r,k}}\n    \\frac{\\prod_{k=1}^{m_r} \\Gamma(\\alpha_{r,k})}{\\prod_{k=1}^{n_r}\n    \\Gamma(\\beta_{r,k})}\n    \\,_{p_r}F_{q_r}(a_{r,1},\\ldots,a_{r,p}; b_{r,1},\n    \\ldots, b_{r,q}; z_r)\\right].\n\nTypically the parameters are linear combinations of a small set of base\nparameters; :func:`~mpmath.hypercomb` permits computing a correct value in\nthe case that some of the `\\alpha`, `\\beta`, `b` turn out to be\nnonpositive integers, or if division by zero occurs for some `w^c`,\nassuming that there are opposing singularities that cancel out.\nThe limit is computed by evaluating the function with the base\nparameters perturbed, at a higher working precision.\n\nThe first argument should be a function that takes the perturbable\nbase parameters ``params`` as input and returns `N` tuples\n``(w, c, alpha, beta, a, b, z)``, where the coefficients ``w``, ``c``,\ngamma factors ``alpha``, ``beta``, and hypergeometric coefficients\n``a``, ``b`` each should be lists of numbers, and ``z`` should be a single\nnumber.\n\n**Examples**\n\nThe following evaluates\n\n.. math ::\n\n    (a-1) \\frac{\\Gamma(a-3)}{\\Gamma(a-4)} \\,_1F_1(a,a-1,z) = e^z(a-4)(a+z-1)\n\nwith `a=1, z=3`. There is a zero factor, two gamma function poles, and\nthe 1F1 function is singular; all singularities cancel out to give a finite\nvalue::\n\n    >>> from mpmath import *\n    >>> mp.dps = 15; mp.pretty = True\n    >>> hypercomb(lambda a: [([a-1],[1],[a-3],[a-4],[a],[a-1],3)], [1])\n    -180.769832308689\n    >>> -9*exp(3)\n    -180.769832308689\n\n'
hyperfac: str = '\nComputes the hyperfactorial, defined for integers as the product\n\n.. math ::\n\n    H(n) = \\prod_{k=1}^n k^k.\n\n\nThe hyperfactorial satisfies the recurrence formula `H(z) = z^z H(z-1)`.\nIt can be defined more generally in terms of the Barnes G-function (see\n:func:`~mpmath.barnesg`) and the gamma function by the formula\n\n.. math ::\n\n    H(z) = \\frac{\\Gamma(z+1)^z}{G(z)}.\n\nThe extension to complex numbers can also be done via\nthe integral representation\n\n.. math ::\n\n    H(z) = (2\\pi)^{-z/2} \\exp \\left[\n        {z+1 \\choose 2} + \\int_0^z \\log(t!)\\,dt\n        \\right].\n\n**Examples**\n\nThe rapidly-growing sequence of hyperfactorials begins\n(OEIS A002109)::\n\n    >>> from mpmath import *\n    >>> mp.dps = 15; mp.pretty = True\n    >>> for n in range(10):\n    ...     print("%s %s" % (n, hyperfac(n)))\n    ...\n    0 1.0\n    1 1.0\n    2 4.0\n    3 108.0\n    4 27648.0\n    5 86400000.0\n    6 4031078400000.0\n    7 3.3197663987712e+18\n    8 5.56964379417266e+25\n    9 2.15779412229419e+34\n\nSome even larger hyperfactorials are::\n\n    >>> hyperfac(1000)\n    5.46458120882585e+1392926\n    >>> hyperfac(10**10)\n    4.60408207642219e+489142638002418704309\n\nThe hyperfactorial can be evaluated for arbitrary arguments::\n\n    >>> hyperfac(0.5)\n    0.880449235173423\n    >>> diff(hyperfac, 1)\n    0.581061466795327\n    >>> hyperfac(pi)\n    205.211134637462\n    >>> hyperfac(-10+1j)\n    (3.01144471378225e+46 - 2.45285242480185e+46j)\n\nThe recurrence property of the hyperfactorial holds\ngenerally::\n\n    >>> z = 3-4*j\n    >>> hyperfac(z)\n    (-4.49795891462086e-7 - 6.33262283196162e-7j)\n    >>> z**z * hyperfac(z-1)\n    (-4.49795891462086e-7 - 6.33262283196162e-7j)\n    >>> z = mpf(-0.6)\n    >>> chop(z**z * hyperfac(z-1))\n    1.28170142849352\n    >>> hyperfac(z)\n    1.28170142849352\n\nThe hyperfactorial may also be computed using the integral\ndefinition::\n\n    >>> z = 2.5\n    >>> hyperfac(z)\n    15.9842119922237\n    >>> (2*pi)**(-z/2)*exp(binomial(z+1,2) +\n    ...     quad(lambda t: loggamma(t+1), [0, z]))\n    15.9842119922237\n\n:func:`~mpmath.hyperfac` supports arbitrary-precision evaluation::\n\n    >>> mp.dps = 50\n    >>> hyperfac(10)\n    215779412229418562091680268288000000000000000.0\n    >>> hyperfac(1/sqrt(2))\n    0.89404818005227001975423476035729076375705084390942\n\n**References**\n\n1. http://oeis.org/A002109\n2. http://mathworld.wolfram.com/Hyperfactorial.html\n\n'
hyperu: str = '\nGives the Tricomi confluent hypergeometric function `U`, also known as\nthe Kummer or confluent hypergeometric function of the second kind. This\nfunction gives a second linearly independent solution to the confluent\nhypergeometric differential equation (the first is provided by `\\,_1F_1`  --\nsee :func:`~mpmath.hyp1f1`).\n\n**Examples**\n\nEvaluation for arbitrary complex arguments::\n\n    >>> from mpmath import *\n    >>> mp.dps = 25; mp.pretty = True\n    >>> hyperu(2,3,4)\n    0.0625\n    >>> hyperu(0.25, 5, 1000)\n    0.1779949416140579573763523\n    >>> hyperu(0.25, 5, -1000)\n    (0.1256256609322773150118907 - 0.1256256609322773150118907j)\n\nThe `U` function may be singular at `z = 0`::\n\n    >>> hyperu(1.5, 2, 0)\n    +inf\n    >>> hyperu(1.5, -2, 0)\n    0.1719434921288400112603671\n\nVerifying the differential equation::\n\n    >>> a, b = 1.5, 2\n    >>> f = lambda z: hyperu(a,b,z)\n    >>> for z in [-10, 3, 3+4j]:\n    ...     chop(z*diff(f,z,2) + (b-z)*diff(f,z) - a*f(z))\n    ...\n    0.0\n    0.0\n    0.0\n\nAn integral representation::\n\n    >>> a,b,z = 2, 3.5, 4.25\n    >>> hyperu(a,b,z)\n    0.06674960718150520648014567\n    >>> quad(lambda t: exp(-z*t)*t**(a-1)*(1+t)**(b-a-1),[0,inf]) / gamma(a)\n    0.06674960718150520648014567\n\n\n[1] http://people.math.sfu.ca/~cbm/aands/page_504.htm\n'
im: str = "\nReturns the imaginary part of `x`, `\\Im(x)`. :func:`~mpmath.im`\nconverts a non-mpmath number to an mpmath number::\n\n    >>> from mpmath import *\n    >>> mp.dps = 15; mp.pretty = False\n    >>> im(3)\n    mpf('0.0')\n    >>> im(-1+4j)\n    mpf('4.0')\n"
jacobi: str = '\n``jacobi(n, a, b, x)`` evaluates the Jacobi polynomial\n`P_n^{(a,b)}(x)`. The Jacobi polynomials are a special\ncase of the hypergeometric function `\\,_2F_1` given by:\n\n.. math ::\n\n    P_n^{(a,b)}(x) = {n+a \\choose n}\n      \\,_2F_1\\left(-n,1+a+b+n,a+1,\\frac{1-x}{2}\\right).\n\nNote that this definition generalizes to nonintegral values\nof `n`. When `n` is an integer, the hypergeometric series\nterminates after a finite number of terms, giving\na polynomial in `x`.\n\n**Evaluation of Jacobi polynomials**\n\nA special evaluation is `P_n^{(a,b)}(1) = {n+a \\choose n}`::\n\n    >>> from mpmath import *\n    >>> mp.dps = 15; mp.pretty = True\n    >>> jacobi(4, 0.5, 0.25, 1)\n    2.4609375\n    >>> binomial(4+0.5, 4)\n    2.4609375\n\nA Jacobi polynomial of degree `n` is equal to its\nTaylor polynomial of degree `n`. The explicit\ncoefficients of Jacobi polynomials can therefore\nbe recovered easily using :func:`~mpmath.taylor`::\n\n    >>> for n in range(5):\n    ...     nprint(taylor(lambda x: jacobi(n,1,2,x), 0, n))\n    ...\n    [1.0]\n    [-0.5, 2.5]\n    [-0.75, -1.5, 5.25]\n    [0.5, -3.5, -3.5, 10.5]\n    [0.625, 2.5, -11.25, -7.5, 20.625]\n\nFor nonintegral `n`, the Jacobi "polynomial" is no longer\na polynomial::\n\n    >>> nprint(taylor(lambda x: jacobi(0.5,1,2,x), 0, 4))\n    [0.309983, 1.84119, -1.26933, 1.26699, -1.34808]\n\n**Orthogonality**\n\nThe Jacobi polynomials are orthogonal on the interval\n`[-1, 1]` with respect to the weight function\n`w(x) = (1-x)^a (1+x)^b`. That is,\n`w(x) P_n^{(a,b)}(x) P_m^{(a,b)}(x)` integrates to\nzero if `m \\ne n` and to a nonzero number if `m = n`.\n\nThe orthogonality is easy to verify using numerical\nquadrature::\n\n    >>> P = jacobi\n    >>> f = lambda x: (1-x)**a * (1+x)**b * P(m,a,b,x) * P(n,a,b,x)\n    >>> a = 2\n    >>> b = 3\n    >>> m, n = 3, 4\n    >>> chop(quad(f, [-1, 1]), 1)\n    0.0\n    >>> m, n = 4, 4\n    >>> quad(f, [-1, 1])\n    1.9047619047619\n\n**Differential equation**\n\nThe Jacobi polynomials are solutions of the differential\nequation\n\n.. math ::\n\n  (1-x^2) y\'\' + (b-a-(a+b+2)x) y\' + n (n+a+b+1) y = 0.\n\nWe can verify that :func:`~mpmath.jacobi` approximately satisfies\nthis equation::\n\n    >>> from mpmath import *\n    >>> mp.dps = 15\n    >>> a = 2.5\n    >>> b = 4\n    >>> n = 3\n    >>> y = lambda x: jacobi(n,a,b,x)\n    >>> x = pi\n    >>> A0 = n*(n+a+b+1)*y(x)\n    >>> A1 = (b-a-(a+b+2)*x)*diff(y,x)\n    >>> A2 = (1-x**2)*diff(y,x,2)\n    >>> nprint(A2 + A1 + A0, 1)\n    4.0e-12\n\nThe difference of order `10^{-12}` is as close to zero as\nit could be at 15-digit working precision, since the terms\nare large::\n\n    >>> A0, A1, A2\n    (26560.2328981879, -21503.7641037294, -5056.46879445852)\n\n'
jtheta: str = "\nComputes the Jacobi theta function `\\vartheta_n(z, q)`, where\n`n = 1, 2, 3, 4`, defined by the infinite series:\n\n.. math ::\n\n  \\vartheta_1(z,q) = 2 q^{1/4} \\sum_{n=0}^{\\infty}\n    (-1)^n q^{n^2+n\\,} \\sin((2n+1)z)\n\n  \\vartheta_2(z,q) = 2 q^{1/4} \\sum_{n=0}^{\\infty}\n    q^{n^{2\\,} + n} \\cos((2n+1)z)\n\n  \\vartheta_3(z,q) = 1 + 2 \\sum_{n=1}^{\\infty}\n    q^{n^2\\,} \\cos(2 n z)\n\n  \\vartheta_4(z,q) = 1 + 2 \\sum_{n=1}^{\\infty}\n    (-q)^{n^2\\,} \\cos(2 n z)\n\nThe theta functions are functions of two variables:\n\n* `z` is the *argument*, an arbitrary real or complex number\n\n* `q` is the *nome*, which must be a real or complex number\n  in the unit disk (i.e. `|q| < 1`). For `|q| \\ll 1`, the\n  series converge very quickly, so the Jacobi theta functions\n  can efficiently be evaluated to high precision.\n\nThe compact notations `\\vartheta_n(q) = \\vartheta_n(0,q)`\nand `\\vartheta_n = \\vartheta_n(0,q)` are also frequently\nencountered. Finally, Jacobi theta functions are frequently\nconsidered as functions of the half-period ratio `\\tau`\nand then usually denoted by `\\vartheta_n(z|\\tau)`.\n\nOptionally, ``jtheta(n, z, q, derivative=d)`` with `d > 0` computes\na `d`-th derivative with respect to `z`.\n\n**Examples and basic properties**\n\nConsidered as functions of `z`, the Jacobi theta functions may be\nviewed as generalizations of the ordinary trigonometric functions\ncos and sin. They are periodic functions::\n\n    >>> from mpmath import *\n    >>> mp.dps = 25; mp.pretty = True\n    >>> jtheta(1, 0.25, '0.2')\n    0.2945120798627300045053104\n    >>> jtheta(1, 0.25 + 2*pi, '0.2')\n    0.2945120798627300045053104\n\nIndeed, the series defining the theta functions are essentially\ntrigonometric Fourier series. The coefficients can be retrieved\nusing :func:`~mpmath.fourier`::\n\n    >>> mp.dps = 10\n    >>> nprint(fourier(lambda x: jtheta(2, x, 0.5), [-pi, pi], 4))\n    ([0.0, 1.68179, 0.0, 0.420448, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0])\n\nThe Jacobi theta functions are also so-called quasiperiodic\nfunctions of `z` and `\\tau`, meaning that for fixed `\\tau`,\n`\\vartheta_n(z, q)` and `\\vartheta_n(z+\\pi \\tau, q)` are the same\nexcept for an exponential factor::\n\n    >>> mp.dps = 25\n    >>> tau = 3*j/10\n    >>> q = exp(pi*j*tau)\n    >>> z = 10\n    >>> jtheta(4, z+tau*pi, q)\n    (-0.682420280786034687520568 + 1.526683999721399103332021j)\n    >>> -exp(-2*j*z)/q * jtheta(4, z, q)\n    (-0.682420280786034687520568 + 1.526683999721399103332021j)\n\nThe Jacobi theta functions satisfy a huge number of other\nfunctional equations, such as the following identity (valid for\nany `q`)::\n\n    >>> q = mpf(3)/10\n    >>> jtheta(3,0,q)**4\n    6.823744089352763305137427\n    >>> jtheta(2,0,q)**4 + jtheta(4,0,q)**4\n    6.823744089352763305137427\n\nExtensive listings of identities satisfied by the Jacobi theta\nfunctions can be found in standard reference works.\n\nThe Jacobi theta functions are related to the gamma function\nfor special arguments::\n\n    >>> jtheta(3, 0, exp(-pi))\n    1.086434811213308014575316\n    >>> pi**(1/4.) / gamma(3/4.)\n    1.086434811213308014575316\n\n:func:`~mpmath.jtheta` supports arbitrary precision evaluation and complex\narguments::\n\n    >>> mp.dps = 50\n    >>> jtheta(4, sqrt(2), 0.5)\n    2.0549510717571539127004115835148878097035750653737\n    >>> mp.dps = 25\n    >>> jtheta(4, 1+2j, (1+j)/5)\n    (7.180331760146805926356634 - 1.634292858119162417301683j)\n\nEvaluation of derivatives::\n\n    >>> mp.dps = 25\n    >>> jtheta(1, 7, 0.25, 1); diff(lambda z: jtheta(1, z, 0.25), 7)\n    1.209857192844475388637236\n    1.209857192844475388637236\n    >>> jtheta(1, 7, 0.25, 2); diff(lambda z: jtheta(1, z, 0.25), 7, 2)\n    -0.2598718791650217206533052\n    -0.2598718791650217206533052\n    >>> jtheta(2, 7, 0.25, 1); diff(lambda z: jtheta(2, z, 0.25), 7)\n    -1.150231437070259644461474\n    -1.150231437070259644461474\n    >>> jtheta(2, 7, 0.25, 2); diff(lambda z: jtheta(2, z, 0.25), 7, 2)\n    -0.6226636990043777445898114\n    -0.6226636990043777445898114\n    >>> jtheta(3, 7, 0.25, 1); diff(lambda z: jtheta(3, z, 0.25), 7)\n    -0.9990312046096634316587882\n    -0.9990312046096634316587882\n    >>> jtheta(3, 7, 0.25, 2); diff(lambda z: jtheta(3, z, 0.25), 7, 2)\n    -0.1530388693066334936151174\n    -0.1530388693066334936151174\n    >>> jtheta(4, 7, 0.25, 1); diff(lambda z: jtheta(4, z, 0.25), 7)\n    0.9820995967262793943571139\n    0.9820995967262793943571139\n    >>> jtheta(4, 7, 0.25, 2); diff(lambda z: jtheta(4, z, 0.25), 7, 2)\n    0.3936902850291437081667755\n    0.3936902850291437081667755\n\n**Possible issues**\n\nFor `|q| \\ge 1` or `\\Im(\\tau) \\le 0`, :func:`~mpmath.jtheta` raises\n``ValueError``. This exception is also raised for `|q|` extremely\nclose to 1 (or equivalently `\\tau` very close to 0), since the\nseries would converge too slowly::\n\n    >>> jtheta(1, 10, 0.99999999 * exp(0.5*j))\n    Traceback (most recent call last):\n      ...\n    ValueError: abs(q) > THETA_Q_LIM = 1.000000\n\n"
kei: str = '\nComputes the Kelvin function kei, which for real arguments gives the\nimaginary part of the (rescaled) Bessel K function of a rotated argument.\nSee :func:`~mpmath.ker`.\n'
ker: str = '\nComputes the Kelvin function ker, which for real arguments gives the real part\nof the (rescaled) Bessel K function of a rotated argument\n\n.. math ::\n\n    e^{-\\pi i/2} K_n\\left(x e^{3\\pi i/4}\\right) = \\mathrm{ker}_n(x) + i \\mathrm{kei}_n(x).\n\nThe imaginary part is given by :func:`~mpmath.kei`.\n\n**Plots**\n\n.. literalinclude :: /plots/ker.py\n.. image :: /plots/ker.png\n\n**Examples**\n\nVerifying the defining relation::\n\n    >>> from mpmath import *\n    >>> mp.dps = 25; mp.pretty = True\n    >>> n, x = 2, 4.5\n    >>> ker(n,x)\n    0.02542895201906369640249801\n    >>> kei(n,x)\n    -0.02074960467222823237055351\n    >>> exp(-n*pi*j/2) * besselk(n, x*root(1,8,1))\n    (0.02542895201906369640249801 - 0.02074960467222823237055351j)\n\nThe ker and kei functions are also defined by analytic continuation\nfor complex arguments::\n\n    >>> ker(1+j, 3+4j)\n    (1.586084268115490421090533 - 2.939717517906339193598719j)\n    >>> kei(1+j, 3+4j)\n    (-2.940403256319453402690132 - 1.585621643835618941044855j)\n\n'
khinchin: str = "\nKhinchin's constant `K` = 2.68542... is a number that\nappears in the theory of continued fractions. Mpmath can evaluate\nit to arbitrary precision::\n\n    >>> from mpmath import *\n    >>> mp.dps = 50; mp.pretty = True\n    >>> +khinchin\n    2.6854520010653064453097148354817956938203822939945\n\nAn integral representation is::\n\n    >>> I = quad(lambda x: log((1-x**2)/sincpi(x))/x/(1+x), [0, 1])\n    >>> 2*exp(1/log(2)*I)\n    2.6854520010653064453097148354817956938203822939945\n\nThe computation of ``khinchin`` is based on an efficient\nimplementation of the following series::\n\n    >>> f = lambda n: (zeta(2*n)-1)/n*sum((-1)**(k+1)/mpf(k)\n    ...     for k in range(1,2*int(n)))\n    >>> exp(nsum(f, [1,inf])/log(2))\n    2.6854520010653064453097148354817956938203822939945\n"
laguerre: str = '\nGives the generalized (associated) Laguerre polynomial, defined by\n\n.. math ::\n\n    L_n^a(z) = \\frac{\\Gamma(n+b+1)}{\\Gamma(b+1) \\Gamma(n+1)}\n        \\,_1F_1(-n, a+1, z).\n\nWith `a = 0` and `n` a nonnegative integer, this reduces to an ordinary\nLaguerre polynomial, the sequence of which begins\n`L_0(z) = 1, L_1(z) = 1-z, L_2(z) = z^2-2z+1, \\ldots`.\n\nThe Laguerre polynomials are orthogonal with respect to the weight\n`z^a e^{-z}` on `[0, \\infty)`.\n\n**Plots**\n\n.. literalinclude :: /plots/laguerre.py\n.. image :: /plots/laguerre.png\n\n**Examples**\n\nEvaluation for arbitrary arguments::\n\n    >>> from mpmath import *\n    >>> mp.dps = 25; mp.pretty = True\n    >>> laguerre(5, 0, 0.25)\n    0.03726399739583333333333333\n    >>> laguerre(1+j, 0.5, 2+3j)\n    (4.474921610704496808379097 - 11.02058050372068958069241j)\n    >>> laguerre(2, 0, 10000)\n    49980001.0\n    >>> laguerre(2.5, 0, 10000)\n    -9.327764910194842158583189e+4328\n\nThe first few Laguerre polynomials, normalized to have integer\ncoefficients::\n\n    >>> for n in range(7):\n    ...     chop(taylor(lambda z: fac(n)*laguerre(n, 0, z), 0, n))\n    ...\n    [1.0]\n    [1.0, -1.0]\n    [2.0, -4.0, 1.0]\n    [6.0, -18.0, 9.0, -1.0]\n    [24.0, -96.0, 72.0, -16.0, 1.0]\n    [120.0, -600.0, 600.0, -200.0, 25.0, -1.0]\n    [720.0, -4320.0, 5400.0, -2400.0, 450.0, -36.0, 1.0]\n\nVerifying orthogonality::\n\n    >>> Lm = lambda t: laguerre(m,a,t)\n    >>> Ln = lambda t: laguerre(n,a,t)\n    >>> a, n, m = 2.5, 2, 3\n    >>> chop(quad(lambda t: exp(-t)*t**a*Lm(t)*Ln(t), [0,inf]))\n    0.0\n\n\n'
lambertw: str = '\nThe Lambert W function `W(z)` is defined as the inverse function\nof `w \\exp(w)`. In other words, the value of `W(z)` is such that\n`z = W(z) \\exp(W(z))` for any complex number `z`.\n\nThe Lambert W function is a multivalued function with infinitely\nmany branches `W_k(z)`, indexed by `k \\in \\mathbb{Z}`. Each branch\ngives a different solution `w` of the equation `z = w \\exp(w)`.\nAll branches are supported by :func:`~mpmath.lambertw`:\n\n* ``lambertw(z)`` gives the principal solution (branch 0)\n\n* ``lambertw(z, k)`` gives the solution on branch `k`\n\nThe Lambert W function has two partially real branches: the\nprincipal branch (`k = 0`) is real for real `z > -1/e`, and the\n`k = -1` branch is real for `-1/e < z < 0`. All branches except\n`k = 0` have a logarithmic singularity at `z = 0`.\n\nThe definition, implementation and choice of branches\nis based on [Corless]_.\n\n**Plots**\n\n.. literalinclude :: /plots/lambertw.py\n.. image :: /plots/lambertw.png\n.. literalinclude :: /plots/lambertw_c.py\n.. image :: /plots/lambertw_c.png\n\n**Basic examples**\n\nThe Lambert W function is the inverse of `w \\exp(w)`::\n\n    >>> from mpmath import *\n    >>> mp.dps = 25; mp.pretty = True\n    >>> w = lambertw(1)\n    >>> w\n    0.5671432904097838729999687\n    >>> w*exp(w)\n    1.0\n\nAny branch gives a valid inverse::\n\n    >>> w = lambertw(1, k=3)\n    >>> w\n    (-2.853581755409037807206819 + 17.11353553941214591260783j)\n    >>> w = lambertw(1, k=25)\n    >>> w\n    (-5.047020464221569709378686 + 155.4763860949415867162066j)\n    >>> chop(w*exp(w))\n    1.0\n\n**Applications to equation-solving**\n\nThe Lambert W function may be used to solve various kinds of\nequations, such as finding the value of the infinite power\ntower `z^{z^{z^{\\ldots}}}`::\n\n    >>> def tower(z, n):\n    ...     if n == 0:\n    ...         return z\n    ...     return z ** tower(z, n-1)\n    ...\n    >>> tower(mpf(0.5), 100)\n    0.6411857445049859844862005\n    >>> -lambertw(-log(0.5))/log(0.5)\n    0.6411857445049859844862005\n\n**Properties**\n\nThe Lambert W function grows roughly like the natural logarithm\nfor large arguments::\n\n    >>> lambertw(1000); log(1000)\n    5.249602852401596227126056\n    6.907755278982137052053974\n    >>> lambertw(10**100); log(10**100)\n    224.8431064451185015393731\n    230.2585092994045684017991\n\nThe principal branch of the Lambert W function has a rational\nTaylor series expansion around `z = 0`::\n\n    >>> nprint(taylor(lambertw, 0, 6), 10)\n    [0.0, 1.0, -1.0, 1.5, -2.666666667, 5.208333333, -10.8]\n\nSome special values and limits are::\n\n    >>> lambertw(0)\n    0.0\n    >>> lambertw(1)\n    0.5671432904097838729999687\n    >>> lambertw(e)\n    1.0\n    >>> lambertw(inf)\n    +inf\n    >>> lambertw(0, k=-1)\n    -inf\n    >>> lambertw(0, k=3)\n    -inf\n    >>> lambertw(inf, k=2)\n    (+inf + 12.56637061435917295385057j)\n    >>> lambertw(inf, k=3)\n    (+inf + 18.84955592153875943077586j)\n    >>> lambertw(-inf, k=3)\n    (+inf + 21.9911485751285526692385j)\n\nThe `k = 0` and `k = -1` branches join at `z = -1/e` where\n`W(z) = -1` for both branches. Since `-1/e` can only be represented\napproximately with binary floating-point numbers, evaluating the\nLambert W function at this point only gives `-1` approximately::\n\n    >>> lambertw(-1/e, 0)\n    -0.9999999999998371330228251\n    >>> lambertw(-1/e, -1)\n    -1.000000000000162866977175\n\nIf `-1/e` happens to round in the negative direction, there might be\na small imaginary part::\n\n    >>> mp.dps = 15\n    >>> lambertw(-1/e)\n    (-1.0 + 8.22007971483662e-9j)\n    >>> lambertw(-1/e+eps)\n    -0.999999966242188\n\n**References**\n\n1. [Corless]_\n'
legendre: str = "\n``legendre(n, x)`` evaluates the Legendre polynomial `P_n(x)`.\nThe Legendre polynomials are given by the formula\n\n.. math ::\n\n    P_n(x) = \\frac{1}{2^n n!} \\frac{d^n}{dx^n} (x^2 -1)^n.\n\nAlternatively, they can be computed recursively using\n\n.. math ::\n\n    P_0(x) = 1\n\n    P_1(x) = x\n\n    (n+1) P_{n+1}(x) = (2n+1) x P_n(x) - n P_{n-1}(x).\n\nA third definition is in terms of the hypergeometric function\n`\\,_2F_1`, whereby they can be generalized to arbitrary `n`:\n\n.. math ::\n\n    P_n(x) = \\,_2F_1\\left(-n, n+1, 1, \\frac{1-x}{2}\\right)\n\n**Plots**\n\n.. literalinclude :: /plots/legendre.py\n.. image :: /plots/legendre.png\n\n**Basic evaluation**\n\nThe Legendre polynomials assume fixed values at the points\n`x = -1` and `x = 1`::\n\n    >>> from mpmath import *\n    >>> mp.dps = 15; mp.pretty = True\n    >>> nprint([legendre(n, 1) for n in range(6)])\n    [1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n    >>> nprint([legendre(n, -1) for n in range(6)])\n    [1.0, -1.0, 1.0, -1.0, 1.0, -1.0]\n\nThe coefficients of Legendre polynomials can be recovered\nusing degree-`n` Taylor expansion::\n\n    >>> for n in range(5):\n    ...     nprint(chop(taylor(lambda x: legendre(n, x), 0, n)))\n    ...\n    [1.0]\n    [0.0, 1.0]\n    [-0.5, 0.0, 1.5]\n    [0.0, -1.5, 0.0, 2.5]\n    [0.375, 0.0, -3.75, 0.0, 4.375]\n\nThe roots of Legendre polynomials are located symmetrically\non the interval `[-1, 1]`::\n\n    >>> for n in range(5):\n    ...     nprint(polyroots(taylor(lambda x: legendre(n, x), 0, n)[::-1]))\n    ...\n    []\n    [0.0]\n    [-0.57735, 0.57735]\n    [-0.774597, 0.0, 0.774597]\n    [-0.861136, -0.339981, 0.339981, 0.861136]\n\nAn example of an evaluation for arbitrary `n`::\n\n    >>> legendre(0.75, 2+4j)\n    (1.94952805264875 + 2.1071073099422j)\n\n**Orthogonality**\n\nThe Legendre polynomials are orthogonal on `[-1, 1]` with respect\nto the trivial weight `w(x) = 1`. That is, `P_m(x) P_n(x)`\nintegrates to zero if `m \\ne n` and to `2/(2n+1)` if `m = n`::\n\n    >>> m, n = 3, 4\n    >>> quad(lambda x: legendre(m,x)*legendre(n,x), [-1, 1])\n    0.0\n    >>> m, n = 4, 4\n    >>> quad(lambda x: legendre(m,x)*legendre(n,x), [-1, 1])\n    0.222222222222222\n\n**Differential equation**\n\nThe Legendre polynomials satisfy the differential equation\n\n.. math ::\n\n    ((1-x^2) y')' + n(n+1) y' = 0.\n\nWe can verify this numerically::\n\n    >>> n = 3.6\n    >>> x = 0.73\n    >>> P = legendre\n    >>> A = diff(lambda t: (1-t**2)*diff(lambda u: P(n,u), t), x)\n    >>> B = n*(n+1)*P(n,x)\n    >>> nprint(A+B,1)\n    9.0e-16\n\n"
legenp: str = "\nCalculates the (associated) Legendre function of the first kind of\ndegree *n* and order *m*, `P_n^m(z)`. Taking `m = 0` gives the ordinary\nLegendre function of the first kind, `P_n(z)`. The parameters may be\ncomplex numbers.\n\nIn terms of the Gauss hypergeometric function, the (associated) Legendre\nfunction is defined as\n\n.. math ::\n\n    P_n^m(z) = \\frac{1}{\\Gamma(1-m)} \\frac{(1+z)^{m/2}}{(1-z)^{m/2}}\n        \\,_2F_1\\left(-n, n+1, 1-m, \\frac{1-z}{2}\\right).\n\nWith *type=3* instead of *type=2*, the alternative\ndefinition\n\n.. math ::\n\n    \\hat{P}_n^m(z) = \\frac{1}{\\Gamma(1-m)} \\frac{(z+1)^{m/2}}{(z-1)^{m/2}}\n        \\,_2F_1\\left(-n, n+1, 1-m, \\frac{1-z}{2}\\right).\n\nis used. These functions correspond respectively to ``LegendreP[n,m,2,z]``\nand ``LegendreP[n,m,3,z]`` in Mathematica.\n\nThe general solution of the (associated) Legendre differential equation\n\n.. math ::\n\n    (1-z^2) f''(z) - 2zf'(z) + \\left(n(n+1)-\\frac{m^2}{1-z^2}\\right)f(z) = 0\n\nis given by `C_1 P_n^m(z) + C_2 Q_n^m(z)` for arbitrary constants\n`C_1`, `C_2`, where `Q_n^m(z)` is a Legendre function of the\nsecond kind as implemented by :func:`~mpmath.legenq`.\n\n**Examples**\n\nEvaluation for arbitrary parameters and arguments::\n\n    >>> from mpmath import *\n    >>> mp.dps = 25; mp.pretty = True\n    >>> legenp(2, 0, 10); legendre(2, 10)\n    149.5\n    149.5\n    >>> legenp(-2, 0.5, 2.5)\n    (1.972260393822275434196053 - 1.972260393822275434196053j)\n    >>> legenp(2+3j, 1-j, -0.5+4j)\n    (-3.335677248386698208736542 - 5.663270217461022307645625j)\n    >>> chop(legenp(3, 2, -1.5, type=2))\n    28.125\n    >>> chop(legenp(3, 2, -1.5, type=3))\n    -28.125\n\nVerifying the associated Legendre differential equation::\n\n    >>> n, m = 2, -0.5\n    >>> C1, C2 = 1, -3\n    >>> f = lambda z: C1*legenp(n,m,z) + C2*legenq(n,m,z)\n    >>> deq = lambda z: (1-z**2)*diff(f,z,2) - 2*z*diff(f,z) + \\\n    ...     (n*(n+1)-m**2/(1-z**2))*f(z)\n    >>> for z in [0, 2, -1.5, 0.5+2j]:\n    ...     chop(deq(mpmathify(z)))\n    ...\n    0.0\n    0.0\n    0.0\n    0.0\n"
legenq: str = '\nCalculates the (associated) Legendre function of the second kind of\ndegree *n* and order *m*, `Q_n^m(z)`. Taking `m = 0` gives the ordinary\nLegendre function of the second kind, `Q_n(z)`. The parameters may be\ncomplex numbers.\n\nThe Legendre functions of the second kind give a second set of\nsolutions to the (associated) Legendre differential equation.\n(See :func:`~mpmath.legenp`.)\nUnlike the Legendre functions of the first kind, they are not\npolynomials of `z` for integer `n`, `m` but rational or logarithmic\nfunctions with poles at `z = \\pm 1`.\n\nThere are various ways to define Legendre functions of\nthe second kind, giving rise to different complex structure.\nA version can be selected using the *type* keyword argument.\nThe *type=2* and *type=3* functions are given respectively by\n\n.. math ::\n\n    Q_n^m(z) = \\frac{\\pi}{2 \\sin(\\pi m)}\n        \\left( \\cos(\\pi m) P_n^m(z) -\n        \\frac{\\Gamma(1+m+n)}{\\Gamma(1-m+n)} P_n^{-m}(z)\\right)\n\n    \\hat{Q}_n^m(z) = \\frac{\\pi}{2 \\sin(\\pi m)} e^{\\pi i m}\n        \\left( \\hat{P}_n^m(z) -\n        \\frac{\\Gamma(1+m+n)}{\\Gamma(1-m+n)} \\hat{P}_n^{-m}(z)\\right)\n\nwhere `P` and `\\hat{P}` are the *type=2* and *type=3* Legendre functions\nof the first kind. The formulas above should be understood as limits\nwhen `m` is an integer.\n\nThese functions correspond to ``LegendreQ[n,m,2,z]`` (or ``LegendreQ[n,m,z]``)\nand ``LegendreQ[n,m,3,z]`` in Mathematica. The *type=3* function\nis essentially the same as the function defined in\nAbramowitz & Stegun (eq. 8.1.3) but with `(z+1)^{m/2}(z-1)^{m/2}` instead\nof `(z^2-1)^{m/2}`, giving slightly different branches.\n\n**Examples**\n\nEvaluation for arbitrary parameters and arguments::\n\n    >>> from mpmath import *\n    >>> mp.dps = 25; mp.pretty = True\n    >>> legenq(2, 0, 0.5)\n    -0.8186632680417568557122028\n    >>> legenq(-1.5, -2, 2.5)\n    (0.6655964618250228714288277 + 0.3937692045497259717762649j)\n    >>> legenq(2-j, 3+4j, -6+5j)\n    (-10001.95256487468541686564 - 6011.691337610097577791134j)\n\nDifferent versions of the function::\n\n    >>> legenq(2, 1, 0.5)\n    0.7298060598018049369381857\n    >>> legenq(2, 1, 1.5)\n    (-7.902916572420817192300921 + 0.1998650072605976600724502j)\n    >>> legenq(2, 1, 0.5, type=3)\n    (2.040524284763495081918338 - 0.7298060598018049369381857j)\n    >>> chop(legenq(2, 1, 1.5, type=3))\n    -0.1998650072605976600724502\n\n'
li: str = '\nComputes the logarithmic integral or li-function\n`\\mathrm{li}(x)`, defined by\n\n.. math ::\n\n    \\mathrm{li}(x) = \\int_0^x \\frac{1}{\\log t} \\, dt\n\nThe logarithmic integral has a singularity at `x = 1`.\n\nAlternatively, ``li(x, offset=True)`` computes the offset\nlogarithmic integral (used in number theory)\n\n.. math ::\n\n    \\mathrm{Li}(x) = \\int_2^x \\frac{1}{\\log t} \\, dt.\n\nThese two functions are related via the simple identity\n`\\mathrm{Li}(x) = \\mathrm{li}(x) - \\mathrm{li}(2)`.\n\nThe logarithmic integral should also not be confused with\nthe polylogarithm (also denoted by Li), which is implemented\nas :func:`~mpmath.polylog`.\n\n**Examples**\n\nSome basic values and limits::\n\n    >>> from mpmath import *\n    >>> mp.dps = 30; mp.pretty = True\n    >>> li(0)\n    0.0\n    >>> li(1)\n    -inf\n    >>> li(1)\n    -inf\n    >>> li(2)\n    1.04516378011749278484458888919\n    >>> findroot(li, 2)\n    1.45136923488338105028396848589\n    >>> li(inf)\n    +inf\n    >>> li(2, offset=True)\n    0.0\n    >>> li(1, offset=True)\n    -inf\n    >>> li(0, offset=True)\n    -1.04516378011749278484458888919\n    >>> li(10, offset=True)\n    5.12043572466980515267839286347\n\nThe logarithmic integral can be evaluated for arbitrary\ncomplex arguments::\n\n    >>> mp.dps = 20\n    >>> li(3+4j)\n    (3.1343755504645775265 + 2.6769247817778742392j)\n\nThe logarithmic integral is related to the exponential integral::\n\n    >>> ei(log(3))\n    2.1635885946671919729\n    >>> li(3)\n    2.1635885946671919729\n\nThe logarithmic integral grows like `O(x/\\log(x))`::\n\n    >>> mp.dps = 15\n    >>> x = 10**100\n    >>> x/log(x)\n    4.34294481903252e+97\n    >>> li(x)\n    4.3619719871407e+97\n\nThe prime number theorem states that the number of primes less\nthan `x` is asymptotic to `\\mathrm{Li}(x)` (equivalently\n`\\mathrm{li}(x)`). For example, it is known that there are\nexactly 1,925,320,391,606,803,968,923 prime numbers less than\n`10^{23}` [1]. The logarithmic integral provides a very\naccurate estimate::\n\n    >>> li(10**23, offset=True)\n    1.92532039161405e+21\n\nA definite integral is::\n\n    >>> quad(li, [0, 1])\n    -0.693147180559945\n    >>> -ln(2)\n    -0.693147180559945\n\n**References**\n\n1. http://mathworld.wolfram.com/PrimeCountingFunction.html\n\n2. http://mathworld.wolfram.com/LogarithmicIntegral.html\n\n'
ln: str = '\nComputes the natural logarithm of `x`, `\\ln x`.\nSee :func:`~mpmath.log` for additional documentation.'
log: str = '\nComputes the base-`b` logarithm of `x`, `\\log_b(x)`. If `b` is\nunspecified, :func:`~mpmath.log` computes the natural (base `e`) logarithm\nand is equivalent to :func:`~mpmath.ln`. In general, the base `b` logarithm\nis defined in terms of the natural logarithm as\n`\\log_b(x) = \\ln(x)/\\ln(b)`.\n\nBy convention, we take `\\log(0) = -\\infty`.\n\nThe natural logarithm is real if `x > 0` and complex if `x < 0` or if\n`x` is complex. The principal branch of the complex logarithm is\nused, meaning that `\\Im(\\ln(x)) = -\\pi < \\arg(x) \\le \\pi`.\n\n**Examples**\n\nSome basic values and limits::\n\n    >>> from mpmath import *\n    >>> mp.dps = 15; mp.pretty = True\n    >>> log(1)\n    0.0\n    >>> log(2)\n    0.693147180559945\n    >>> log(1000,10)\n    3.0\n    >>> log(4, 16)\n    0.5\n    >>> log(j)\n    (0.0 + 1.5707963267949j)\n    >>> log(-1)\n    (0.0 + 3.14159265358979j)\n    >>> log(0)\n    -inf\n    >>> log(inf)\n    +inf\n\nThe natural logarithm is the antiderivative of `1/x`::\n\n    >>> quad(lambda x: 1/x, [1, 5])\n    1.6094379124341\n    >>> log(5)\n    1.6094379124341\n    >>> diff(log, 10)\n    0.1\n\nThe Taylor series expansion of the natural logarithm around\n`x = 1` has coefficients `(-1)^{n+1}/n`::\n\n    >>> nprint(taylor(log, 1, 7))\n    [0.0, 1.0, -0.5, 0.333333, -0.25, 0.2, -0.166667, 0.142857]\n\n:func:`~mpmath.log` supports arbitrary precision evaluation::\n\n    >>> mp.dps = 50\n    >>> log(pi)\n    1.1447298858494001741434273513530587116472948129153\n    >>> log(pi, pi**3)\n    0.33333333333333333333333333333333333333333333333333\n    >>> mp.dps = 25\n    >>> log(3+4j)\n    (1.609437912434100374600759 + 0.9272952180016122324285125j)\n'
log10: str = '\nComputes the base-10 logarithm of `x`, `\\log_{10}(x)`. ``log10(x)``\nis equivalent to ``log(x, 10)``.\n'
log1p: str = '\nComputes `\\log(1+x)`, accurately for small `x`.\n\n    >>> from mpmath import *\n    >>> mp.dps = 15; mp.pretty = True\n    >>> log(1+1e-10); print(mp.log1p(1e-10))\n    1.00000008269037e-10\n    9.9999999995e-11\n    >>> mp.log1p(1e-100j)\n    (5.0e-201 + 1.0e-100j)\n    >>> mp.log1p(0)\n    0.0\n\n'
loggamma: str = "\nComputes the principal branch of the log-gamma function,\n`\\ln \\Gamma(z)`. Unlike `\\ln(\\Gamma(z))`, which has infinitely many\ncomplex branch cuts, the principal log-gamma function only has a single\nbranch cut along the negative half-axis. The principal branch\ncontinuously matches the asymptotic Stirling expansion\n\n.. math ::\n\n    \\ln \\Gamma(z) \\sim \\frac{\\ln(2 \\pi)}{2} +\n        \\left(z-\\frac{1}{2}\\right) \\ln(z) - z + O(z^{-1}).\n\nThe real parts of both functions agree, but their imaginary\nparts generally differ by `2 n \\pi` for some `n \\in \\mathbb{Z}`.\nThey coincide for `z \\in \\mathbb{R}, z > 0`.\n\nComputationally, it is advantageous to use :func:`~mpmath.loggamma`\ninstead of :func:`~mpmath.gamma` for extremely large arguments.\n\n**Examples**\n\nComparing with `\\ln(\\Gamma(z))`::\n\n    >>> from mpmath import *\n    >>> mp.dps = 25; mp.pretty = True\n    >>> loggamma('13.2'); log(gamma('13.2'))\n    20.49400419456603678498394\n    20.49400419456603678498394\n    >>> loggamma(3+4j)\n    (-1.756626784603784110530604 + 4.742664438034657928194889j)\n    >>> log(gamma(3+4j))\n    (-1.756626784603784110530604 - 1.540520869144928548730397j)\n    >>> log(gamma(3+4j)) + 2*pi*j\n    (-1.756626784603784110530604 + 4.742664438034657928194889j)\n\nNote the imaginary parts for negative arguments::\n\n    >>> loggamma(-0.5); loggamma(-1.5); loggamma(-2.5)\n    (1.265512123484645396488946 - 3.141592653589793238462643j)\n    (0.8600470153764810145109327 - 6.283185307179586476925287j)\n    (-0.05624371649767405067259453 - 9.42477796076937971538793j)\n\nSome special values::\n\n    >>> loggamma(1); loggamma(2)\n    0.0\n    0.0\n    >>> loggamma(3); +ln2\n    0.6931471805599453094172321\n    0.6931471805599453094172321\n    >>> loggamma(3.5); log(15*sqrt(pi)/8)\n    1.200973602347074224816022\n    1.200973602347074224816022\n    >>> loggamma(inf)\n    +inf\n\nHuge arguments are permitted::\n\n    >>> loggamma('1e30')\n    6.807755278982137052053974e+31\n    >>> loggamma('1e300')\n    6.897755278982137052053974e+302\n    >>> loggamma('1e3000')\n    6.906755278982137052053974e+3003\n    >>> loggamma('1e100000000000000000000')\n    2.302585092994045684007991e+100000000000000000020\n    >>> loggamma('1e30j')\n    (-1.570796326794896619231322e+30 + 6.807755278982137052053974e+31j)\n    >>> loggamma('1e300j')\n    (-1.570796326794896619231322e+300 + 6.897755278982137052053974e+302j)\n    >>> loggamma('1e3000j')\n    (-1.570796326794896619231322e+3000 + 6.906755278982137052053974e+3003j)\n\nThe log-gamma function can be integrated analytically\non any interval of unit length::\n\n    >>> z = 0\n    >>> quad(loggamma, [z,z+1]); log(2*pi)/2\n    0.9189385332046727417803297\n    0.9189385332046727417803297\n    >>> z = 3+4j\n    >>> quad(loggamma, [z,z+1]); (log(z)-1)*z + log(2*pi)/2\n    (-0.9619286014994750641314421 + 5.219637303741238195688575j)\n    (-0.9619286014994750641314421 + 5.219637303741238195688575j)\n\nThe derivatives of the log-gamma function are given by the\npolygamma function (:func:`~mpmath.psi`)::\n\n    >>> diff(loggamma, -4+3j); psi(0, -4+3j)\n    (1.688493531222971393607153 + 2.554898911356806978892748j)\n    (1.688493531222971393607153 + 2.554898911356806978892748j)\n    >>> diff(loggamma, -4+3j, 2); psi(1, -4+3j)\n    (-0.1539414829219882371561038 - 0.1020485197430267719746479j)\n    (-0.1539414829219882371561038 - 0.1020485197430267719746479j)\n\nThe log-gamma function satisfies an additive form of the\nrecurrence relation for the ordinary gamma function::\n\n    >>> z = 2+3j\n    >>> loggamma(z); loggamma(z+1) - log(z)\n    (-2.092851753092733349564189 + 2.302396543466867626153708j)\n    (-2.092851753092733349564189 + 2.302396543466867626153708j)\n\n"
lommels1: str = "\nGives the Lommel function `s_{\\mu,\\nu}` or `s^{(1)}_{\\mu,\\nu}`\n\n.. math ::\n\n    s_{\\mu,\\nu}(z) = \\frac{z^{\\mu+1}}{(\\mu-\\nu+1)(\\mu+\\nu+1)}\n        \\,_1F_2\\left(1; \\frac{\\mu-\\nu+3}{2}, \\frac{\\mu+\\nu+3}{2};\n        -\\frac{z^2}{4} \\right)\n\nwhich solves the inhomogeneous Bessel equation\n\n.. math ::\n\n    z^2 f''(z) + z f'(z) + (z^2-\\nu^2) f(z) = z^{\\mu+1}.\n\nA second solution is given by :func:`~mpmath.lommels2`.\n\n**Plots**\n\n.. literalinclude :: /plots/lommels1.py\n.. image :: /plots/lommels1.png\n\n**Examples**\n\nAn integral representation::\n\n    >>> from mpmath import *\n    >>> mp.dps = 25; mp.pretty = True\n    >>> u,v,z = 0.25, 0.125, mpf(0.75)\n    >>> lommels1(u,v,z)\n    0.4276243877565150372999126\n    >>> (bessely(v,z)*quad(lambda t: t**u*besselj(v,t), [0,z]) - \\\n    ...  besselj(v,z)*quad(lambda t: t**u*bessely(v,t), [0,z]))*(pi/2)\n    0.4276243877565150372999126\n\nA special value::\n\n    >>> lommels1(v,v,z)\n    0.5461221367746048054932553\n    >>> gamma(v+0.5)*sqrt(pi)*power(2,v-1)*struveh(v,z)\n    0.5461221367746048054932553\n\nVerifying the differential equation::\n\n    >>> f = lambda z: lommels1(u,v,z)\n    >>> z**2*diff(f,z,2) + z*diff(f,z) + (z**2-v**2)*f(z)\n    0.6979536443265746992059141\n    >>> z**(u+1)\n    0.6979536443265746992059141\n\n**References**\n\n1. [GradshteynRyzhik]_\n2. [Weisstein]_ http://mathworld.wolfram.com/LommelFunction.html\n"
lommels2: str = '\nGives the second Lommel function `S_{\\mu,\\nu}` or `s^{(2)}_{\\mu,\\nu}`\n\n.. math ::\n\n    S_{\\mu,\\nu}(z) = s_{\\mu,\\nu}(z) + 2^{\\mu-1}\n        \\Gamma\\left(\\tfrac{1}{2}(\\mu-\\nu+1)\\right)\n        \\Gamma\\left(\\tfrac{1}{2}(\\mu+\\nu+1)\\right) \\times\n\n        \\left[\\sin(\\tfrac{1}{2}(\\mu-\\nu)\\pi) J_{\\nu}(z) -\n              \\cos(\\tfrac{1}{2}(\\mu-\\nu)\\pi) Y_{\\nu}(z)\n        \\right]\n\nwhich solves the same differential equation as\n:func:`~mpmath.lommels1`.\n\n**Plots**\n\n.. literalinclude :: /plots/lommels2.py\n.. image :: /plots/lommels2.png\n\n**Examples**\n\nFor large `|z|`, `S_{\\mu,\\nu} \\sim z^{\\mu-1}`::\n\n    >>> from mpmath import *\n    >>> mp.dps = 25; mp.pretty = True\n    >>> lommels2(10,2,30000)\n    1.968299831601008419949804e+40\n    >>> power(30000,9)\n    1.9683e+40\n\nA special value::\n\n    >>> u,v,z = 0.5, 0.125, mpf(0.75)\n    >>> lommels2(v,v,z)\n    0.9589683199624672099969765\n    >>> (struveh(v,z)-bessely(v,z))*power(2,v-1)*sqrt(pi)*gamma(v+0.5)\n    0.9589683199624672099969765\n\nVerifying the differential equation::\n\n    >>> f = lambda z: lommels2(u,v,z)\n    >>> z**2*diff(f,z,2) + z*diff(f,z) + (z**2-v**2)*f(z)\n    0.6495190528383289850727924\n    >>> z**(u+1)\n    0.6495190528383289850727924\n\n**References**\n\n1. [GradshteynRyzhik]_\n2. [Weisstein]_ http://mathworld.wolfram.com/LommelFunction.html\n'
meijerg: str = "\nEvaluates the Meijer G-function, defined as\n\n.. math ::\n\n    G^{m,n}_{p,q} \\left( \\left. \\begin{matrix}\n         a_1, \\dots, a_n ; a_{n+1} \\dots a_p \\\\\n         b_1, \\dots, b_m ; b_{m+1} \\dots b_q\n    \\end{matrix}\\; \\right| \\; z ; r \\right) =\n    \\frac{1}{2 \\pi i} \\int_L\n    \\frac{\\prod_{j=1}^m \\Gamma(b_j+s) \\prod_{j=1}^n\\Gamma(1-a_j-s)}\n         {\\prod_{j=n+1}^{p}\\Gamma(a_j+s) \\prod_{j=m+1}^q \\Gamma(1-b_j-s)}\n         z^{-s/r} ds\n\nfor an appropriate choice of the contour `L` (see references).\n\nThere are `p` elements `a_j`.\nThe argument *a_s* should be a pair of lists, the first containing the\n`n` elements `a_1, \\ldots, a_n` and the second containing\nthe `p-n` elements `a_{n+1}, \\ldots a_p`.\n\nThere are `q` elements `b_j`.\nThe argument *b_s* should be a pair of lists, the first containing the\n`m` elements `b_1, \\ldots, b_m` and the second containing\nthe `q-m` elements `b_{m+1}, \\ldots b_q`.\n\nThe implicit tuple `(m, n, p, q)` constitutes the order or degree of the\nMeijer G-function, and is determined by the lengths of the coefficient\nvectors. Confusingly, the indices in this tuple appear in a different order\nfrom the coefficients, but this notation is standard. The many examples\ngiven below should hopefully clear up any potential confusion.\n\n**Algorithm**\n\nThe Meijer G-function is evaluated as a combination of hypergeometric series.\nThere are two versions of the function, which can be selected with\nthe optional *series* argument.\n\n*series=1* uses a sum of `m` `\\,_pF_{q-1}` functions of `z`\n\n*series=2* uses a sum of `n` `\\,_qF_{p-1}` functions of `1/z`\n\nThe default series is chosen based on the degree and `|z|` in order\nto be consistent with Mathematica's. This definition of the Meijer G-function\nhas a discontinuity at `|z| = 1` for some orders, which can\nbe avoided by explicitly specifying a series.\n\nKeyword arguments are forwarded to :func:`~mpmath.hypercomb`.\n\n**Examples**\n\nMany standard functions are special cases of the Meijer G-function\n(possibly rescaled and/or with branch cut corrections). We define\nsome test parameters::\n\n    >>> from mpmath import *\n    >>> mp.dps = 25; mp.pretty = True\n    >>> a = mpf(0.75)\n    >>> b = mpf(1.5)\n    >>> z = mpf(2.25)\n\nThe exponential function:\n`e^z = G^{1,0}_{0,1} \\left( \\left. \\begin{matrix} - \\\\ 0 \\end{matrix} \\;\n\\right| \\; -z \\right)`\n\n    >>> meijerg([[],[]], [[0],[]], -z)\n    9.487735836358525720550369\n    >>> exp(z)\n    9.487735836358525720550369\n\nThe natural logarithm:\n`\\log(1+z) = G^{1,2}_{2,2} \\left( \\left. \\begin{matrix} 1, 1 \\\\ 1, 0\n\\end{matrix} \\; \\right| \\; -z \\right)`\n\n    >>> meijerg([[1,1],[]], [[1],[0]], z)\n    1.178654996341646117219023\n    >>> log(1+z)\n    1.178654996341646117219023\n\nA rational function:\n`\\frac{z}{z+1} = G^{1,2}_{2,2} \\left( \\left. \\begin{matrix} 1, 1 \\\\ 1, 1\n\\end{matrix} \\; \\right| \\; z \\right)`\n\n    >>> meijerg([[1,1],[]], [[1],[1]], z)\n    0.6923076923076923076923077\n    >>> z/(z+1)\n    0.6923076923076923076923077\n\nThe sine and cosine functions:\n\n`\\frac{1}{\\sqrt \\pi} \\sin(2 \\sqrt z) = G^{1,0}_{0,2} \\left( \\left. \\begin{matrix}\n- \\\\ \\frac{1}{2}, 0 \\end{matrix} \\; \\right| \\; z \\right)`\n\n`\\frac{1}{\\sqrt \\pi} \\cos(2 \\sqrt z) = G^{1,0}_{0,2} \\left( \\left. \\begin{matrix}\n- \\\\ 0, \\frac{1}{2} \\end{matrix} \\; \\right| \\; z \\right)`\n\n    >>> meijerg([[],[]], [[0.5],[0]], (z/2)**2)\n    0.4389807929218676682296453\n    >>> sin(z)/sqrt(pi)\n    0.4389807929218676682296453\n    >>> meijerg([[],[]], [[0],[0.5]], (z/2)**2)\n    -0.3544090145996275423331762\n    >>> cos(z)/sqrt(pi)\n    -0.3544090145996275423331762\n\nBessel functions:\n\n`J_a(2 \\sqrt z) = G^{1,0}_{0,2} \\left( \\left.\n\\begin{matrix} - \\\\ \\frac{a}{2}, -\\frac{a}{2}\n\\end{matrix} \\; \\right| \\; z \\right)`\n\n`Y_a(2 \\sqrt z) = G^{2,0}_{1,3} \\left( \\left.\n\\begin{matrix} \\frac{-a-1}{2} \\\\ \\frac{a}{2}, -\\frac{a}{2}, \\frac{-a-1}{2}\n\\end{matrix} \\; \\right| \\; z \\right)`\n\n`(-z)^{a/2} z^{-a/2} I_a(2 \\sqrt z) = G^{1,0}_{0,2} \\left( \\left.\n\\begin{matrix} - \\\\ \\frac{a}{2}, -\\frac{a}{2}\n\\end{matrix} \\; \\right| \\; -z \\right)`\n\n`2 K_a(2 \\sqrt z) = G^{2,0}_{0,2} \\left( \\left.\n\\begin{matrix} - \\\\ \\frac{a}{2}, -\\frac{a}{2}\n\\end{matrix} \\; \\right| \\; z \\right)`\n\nAs the example with the Bessel *I* function shows, a branch\nfactor is required for some arguments when inverting the square root.\n\n    >>> meijerg([[],[]], [[a/2],[-a/2]], (z/2)**2)\n    0.5059425789597154858527264\n    >>> besselj(a,z)\n    0.5059425789597154858527264\n    >>> meijerg([[],[(-a-1)/2]], [[a/2,-a/2],[(-a-1)/2]], (z/2)**2)\n    0.1853868950066556941442559\n    >>> bessely(a, z)\n    0.1853868950066556941442559\n    >>> meijerg([[],[]], [[a/2],[-a/2]], -(z/2)**2)\n    (0.8685913322427653875717476 + 2.096964974460199200551738j)\n    >>> (-z)**(a/2) / z**(a/2) * besseli(a, z)\n    (0.8685913322427653875717476 + 2.096964974460199200551738j)\n    >>> 0.5*meijerg([[],[]], [[a/2,-a/2],[]], (z/2)**2)\n    0.09334163695597828403796071\n    >>> besselk(a,z)\n    0.09334163695597828403796071\n\nError functions:\n\n`\\sqrt{\\pi} z^{2(a-1)} \\mathrm{erfc}(z) = G^{2,0}_{1,2} \\left( \\left.\n\\begin{matrix} a \\\\ a-1, a-\\frac{1}{2}\n\\end{matrix} \\; \\right| \\; z, \\frac{1}{2} \\right)`\n\n    >>> meijerg([[],[a]], [[a-1,a-0.5],[]], z, 0.5)\n    0.00172839843123091957468712\n    >>> sqrt(pi) * z**(2*a-2) * erfc(z)\n    0.00172839843123091957468712\n\nA Meijer G-function of higher degree, (1,1,2,3):\n\n    >>> meijerg([[a],[b]], [[a],[b,a-1]], z)\n    1.55984467443050210115617\n    >>> sin((b-a)*pi)/pi*(exp(z)-1)*z**(a-1)\n    1.55984467443050210115617\n\nA Meijer G-function of still higher degree, (4,1,2,4), that can\nbe expanded as a messy combination of exponential integrals:\n\n    >>> meijerg([[a],[2*b-a]], [[b,a,b-0.5,-1-a+2*b],[]], z)\n    0.3323667133658557271898061\n    >>> chop(4**(a-b+1)*sqrt(pi)*gamma(2*b-2*a)*z**a*\\\n    ...     expint(2*b-2*a, -2*sqrt(-z))*expint(2*b-2*a, 2*sqrt(-z)))\n    0.3323667133658557271898061\n\nIn the following case, different series give different values::\n\n    >>> chop(meijerg([[1],[0.25]],[[3],[0.5]],-2))\n    -0.06417628097442437076207337\n    >>> meijerg([[1],[0.25]],[[3],[0.5]],-2,series=1)\n    0.1428699426155117511873047\n    >>> chop(meijerg([[1],[0.25]],[[3],[0.5]],-2,series=2))\n    -0.06417628097442437076207337\n\n**References**\n\n1. http://en.wikipedia.org/wiki/Meijer_G-function\n\n2. http://mathworld.wolfram.com/MeijerG-Function.html\n\n3. http://functions.wolfram.com/HypergeometricFunctions/MeijerG/\n\n4. http://functions.wolfram.com/HypergeometricFunctions/MeijerG1/\n\n"
mertens: str = "\nRepresents the Mertens or Meissel-Mertens constant, which is the\nprime number analog of Euler's constant:\n\n.. math ::\n\n    B_1 = \\lim_{N\\to\\infty}\n        \\left(\\sum_{p_k \\le N} \\frac{1}{p_k} - \\log \\log N \\right)\n\nHere `p_k` denotes the `k`-th prime number. Other names for this\nconstant include the Hadamard-de la Vallee-Poussin constant or\nthe prime reciprocal constant.\n\nThe following gives the Mertens constant to 50 digits::\n\n    >>> from mpmath import *\n    >>> mp.dps = 50; mp.pretty = True\n    >>> +mertens\n    0.2614972128476427837554268386086958590515666482612\n\nReferences:\nhttp://mathworld.wolfram.com/MertensConstant.html\n"
ncdf: str = '\n``ncdf(x, mu=0, sigma=1)`` evaluates the cumulative distribution\nfunction of a normal distribution with mean value `\\mu`\nand variance `\\sigma^2`.\n\nSee also :func:`~mpmath.npdf`, which gives the probability density.\n\nElementary properties include::\n\n    >>> from mpmath import *\n    >>> mp.dps = 15; mp.pretty = True\n    >>> ncdf(pi, mu=pi)\n    0.5\n    >>> ncdf(-inf)\n    0.0\n    >>> ncdf(+inf)\n    1.0\n\nThe cumulative distribution is the integral of the density\nfunction having identical mu and sigma::\n\n    >>> mp.dps = 15\n    >>> diff(ncdf, 2)\n    0.053990966513188\n    >>> npdf(2)\n    0.053990966513188\n    >>> diff(lambda x: ncdf(x, 1, 0.5), 0)\n    0.107981933026376\n    >>> npdf(0, 1, 0.5)\n    0.107981933026376\n'
nint: str = "\nEvaluates the nearest integer function, `\\mathrm{nint}(x)`.\nThis gives the nearest integer to `x`; on a tie, it\ngives the nearest even integer::\n\n    >>> from mpmath import *\n    >>> mp.pretty = False\n    >>> nint(3.2)\n    mpf('3.0')\n    >>> nint(3.8)\n    mpf('4.0')\n    >>> nint(3.5)\n    mpf('4.0')\n    >>> nint(4.5)\n    mpf('4.0')\n\nThe nearest integer function is defined for complex numbers and\nacts on the real and imaginary parts separately::\n\n    >>> nint(3.25+4.75j)\n    mpc(real='3.0', imag='5.0')\n\nSee notes about rounding for :func:`~mpmath.floor`.\n"
npdf: str = '\n``npdf(x, mu=0, sigma=1)`` evaluates the probability density\nfunction of a normal distribution with mean value `\\mu`\nand variance `\\sigma^2`.\n\nElementary properties of the probability distribution can\nbe verified using numerical integration::\n\n    >>> from mpmath import *\n    >>> mp.dps = 15; mp.pretty = True\n    >>> quad(npdf, [-inf, inf])\n    1.0\n    >>> quad(lambda x: npdf(x, 3), [3, inf])\n    0.5\n    >>> quad(lambda x: npdf(x, 3, 2), [3, inf])\n    0.5\n\nSee also :func:`~mpmath.ncdf`, which gives the cumulative\ndistribution.\n'
phi: str = '\nRepresents the golden ratio `\\phi = (1+\\sqrt 5)/2`,\napproximately equal to 1.6180339887. To high precision,\nits value is::\n\n    >>> from mpmath import *\n    >>> mp.dps = 50; mp.pretty = True\n    >>> +phi\n    1.6180339887498948482045868343656381177203091798058\n\nFormulas for the golden ratio include the following::\n\n    >>> (1+sqrt(5))/2\n    1.6180339887498948482045868343656381177203091798058\n    >>> findroot(lambda x: x**2-x-1, 1)\n    1.6180339887498948482045868343656381177203091798058\n    >>> limit(lambda n: fib(n+1)/fib(n), inf)\n    1.6180339887498948482045868343656381177203091798058\n'
pi: str = "\n`\\pi`, roughly equal to 3.141592654, represents the area of the unit\ncircle, the half-period of trigonometric functions, and many other\nthings in mathematics.\n\nMpmath can evaluate `\\pi` to arbitrary precision::\n\n    >>> from mpmath import *\n    >>> mp.dps = 50; mp.pretty = True\n    >>> +pi\n    3.1415926535897932384626433832795028841971693993751\n\nThis shows digits 99991-100000 of `\\pi` (the last digit is actually\na 4 when the decimal expansion is truncated, but here the nearest\nrounding is used)::\n\n    >>> mp.dps = 100000\n    >>> str(pi)[-10:]\n    '5549362465'\n\n**Possible issues**\n\n:data:`pi` always rounds to the nearest floating-point\nnumber when used. This means that exact mathematical identities\ninvolving `\\pi` will generally not be preserved in floating-point\narithmetic. In particular, multiples of :data:`pi` (except for\nthe trivial case ``0*pi``) are *not* the exact roots of\n:func:`~mpmath.sin`, but differ roughly by the current epsilon::\n\n    >>> mp.dps = 15\n    >>> sin(pi)\n    1.22464679914735e-16\n\nOne solution is to use the :func:`~mpmath.sinpi` function instead::\n\n    >>> sinpi(1)\n    0.0\n\nSee the documentation of trigonometric functions for additional\ndetails.\n\n**References**\n\n* [BorweinBorwein]_\n\n"
polar: str = '\nReturns the polar representation of the complex number `z`\nas a pair `(r, \\phi)` such that `z = r e^{i \\phi}`::\n\n    >>> from mpmath import *\n    >>> mp.dps = 15; mp.pretty = True\n    >>> polar(-2)\n    (2.0, 3.14159265358979)\n    >>> polar(3-4j)\n    (5.0, -0.927295218001612)\n'
polyexp: str = '\nEvaluates the polyexponential function, defined for arbitrary\ncomplex `s`, `z` by the series\n\n.. math ::\n\n    E_s(z) = \\sum_{k=1}^{\\infty} \\frac{k^s}{k!} z^k.\n\n`E_s(z)` is constructed from the exponential function analogously\nto how the polylogarithm is constructed from the ordinary\nlogarithm; as a function of `s` (with `z` fixed), `E_s` is an L-series\nIt is an entire function of both `s` and `z`.\n\nThe polyexponential function provides a generalization of the\nBell polynomials `B_n(x)` (see :func:`~mpmath.bell`) to noninteger orders `n`.\nIn terms of the Bell polynomials,\n\n.. math ::\n\n    E_s(z) = e^z B_s(z) - \\mathrm{sinc}(\\pi s).\n\nNote that `B_n(x)` and `e^{-x} E_n(x)` are identical if `n`\nis a nonzero integer, but not otherwise. In particular, they differ\nat `n = 0`.\n\n**Examples**\n\nEvaluating a series::\n\n    >>> from mpmath import *\n    >>> mp.dps = 25; mp.pretty = True\n    >>> nsum(lambda k: sqrt(k)/fac(k), [1,inf])\n    2.101755547733791780315904\n    >>> polyexp(0.5,1)\n    2.101755547733791780315904\n\nEvaluation for arbitrary arguments::\n\n    >>> polyexp(-3-4j, 2.5+2j)\n    (2.351660261190434618268706 + 1.202966666673054671364215j)\n\nEvaluation is accurate for tiny function values::\n\n    >>> polyexp(4, -100)\n    3.499471750566824369520223e-36\n\nIf `n` is a nonpositive integer, `E_n` reduces to a special\ninstance of the hypergeometric function `\\,_pF_q`::\n\n    >>> n = 3\n    >>> x = pi\n    >>> polyexp(-n,x)\n    4.042192318847986561771779\n    >>> x*hyper([1]*(n+1), [2]*(n+1), x)\n    4.042192318847986561771779\n\n'
polylog: str = '\nComputes the polylogarithm, defined by the sum\n\n.. math ::\n\n    \\mathrm{Li}_s(z) = \\sum_{k=1}^{\\infty} \\frac{z^k}{k^s}.\n\nThis series is convergent only for `|z| < 1`, so elsewhere\nthe analytic continuation is implied.\n\nThe polylogarithm should not be confused with the logarithmic\nintegral (also denoted by Li or li), which is implemented\nas :func:`~mpmath.li`.\n\n**Examples**\n\nThe polylogarithm satisfies a huge number of functional identities.\nA sample of polylogarithm evaluations is shown below::\n\n    >>> from mpmath import *\n    >>> mp.dps = 15; mp.pretty = True\n    >>> polylog(1,0.5), log(2)\n    (0.693147180559945, 0.693147180559945)\n    >>> polylog(2,0.5), (pi**2-6*log(2)**2)/12\n    (0.582240526465012, 0.582240526465012)\n    >>> polylog(2,-phi), -log(phi)**2-pi**2/10\n    (-1.21852526068613, -1.21852526068613)\n    >>> polylog(3,0.5), 7*zeta(3)/8-pi**2*log(2)/12+log(2)**3/6\n    (0.53721319360804, 0.53721319360804)\n\n:func:`~mpmath.polylog` can evaluate the analytic continuation of the\npolylogarithm when `s` is an integer::\n\n    >>> polylog(2, 10)\n    (0.536301287357863 - 7.23378441241546j)\n    >>> polylog(2, -10)\n    -4.1982778868581\n    >>> polylog(2, 10j)\n    (-3.05968879432873 + 3.71678149306807j)\n    >>> polylog(-2, 10)\n    -0.150891632373114\n    >>> polylog(-2, -10)\n    0.067618332081142\n    >>> polylog(-2, 10j)\n    (0.0384353698579347 + 0.0912451798066779j)\n\nSome more examples, with arguments on the unit circle (note that\nthe series definition cannot be used for computation here)::\n\n    >>> polylog(2,j)\n    (-0.205616758356028 + 0.915965594177219j)\n    >>> j*catalan-pi**2/48\n    (-0.205616758356028 + 0.915965594177219j)\n    >>> polylog(3,exp(2*pi*j/3))\n    (-0.534247512515375 + 0.765587078525922j)\n    >>> -4*zeta(3)/9 + 2*j*pi**3/81\n    (-0.534247512515375 + 0.765587078525921j)\n\nPolylogarithms of different order are related by integration\nand differentiation::\n\n    >>> s, z = 3, 0.5\n    >>> polylog(s+1, z)\n    0.517479061673899\n    >>> quad(lambda t: polylog(s,t)/t, [0, z])\n    0.517479061673899\n    >>> z*diff(lambda t: polylog(s+2,t), z)\n    0.517479061673899\n\nTaylor series expansions around `z = 0` are::\n\n    >>> for n in range(-3, 4):\n    ...     nprint(taylor(lambda x: polylog(n,x), 0, 5))\n    ...\n    [0.0, 1.0, 8.0, 27.0, 64.0, 125.0]\n    [0.0, 1.0, 4.0, 9.0, 16.0, 25.0]\n    [0.0, 1.0, 2.0, 3.0, 4.0, 5.0]\n    [0.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n    [0.0, 1.0, 0.5, 0.333333, 0.25, 0.2]\n    [0.0, 1.0, 0.25, 0.111111, 0.0625, 0.04]\n    [0.0, 1.0, 0.125, 0.037037, 0.015625, 0.008]\n\nThe series defining the polylogarithm is simultaneously\na Taylor series and an L-series. For certain values of `z`, the\npolylogarithm reduces to a pure zeta function::\n\n    >>> polylog(pi, 1), zeta(pi)\n    (1.17624173838258, 1.17624173838258)\n    >>> polylog(pi, -1), -altzeta(pi)\n    (-0.909670702980385, -0.909670702980385)\n\nEvaluation for arbitrary, nonintegral `s` is supported\nfor `z` within the unit circle:\n\n    >>> polylog(3+4j, 0.25)\n    (0.24258605789446 - 0.00222938275488344j)\n    >>> nsum(lambda k: 0.25**k / k**(3+4j), [1,inf])\n    (0.24258605789446 - 0.00222938275488344j)\n\nIt is also supported outside of the unit circle::\n\n    >>> polylog(1+j, 20+40j)\n    (-7.1421172179728 - 3.92726697721369j)\n    >>> polylog(1+j, 200+400j)\n    (-5.41934747194626 - 9.94037752563927j)\n\n**References**\n\n1. Richard Crandall, "Note on fast polylogarithm computation"\n   http://www.reed.edu/physics/faculty/crandall/papers/Polylog.pdf\n2. http://en.wikipedia.org/wiki/Polylogarithm\n3. http://mathworld.wolfram.com/Polylogarithm.html\n\n'
powm1: str = "\nComputes `x^y - 1`, accurately when `x^y` is very close to 1.\n\nThis avoids potentially catastrophic cancellation::\n\n    >>> from mpmath import *\n    >>> mp.dps = 15; mp.pretty = True\n    >>> power(0.99999995, 1e-10) - 1\n    0.0\n    >>> powm1(0.99999995, 1e-10)\n    -5.00000012791934e-18\n\nPowers exactly equal to 1, and only those powers, yield 0 exactly::\n\n    >>> powm1(-j, 4)\n    (0.0 + 0.0j)\n    >>> powm1(3, 0)\n    0.0\n    >>> powm1(fadd(-1, 1e-100, exact=True), 4)\n    -4.0e-100\n\nEvaluation works for extremely tiny `y`::\n\n    >>> powm1(2, '1e-100000')\n    6.93147180559945e-100001\n    >>> powm1(j, '1e-1000')\n    (-1.23370055013617e-2000 + 1.5707963267949e-1000j)\n\n"
primepi: str = '\nEvaluates the prime counting function, `\\pi(x)`, which gives\nthe number of primes less than or equal to `x`. The argument\n`x` may be fractional.\n\nThe prime counting function is very expensive to evaluate\nprecisely for large `x`, and the present implementation is\nnot optimized in any way. For numerical approximation of the\nprime counting function, it is better to use :func:`~mpmath.primepi2`\nor :func:`~mpmath.riemannr`.\n\nSome values of the prime counting function::\n\n    >>> from mpmath import *\n    >>> [primepi(k) for k in range(20)]\n    [0, 0, 1, 2, 2, 3, 3, 4, 4, 4, 4, 5, 5, 6, 6, 6, 6, 7, 7, 8]\n    >>> primepi(3.5)\n    2\n    >>> primepi(100000)\n    9592\n\n'
primepi2: str = "\nReturns an interval (as an ``mpi`` instance) providing bounds\nfor the value of the prime counting function `\\pi(x)`. For small\n`x`, :func:`~mpmath.primepi2` returns an exact interval based on\nthe output of :func:`~mpmath.primepi`. For `x > 2656`, a loose interval\nbased on Schoenfeld's inequality\n\n.. math ::\n\n    |\\pi(x) - \\mathrm{li}(x)| < \\frac{\\sqrt x \\log x}{8 \\pi}\n\nis returned. This estimate is rigorous assuming the truth of\nthe Riemann hypothesis, and can be computed very quickly.\n\n**Examples**\n\nExact values of the prime counting function for small `x`::\n\n    >>> from mpmath import *\n    >>> mp.dps = 15; mp.pretty = True\n    >>> iv.dps = 15; iv.pretty = True\n    >>> primepi2(10)\n    [4.0, 4.0]\n    >>> primepi2(100)\n    [25.0, 25.0]\n    >>> primepi2(1000)\n    [168.0, 168.0]\n\nLoose intervals are generated for moderately large `x`:\n\n    >>> primepi2(10000), primepi(10000)\n    ([1209.0, 1283.0], 1229)\n    >>> primepi2(50000), primepi(50000)\n    ([5070.0, 5263.0], 5133)\n\nAs `x` increases, the absolute error gets worse while the relative\nerror improves. The exact value of `\\pi(10^{23})` is\n1925320391606803968923, and :func:`~mpmath.primepi2` gives 9 significant\ndigits::\n\n    >>> p = primepi2(10**23)\n    >>> p\n    [1.9253203909477020467e+21, 1.925320392280406229e+21]\n    >>> mpf(p.delta) / mpf(p.a)\n    6.9219865355293e-10\n\nA more precise, nonrigorous estimate for `\\pi(x)` can be\nobtained using the Riemann R function (:func:`~mpmath.riemannr`).\nFor large enough `x`, the value returned by :func:`~mpmath.primepi2`\nessentially amounts to a small perturbation of the value returned by\n:func:`~mpmath.riemannr`::\n\n    >>> primepi2(10**100)\n    [4.3619719871407024816e+97, 4.3619719871407032404e+97]\n    >>> riemannr(10**100)\n    4.3619719871407e+97\n"
primezeta: str = '\nComputes the prime zeta function, which is defined\nin analogy with the Riemann zeta function (:func:`~mpmath.zeta`)\nas\n\n.. math ::\n\n    P(s) = \\sum_p \\frac{1}{p^s}\n\nwhere the sum is taken over all prime numbers `p`. Although\nthis sum only converges for `\\mathrm{Re}(s) > 1`, the\nfunction is defined by analytic continuation in the\nhalf-plane `\\mathrm{Re}(s) > 0`.\n\n**Examples**\n\nArbitrary-precision evaluation for real and complex arguments is\nsupported::\n\n    >>> from mpmath import *\n    >>> mp.dps = 30; mp.pretty = True\n    >>> primezeta(2)\n    0.452247420041065498506543364832\n    >>> primezeta(pi)\n    0.15483752698840284272036497397\n    >>> mp.dps = 50\n    >>> primezeta(3)\n    0.17476263929944353642311331466570670097541212192615\n    >>> mp.dps = 20\n    >>> primezeta(3+4j)\n    (-0.12085382601645763295 - 0.013370403397787023602j)\n\nThe prime zeta function has a logarithmic pole at `s = 1`,\nwith residue equal to the difference of the Mertens and\nEuler constants::\n\n    >>> primezeta(1)\n    +inf\n    >>> extradps(25)(lambda x: primezeta(1+x)+log(x))(+eps)\n    -0.31571845205389007685\n    >>> mertens-euler\n    -0.31571845205389007685\n\nThe analytic continuation to `0 < \\mathrm{Re}(s) \\le 1`\nis implemented. In this strip the function exhibits\nvery complex behavior; on the unit interval, it has poles at\n`1/n` for every squarefree integer `n`::\n\n    >>> primezeta(0.5)         # Pole at s = 1/2\n    (-inf + 3.1415926535897932385j)\n    >>> primezeta(0.25)\n    (-1.0416106801757269036 + 0.52359877559829887308j)\n    >>> primezeta(0.5+10j)\n    (0.54892423556409790529 + 0.45626803423487934264j)\n\nAlthough evaluation works in principle for any `\\mathrm{Re}(s) > 0`,\nit should be noted that the evaluation time increases exponentially\nas `s` approaches the imaginary axis.\n\nFor large `\\mathrm{Re}(s)`, `P(s)` is asymptotic to `2^{-s}`::\n\n    >>> primezeta(inf)\n    0.0\n    >>> primezeta(10), mpf(2)**-10\n    (0.00099360357443698021786, 0.0009765625)\n    >>> primezeta(1000)\n    9.3326361850321887899e-302\n    >>> primezeta(1000+1000j)\n    (-3.8565440833654995949e-302 - 8.4985390447553234305e-302j)\n\n**References**\n\nCarl-Erik Froberg, "On the prime zeta function",\nBIT 8 (1968), pp. 187-202.\n\n'
psi: str = "\nGives the polygamma function of order `m` of `z`, `\\psi^{(m)}(z)`.\nSpecial cases are known as the *digamma function* (`\\psi^{(0)}(z)`),\nthe *trigamma function* (`\\psi^{(1)}(z)`), etc. The polygamma\nfunctions are defined as the logarithmic derivatives of the gamma\nfunction:\n\n.. math ::\n\n    \\psi^{(m)}(z) = \\left(\\frac{d}{dz}\\right)^{m+1} \\log \\Gamma(z)\n\nIn particular, `\\psi^{(0)}(z) = \\Gamma'(z)/\\Gamma(z)`. In the\npresent implementation of :func:`~mpmath.psi`, the order `m` must be a\nnonnegative integer, while the argument `z` may be an arbitrary\ncomplex number (with exception for the polygamma function's poles\nat `z = 0, -1, -2, \\ldots`).\n\n**Examples**\n\nFor various rational arguments, the polygamma function reduces to\na combination of standard mathematical constants::\n\n    >>> from mpmath import *\n    >>> mp.dps = 25; mp.pretty = True\n    >>> psi(0, 1), -euler\n    (-0.5772156649015328606065121, -0.5772156649015328606065121)\n    >>> psi(1, '1/4'), pi**2+8*catalan\n    (17.19732915450711073927132, 17.19732915450711073927132)\n    >>> psi(2, '1/2'), -14*apery\n    (-16.82879664423431999559633, -16.82879664423431999559633)\n\nThe polygamma functions are derivatives of each other::\n\n    >>> diff(lambda x: psi(3, x), pi), psi(4, pi)\n    (-0.1105749312578862734526952, -0.1105749312578862734526952)\n    >>> quad(lambda x: psi(4, x), [2, 3]), psi(3,3)-psi(3,2)\n    (-0.375, -0.375)\n\nThe digamma function diverges logarithmically as `z \\to \\infty`,\nwhile higher orders tend to zero::\n\n    >>> psi(0,inf), psi(1,inf), psi(2,inf)\n    (+inf, 0.0, 0.0)\n\nEvaluation for a complex argument::\n\n    >>> psi(2, -1-2j)\n    (0.03902435405364952654838445 + 0.1574325240413029954685366j)\n\nEvaluation is supported for large orders `m` and/or large\narguments `z`::\n\n    >>> psi(3, 10**100)\n    2.0e-300\n    >>> psi(250, 10**30+10**20*j)\n    (-1.293142504363642687204865e-7010 + 3.232856260909107391513108e-7018j)\n\n**Application to infinite series**\n\nAny infinite series where the summand is a rational function of\nthe index `k` can be evaluated in closed form in terms of polygamma\nfunctions of the roots and poles of the summand::\n\n    >>> a = sqrt(2)\n    >>> b = sqrt(3)\n    >>> nsum(lambda k: 1/((k+a)**2*(k+b)), [0, inf])\n    0.4049668927517857061917531\n    >>> (psi(0,a)-psi(0,b)-a*psi(1,a)+b*psi(1,a))/(a-b)**2\n    0.4049668927517857061917531\n\nThis follows from the series representation (`m > 0`)\n\n.. math ::\n\n    \\psi^{(m)}(z) = (-1)^{m+1} m! \\sum_{k=0}^{\\infty}\n        \\frac{1}{(z+k)^{m+1}}.\n\nSince the roots of a polynomial may be complex, it is sometimes\nnecessary to use the complex polygamma function to evaluate\nan entirely real-valued sum::\n\n    >>> nsum(lambda k: 1/(k**2-2*k+3), [0, inf])\n    1.694361433907061256154665\n    >>> nprint(polyroots([1,-2,3]))\n    [(1.0 - 1.41421j), (1.0 + 1.41421j)]\n    >>> r1 = 1-sqrt(2)*j\n    >>> r2 = r1.conjugate()\n    >>> (psi(0,-r2)-psi(0,-r1))/(r1-r2)\n    (1.694361433907061256154665 + 0.0j)\n\n"
radians: str = '\nConverts the degree angle `x` to radians::\n\n    >>> from mpmath import *\n    >>> mp.dps = 15; mp.pretty = True\n    >>> radians(60)\n    1.0471975511966\n'
re: str = "\nReturns the real part of `x`, `\\Re(x)`. :func:`~mpmath.re`\nconverts a non-mpmath number to an mpmath number::\n\n    >>> from mpmath import *\n    >>> mp.dps = 15; mp.pretty = False\n    >>> re(3)\n    mpf('3.0')\n    >>> re(-1+4j)\n    mpf('-1.0')\n"
rect: str = '\nReturns the complex number represented by polar\ncoordinates `(r, \\phi)`::\n\n    >>> from mpmath import *\n    >>> mp.dps = 15; mp.pretty = True\n    >>> chop(rect(2, pi))\n    -2.0\n    >>> rect(sqrt(2), -pi/4)\n    (1.0 - 1.0j)\n'
rf: str = '\nComputes the rising factorial or Pochhammer symbol,\n\n.. math ::\n\n    x^{(n)} = x (x+1) \\cdots (x+n-1) = \\frac{\\Gamma(x+n)}{\\Gamma(x)}\n\nwhere the rightmost expression is valid for nonintegral `n`.\n\n**Examples**\n\nFor integral `n`, the rising factorial is a polynomial::\n\n    >>> from mpmath import *\n    >>> mp.dps = 15; mp.pretty = True\n    >>> for n in range(5):\n    ...     nprint(taylor(lambda x: rf(x,n), 0, n))\n    ...\n    [1.0]\n    [0.0, 1.0]\n    [0.0, 1.0, 1.0]\n    [0.0, 2.0, 3.0, 1.0]\n    [0.0, 6.0, 11.0, 6.0, 1.0]\n\nEvaluation is supported for arbitrary arguments::\n\n    >>> rf(2+3j, 5.5)\n    (-7202.03920483347 - 3777.58810701527j)\n'
rgamma: str = '\nComputes the reciprocal of the gamma function, `1/\\Gamma(z)`. This\nfunction evaluates to zero at the poles\nof the gamma function, `z = 0, -1, -2, \\ldots`.\n\n**Examples**\n\nBasic examples::\n\n    >>> from mpmath import *\n    >>> mp.dps = 25; mp.pretty = True\n    >>> rgamma(1)\n    1.0\n    >>> rgamma(4)\n    0.1666666666666666666666667\n    >>> rgamma(0); rgamma(-1)\n    0.0\n    0.0\n    >>> rgamma(1000)\n    2.485168143266784862783596e-2565\n    >>> rgamma(inf)\n    0.0\n\nA definite integral that can be evaluated in terms of elementary\nintegrals::\n\n    >>> quad(rgamma, [0,inf])\n    2.807770242028519365221501\n    >>> e + quad(lambda t: exp(-t)/(pi**2+log(t)**2), [0,inf])\n    2.807770242028519365221501\n'
riemannr: str = '\nEvaluates the Riemann R function, a smooth approximation of the\nprime counting function `\\pi(x)` (see :func:`~mpmath.primepi`). The Riemann\nR function gives a fast numerical approximation useful e.g. to\nroughly estimate the number of primes in a given interval.\n\nThe Riemann R function is computed using the rapidly convergent Gram\nseries,\n\n.. math ::\n\n    R(x) = 1 + \\sum_{k=1}^{\\infty}\n        \\frac{\\log^k x}{k k! \\zeta(k+1)}.\n\nFrom the Gram series, one sees that the Riemann R function is a\nwell-defined analytic function (except for a branch cut along\nthe negative real half-axis); it can be evaluated for arbitrary\nreal or complex arguments.\n\nThe Riemann R function gives a very accurate approximation\nof the prime counting function. For example, it is wrong by at\nmost 2 for `x < 1000`, and for `x = 10^9` differs from the exact\nvalue of `\\pi(x)` by 79, or less than two parts in a million.\nIt is about 10 times more accurate than the logarithmic integral\nestimate (see :func:`~mpmath.li`), which however is even faster to evaluate.\nIt is orders of magnitude more accurate than the extremely\nfast `x/\\log x` estimate.\n\n**Examples**\n\nFor small arguments, the Riemann R function almost exactly\ngives the prime counting function if rounded to the nearest\ninteger::\n\n    >>> from mpmath import *\n    >>> mp.dps = 15; mp.pretty = True\n    >>> primepi(50), riemannr(50)\n    (15, 14.9757023241462)\n    >>> max(abs(primepi(n)-int(round(riemannr(n)))) for n in range(100))\n    1\n    >>> max(abs(primepi(n)-int(round(riemannr(n)))) for n in range(300))\n    2\n\nThe Riemann R function can be evaluated for arguments far too large\nfor exact determination of `\\pi(x)` to be computationally\nfeasible with any presently known algorithm::\n\n    >>> riemannr(10**30)\n    1.46923988977204e+28\n    >>> riemannr(10**100)\n    4.3619719871407e+97\n    >>> riemannr(10**1000)\n    4.3448325764012e+996\n\nA comparison of the Riemann R function and logarithmic integral estimates\nfor `\\pi(x)` using exact values of `\\pi(10^n)` up to `n = 9`.\nThe fractional error is shown in parentheses::\n\n    >>> exact = [4,25,168,1229,9592,78498,664579,5761455,50847534]\n    >>> for n, p in enumerate(exact):\n    ...     n += 1\n    ...     r, l = riemannr(10**n), li(10**n)\n    ...     rerr, lerr = nstr((r-p)/p,3), nstr((l-p)/p,3)\n    ...     print("%i %i %s(%s) %s(%s)" % (n, p, r, rerr, l, lerr))\n    ...\n    1 4 4.56458314100509(0.141) 6.1655995047873(0.541)\n    2 25 25.6616332669242(0.0265) 30.1261415840796(0.205)\n    3 168 168.359446281167(0.00214) 177.609657990152(0.0572)\n    4 1229 1226.93121834343(-0.00168) 1246.13721589939(0.0139)\n    5 9592 9587.43173884197(-0.000476) 9629.8090010508(0.00394)\n    6 78498 78527.3994291277(0.000375) 78627.5491594622(0.00165)\n    7 664579 664667.447564748(0.000133) 664918.405048569(0.000511)\n    8 5761455 5761551.86732017(1.68e-5) 5762209.37544803(0.000131)\n    9 50847534 50847455.4277214(-1.55e-6) 50849234.9570018(3.35e-5)\n\nThe derivative of the Riemann R function gives the approximate\nprobability for a number of magnitude `x` to be prime::\n\n    >>> diff(riemannr, 1000)\n    0.141903028110784\n    >>> mpf(primepi(1050) - primepi(950)) / 100\n    0.15\n\nEvaluation is supported for arbitrary arguments and at arbitrary\nprecision::\n\n    >>> mp.dps = 30\n    >>> riemannr(7.5)\n    3.72934743264966261918857135136\n    >>> riemannr(-4+2j)\n    (-0.551002208155486427591793957644 + 2.16966398138119450043195899746j)\n\n'
root: str = '\n``root(z, n, k=0)`` computes an `n`-th root of `z`, i.e. returns a number\n`r` that (up to possible approximation error) satisfies `r^n = z`.\n(``nthroot`` is available as an alias for ``root``.)\n\nEvery complex number `z \\ne 0` has `n` distinct `n`-th roots, which are\nequidistant points on a circle with radius `|z|^{1/n}`, centered around the\norigin. A specific root may be selected using the optional index\n`k`. The roots are indexed counterclockwise, starting with `k = 0` for the root\nclosest to the positive real half-axis.\n\nThe `k = 0` root is the so-called principal `n`-th root, often denoted by\n`\\sqrt[n]{z}` or `z^{1/n}`, and also given by `\\exp(\\log(z) / n)`. If `z` is\na positive real number, the principal root is just the unique positive\n`n`-th root of `z`. Under some circumstances, non-principal real roots exist:\nfor positive real `z`, `n` even, there is a negative root given by `k = n/2`;\nfor negative real `z`, `n` odd, there is a negative root given by `k = (n-1)/2`.\n\nTo obtain all roots with a simple expression, use\n``[root(z,n,k) for k in range(n)]``.\n\nAn important special case, ``root(1, n, k)`` returns the `k`-th `n`-th root of\nunity, `\\zeta_k = e^{2 \\pi i k / n}`. Alternatively, :func:`~mpmath.unitroots`\nprovides a slightly more convenient way to obtain the roots of unity,\nincluding the option to compute only the primitive roots of unity.\n\nBoth `k` and `n` should be integers; `k` outside of ``range(n)`` will be\nreduced modulo `n`. If `n` is negative, `x^{-1/n} = 1/x^{1/n}` (or\nthe equivalent reciprocal for a non-principal root with `k \\ne 0`) is computed.\n\n:func:`~mpmath.root` is implemented to use Newton\'s method for small\n`n`. At high precision, this makes `x^{1/n}` not much more\nexpensive than the regular exponentiation, `x^n`. For very large\n`n`, :func:`~mpmath.nthroot` falls back to use the exponential function.\n\n**Examples**\n\n:func:`~mpmath.nthroot`/:func:`~mpmath.root` is faster and more accurate than raising to a\nfloating-point fraction::\n\n    >>> from mpmath import *\n    >>> mp.dps = 15; mp.pretty = False\n    >>> 16807 ** (mpf(1)/5)\n    mpf(\'7.0000000000000009\')\n    >>> root(16807, 5)\n    mpf(\'7.0\')\n    >>> nthroot(16807, 5)    # Alias\n    mpf(\'7.0\')\n\nA high-precision root::\n\n    >>> mp.dps = 50; mp.pretty = True\n    >>> nthroot(10, 5)\n    1.584893192461113485202101373391507013269442133825\n    >>> nthroot(10, 5) ** 5\n    10.0\n\nComputing principal and non-principal square and cube roots::\n\n    >>> mp.dps = 15\n    >>> root(10, 2)\n    3.16227766016838\n    >>> root(10, 2, 1)\n    -3.16227766016838\n    >>> root(-10, 3)\n    (1.07721734501594 + 1.86579517236206j)\n    >>> root(-10, 3, 1)\n    -2.15443469003188\n    >>> root(-10, 3, 2)\n    (1.07721734501594 - 1.86579517236206j)\n\nAll the 7th roots of a complex number::\n\n    >>> for r in [root(3+4j, 7, k) for k in range(7)]:\n    ...     print("%s %s" % (r, r**7))\n    ...\n    (1.24747270589553 + 0.166227124177353j) (3.0 + 4.0j)\n    (0.647824911301003 + 1.07895435170559j) (3.0 + 4.0j)\n    (-0.439648254723098 + 1.17920694574172j) (3.0 + 4.0j)\n    (-1.19605731775069 + 0.391492658196305j) (3.0 + 4.0j)\n    (-1.05181082538903 - 0.691023585965793j) (3.0 + 4.0j)\n    (-0.115529328478668 - 1.25318497558335j) (3.0 + 4.0j)\n    (0.907748109144957 - 0.871672518271819j) (3.0 + 4.0j)\n\nCube roots of unity::\n\n    >>> for k in range(3): print(root(1, 3, k))\n    ...\n    1.0\n    (-0.5 + 0.866025403784439j)\n    (-0.5 - 0.866025403784439j)\n\nSome exact high order roots::\n\n    >>> root(75**210, 105)\n    5625.0\n    >>> root(1, 128, 96)\n    (0.0 - 1.0j)\n    >>> root(4**128, 128, 96)\n    (0.0 - 4.0j)\n\n'
sawtoothw: str = '\nComputes the sawtooth wave function using the definition:\n\n.. math::\n    x(t) = A\\operatorname{frac}\\left(\\frac{t}{T}\\right)\n\nwhere :math:`\\operatorname{frac}\\left(\\frac{t}{T}\\right) = \\frac{t}{T}-\\left\\lfloor{\\frac{t}{T}}\\right\\rfloor`,\n`P` is the period of the wave, and `A` is the amplitude.\n\n**Examples**\n\nSawtooth wave with period = 2, amplitude = 1 ::\n\n    >>> from mpmath import *\n    >>> mp.dps = 25; mp.pretty = True\n    >>> sawtoothw(0,1,2)\n    0.0\n    >>> sawtoothw(0.5,1,2)\n    0.25\n    >>> sawtoothw(1,1,2)\n    0.5\n    >>> sawtoothw(1.5,1,2)\n    0.75\n    >>> sawtoothw(2,1,2)\n    0.0\n'
scorergi: str = "\nEvaluates the Scorer function\n\n.. math ::\n\n    \\operatorname{Gi}(z) =\n    \\operatorname{Ai}(z) \\int_0^z \\operatorname{Bi}(t) dt +\n    \\operatorname{Bi}(z) \\int_z^{\\infty} \\operatorname{Ai}(t) dt\n\nwhich gives a particular solution to the inhomogeneous Airy\ndifferential equation `f''(z) - z f(z) = 1/\\pi`. Another\nparticular solution is given by the Scorer Hi-function\n(:func:`~mpmath.scorerhi`). The two functions are related as\n`\\operatorname{Gi}(z) + \\operatorname{Hi}(z) = \\operatorname{Bi}(z)`.\n\n**Plots**\n\n.. literalinclude :: /plots/gi.py\n.. image :: /plots/gi.png\n.. literalinclude :: /plots/gi_c.py\n.. image :: /plots/gi_c.png\n\n**Examples**\n\nSome values and limits::\n\n    >>> from mpmath import *\n    >>> mp.dps = 25; mp.pretty = True\n    >>> scorergi(0); 1/(power(3,'7/6')*gamma('2/3'))\n    0.2049755424820002450503075\n    0.2049755424820002450503075\n    >>> diff(scorergi, 0); 1/(power(3,'5/6')*gamma('1/3'))\n    0.1494294524512754526382746\n    0.1494294524512754526382746\n    >>> scorergi(+inf); scorergi(-inf)\n    0.0\n    0.0\n    >>> scorergi(1)\n    0.2352184398104379375986902\n    >>> scorergi(-1)\n    -0.1166722172960152826494198\n\nEvaluation for large arguments::\n\n    >>> scorergi(10)\n    0.03189600510067958798062034\n    >>> scorergi(100)\n    0.003183105228162961476590531\n    >>> scorergi(1000000)\n    0.0000003183098861837906721743873\n    >>> 1/(pi*1000000)\n    0.0000003183098861837906715377675\n    >>> scorergi(-1000)\n    -0.08358288400262780392338014\n    >>> scorergi(-100000)\n    0.02886866118619660226809581\n    >>> scorergi(50+10j)\n    (0.0061214102799778578790984 - 0.001224335676457532180747917j)\n    >>> scorergi(-50-10j)\n    (5.236047850352252236372551e+29 - 3.08254224233701381482228e+29j)\n    >>> scorergi(100000j)\n    (-8.806659285336231052679025e+6474077 + 8.684731303500835514850962e+6474077j)\n\nVerifying the connection between Gi and Hi::\n\n    >>> z = 0.25\n    >>> scorergi(z) + scorerhi(z)\n    0.7287469039362150078694543\n    >>> airybi(z)\n    0.7287469039362150078694543\n\nVerifying the differential equation::\n\n    >>> for z in [-3.4, 0, 2.5, 1+2j]:\n    ...     chop(diff(scorergi,z,2) - z*scorergi(z))\n    ...\n    -0.3183098861837906715377675\n    -0.3183098861837906715377675\n    -0.3183098861837906715377675\n    -0.3183098861837906715377675\n\nVerifying the integral representation::\n\n    >>> z = 0.5\n    >>> scorergi(z)\n    0.2447210432765581976910539\n    >>> Ai,Bi = airyai,airybi\n    >>> Bi(z)*(Ai(inf,-1)-Ai(z,-1)) + Ai(z)*(Bi(z,-1)-Bi(0,-1))\n    0.2447210432765581976910539\n\n**References**\n\n1. [DLMF]_ section 9.12: Scorer Functions\n\n"
scorerhi: str = "\nEvaluates the second Scorer function\n\n.. math ::\n\n    \\operatorname{Hi}(z) =\n    \\operatorname{Bi}(z) \\int_{-\\infty}^z \\operatorname{Ai}(t) dt -\n    \\operatorname{Ai}(z) \\int_{-\\infty}^z \\operatorname{Bi}(t) dt\n\nwhich gives a particular solution to the inhomogeneous Airy\ndifferential equation `f''(z) - z f(z) = 1/\\pi`. See also\n:func:`~mpmath.scorergi`.\n\n**Plots**\n\n.. literalinclude :: /plots/hi.py\n.. image :: /plots/hi.png\n.. literalinclude :: /plots/hi_c.py\n.. image :: /plots/hi_c.png\n\n**Examples**\n\nSome values and limits::\n\n    >>> from mpmath import *\n    >>> mp.dps = 25; mp.pretty = True\n    >>> scorerhi(0); 2/(power(3,'7/6')*gamma('2/3'))\n    0.4099510849640004901006149\n    0.4099510849640004901006149\n    >>> diff(scorerhi,0); 2/(power(3,'5/6')*gamma('1/3'))\n    0.2988589049025509052765491\n    0.2988589049025509052765491\n    >>> scorerhi(+inf); scorerhi(-inf)\n    +inf\n    0.0\n    >>> scorerhi(1)\n    0.9722051551424333218376886\n    >>> scorerhi(-1)\n    0.2206696067929598945381098\n\nEvaluation for large arguments::\n\n    >>> scorerhi(10)\n    455641153.5163291358991077\n    >>> scorerhi(100)\n    6.041223996670201399005265e+288\n    >>> scorerhi(1000000)\n    7.138269638197858094311122e+289529652\n    >>> scorerhi(-10)\n    0.0317685352825022727415011\n    >>> scorerhi(-100)\n    0.003183092495767499864680483\n    >>> scorerhi(100j)\n    (-6.366197716545672122983857e-9 + 0.003183098861710582761688475j)\n    >>> scorerhi(50+50j)\n    (-5.322076267321435669290334e+63 + 1.478450291165243789749427e+65j)\n    >>> scorerhi(-1000-1000j)\n    (0.0001591549432510502796565538 - 0.000159154943091895334973109j)\n\nVerifying the differential equation::\n\n    >>> for z in [-3.4, 0, 2, 1+2j]:\n    ...     chop(diff(scorerhi,z,2) - z*scorerhi(z))\n    ...\n    0.3183098861837906715377675\n    0.3183098861837906715377675\n    0.3183098861837906715377675\n    0.3183098861837906715377675\n\nVerifying the integral representation::\n\n    >>> z = 0.5\n    >>> scorerhi(z)\n    0.6095559998265972956089949\n    >>> Ai,Bi = airyai,airybi\n    >>> Bi(z)*(Ai(z,-1)-Ai(-inf,-1)) - Ai(z)*(Bi(z,-1)-Bi(-inf,-1))\n    0.6095559998265972956089949\n\n"
sec: str = '\nComputes the secant of `x`, `\\mathrm{sec}(x) = \\frac{1}{\\cos(x)}`.\nThe secant function is singular at `x = (n+1/2)\\pi`, but\n``sec(x)`` always returns a finite result since `(n+1/2)\\pi`\ncannot be represented exactly using floating-point arithmetic.\n\n    >>> from mpmath import *\n    >>> mp.dps = 25; mp.pretty = True\n    >>> sec(pi/3)\n    2.0\n    >>> sec(10000001)\n    -1.184723164360392819100265\n    >>> sec(2+3j)\n    (-0.04167496441114427004834991 + 0.0906111371962375965296612j)\n    >>> sec(inf)\n    nan\n    >>> nprint(chop(taylor(sec, 0, 6)))\n    [1.0, 0.0, 0.5, 0.0, 0.208333, 0.0, 0.0847222]\n\nIntervals are supported via :func:`mpmath.iv.sec`::\n\n    >>> iv.dps = 25; iv.pretty = True\n    >>> iv.sec([0,1])\n    [1.0, 1.85081571768092561791175326276]\n    >>> iv.sec([0,2])  # Interval includes a singularity\n    [-inf, +inf]\n'
sech: str = 'Computes the hyperbolic secant of `x`,\n`\\mathrm{sech}(x) = \\frac{1}{\\cosh(x)}`.\n'
shi: str = '\nComputes the hyperbolic sine integral, defined\nin analogy with the sine integral (see :func:`~mpmath.si`) as\n\n.. math ::\n\n    \\mathrm{Shi}(x) = \\int_0^x \\frac{\\sinh t}{t}\\,dt.\n\nSome values and limits::\n\n    >>> from mpmath import *\n    >>> mp.dps = 25; mp.pretty = True\n    >>> shi(0)\n    0.0\n    >>> shi(1)\n    1.057250875375728514571842\n    >>> shi(-1)\n    -1.057250875375728514571842\n    >>> shi(inf)\n    +inf\n    >>> shi(2+3j)\n    (-0.1931890762719198291678095 + 2.645432555362369624818525j)\n\nEvaluation is supported for `z` anywhere in the complex plane::\n\n    >>> shi(10**6*(1+j))\n    (4.449410587611035724984376e+434287 - 9.75744874290013526417059e+434287j)\n\n'
si: str = '\nComputes the sine integral,\n\n.. math ::\n\n    \\mathrm{Si}(x) = \\int_0^x \\frac{\\sin t}{t}\\,dt.\n\nThe sine integral is thus the antiderivative of the sinc\nfunction (see :func:`~mpmath.sinc`).\n\n**Examples**\n\nSome values and limits::\n\n    >>> from mpmath import *\n    >>> mp.dps = 25; mp.pretty = True\n    >>> si(0)\n    0.0\n    >>> si(1)\n    0.9460830703671830149413533\n    >>> si(-1)\n    -0.9460830703671830149413533\n    >>> si(pi)\n    1.851937051982466170361053\n    >>> si(inf)\n    1.570796326794896619231322\n    >>> si(-inf)\n    -1.570796326794896619231322\n    >>> si(2+3j)\n    (4.547513889562289219853204 + 1.399196580646054789459839j)\n\nThe sine integral approaches `\\pi/2` for large real `x`::\n\n    >>> si(10**10)\n    1.570796326707584656968511\n    >>> pi/2\n    1.570796326794896619231322\n\nEvaluation is supported for `z` anywhere in the complex plane::\n\n    >>> si(10**6*(1+j))\n    (-9.75744874290013526417059e+434287 + 4.449410587611035724984376e+434287j)\n\nWe can evaluate the defining integral as a reference::\n\n    >>> mp.dps = 15\n    >>> quad(sinc, [0, 5])\n    1.54993124494467\n    >>> si(5)\n    1.54993124494467\n\nSome infinite series can be evaluated using the\nsine integral::\n\n    >>> nsum(lambda k: (-1)**k/(fac(2*k+1)*(2*k+1)), [0,inf])\n    0.946083070367183\n    >>> si(1)\n    0.946083070367183\n\n'
siegeltheta: str = '\nComputes the Riemann-Siegel theta function,\n\n.. math ::\n\n    \\theta(t) = \\frac{\n    \\log\\Gamma\\left(\\frac{1+2it}{4}\\right) -\n    \\log\\Gamma\\left(\\frac{1-2it}{4}\\right)\n    }{2i} - \\frac{\\log \\pi}{2} t.\n\nThe Riemann-Siegel theta function is important in\nproviding the phase factor for the Z-function\n(see :func:`~mpmath.siegelz`). Evaluation is supported for real and\ncomplex arguments::\n\n    >>> from mpmath import *\n    >>> mp.dps = 25; mp.pretty = True\n    >>> siegeltheta(0)\n    0.0\n    >>> siegeltheta(inf)\n    +inf\n    >>> siegeltheta(-inf)\n    -inf\n    >>> siegeltheta(1)\n    -1.767547952812290388302216\n    >>> siegeltheta(10+0.25j)\n    (-3.068638039426838572528867 + 0.05804937947429712998395177j)\n\nArbitrary derivatives may be computed with derivative = k\n\n    >>> siegeltheta(1234, derivative=2)\n    0.0004051864079114053109473741\n    >>> diff(siegeltheta, 1234, n=2)\n    0.0004051864079114053109473741\n\n\nThe Riemann-Siegel theta function has odd symmetry around `t = 0`,\ntwo local extreme points and three real roots including 0 (located\nsymmetrically)::\n\n    >>> nprint(chop(taylor(siegeltheta, 0, 5)))\n    [0.0, -2.68609, 0.0, 2.69433, 0.0, -6.40218]\n    >>> findroot(diffun(siegeltheta), 7)\n    6.28983598883690277966509\n    >>> findroot(siegeltheta, 20)\n    17.84559954041086081682634\n\nFor large `t`, there is a famous asymptotic formula\nfor `\\theta(t)`, to first order given by::\n\n    >>> t = mpf(10**6)\n    >>> siegeltheta(t)\n    5488816.353078403444882823\n    >>> -t*log(2*pi/t)/2-t/2\n    5488816.745777464310273645\n'
siegelz: str = "\nComputes the Z-function, also known as the Riemann-Siegel Z function,\n\n.. math ::\n\n    Z(t) = e^{i \\theta(t)} \\zeta(1/2+it)\n\nwhere `\\zeta(s)` is the Riemann zeta function (:func:`~mpmath.zeta`)\nand where `\\theta(t)` denotes the Riemann-Siegel theta function\n(see :func:`~mpmath.siegeltheta`).\n\nEvaluation is supported for real and complex arguments::\n\n    >>> from mpmath import *\n    >>> mp.dps = 25; mp.pretty = True\n    >>> siegelz(1)\n    -0.7363054628673177346778998\n    >>> siegelz(3+4j)\n    (-0.1852895764366314976003936 - 0.2773099198055652246992479j)\n\nThe first four derivatives are supported, using the\noptional *derivative* keyword argument::\n\n    >>> siegelz(1234567, derivative=3)\n    56.89689348495089294249178\n    >>> diff(siegelz, 1234567, n=3)\n    56.89689348495089294249178\n\n\nThe Z-function has a Maclaurin expansion::\n\n    >>> nprint(chop(taylor(siegelz, 0, 4)))\n    [-1.46035, 0.0, 2.73588, 0.0, -8.39357]\n\nThe Z-function `Z(t)` is equal to `\\pm |\\zeta(s)|` on the\ncritical line `s = 1/2+it` (i.e. for real arguments `t`\nto `Z`).  Its zeros coincide with those of the Riemann zeta\nfunction::\n\n    >>> findroot(siegelz, 14)\n    14.13472514173469379045725\n    >>> findroot(siegelz, 20)\n    21.02203963877155499262848\n    >>> findroot(zeta, 0.5+14j)\n    (0.5 + 14.13472514173469379045725j)\n    >>> findroot(zeta, 0.5+20j)\n    (0.5 + 21.02203963877155499262848j)\n\nSince the Z-function is real-valued on the critical line\n(and unlike `|\\zeta(s)|` analytic), it is useful for\ninvestigating the zeros of the Riemann zeta function.\nFor example, one can use a root-finding algorithm based\non sign changes::\n\n    >>> findroot(siegelz, [100, 200], solver='bisect')\n    176.4414342977104188888926\n\nTo locate roots, Gram points `g_n` which can be computed\nby :func:`~mpmath.grampoint` are useful. If `(-1)^n Z(g_n)` is\npositive for two consecutive `n`, then `Z(t)` must have\na zero between those points::\n\n    >>> g10 = grampoint(10)\n    >>> g11 = grampoint(11)\n    >>> (-1)**10 * siegelz(g10) > 0\n    True\n    >>> (-1)**11 * siegelz(g11) > 0\n    True\n    >>> findroot(siegelz, [g10, g11], solver='bisect')\n    56.44624769706339480436776\n    >>> g10, g11\n    (54.67523744685325626632663, 57.54516517954725443703014)\n\n"
sigmoid: str = '\nComputes the sigmoid function using the definition:\n\n.. math::\n    x(t) = \\frac{A}{1 + e^{-t}}\n\nwhere `A` is the amplitude.\n\n**Examples**\n\nSigmoid function with amplitude = 1 ::\n\n    >>> from mpmath import *\n    >>> mp.dps = 25; mp.pretty = True\n    >>> sigmoid(-1,1)\n    0.2689414213699951207488408\n    >>> sigmoid(-0.5,1)\n    0.3775406687981454353610994\n    >>> sigmoid(0,1)\n    0.5\n    >>> sigmoid(0.5,1)\n    0.6224593312018545646389006\n    >>> sigmoid(1,1)\n    0.7310585786300048792511592\n\n'
sign: str = "\nReturns the sign of `x`, defined as `\\mathrm{sign}(x) = x / |x|`\n(with the special case `\\mathrm{sign}(0) = 0`)::\n\n    >>> from mpmath import *\n    >>> mp.dps = 15; mp.pretty = False\n    >>> sign(10)\n    mpf('1.0')\n    >>> sign(-10)\n    mpf('-1.0')\n    >>> sign(0)\n    mpf('0.0')\n\nNote that the sign function is also defined for complex numbers,\nfor which it gives the projection onto the unit circle::\n\n    >>> mp.dps = 15; mp.pretty = True\n    >>> sign(1+j)\n    (0.707106781186547 + 0.707106781186547j)\n\n"
sin: str = '\nComputes the sine of `x`, `\\sin(x)`.\n\n    >>> from mpmath import *\n    >>> mp.dps = 25; mp.pretty = True\n    >>> sin(pi/3)\n    0.8660254037844386467637232\n    >>> sin(100000001)\n    0.1975887055794968911438743\n    >>> sin(2+3j)\n    (9.1544991469114295734673 - 4.168906959966564350754813j)\n    >>> sin(inf)\n    nan\n    >>> nprint(chop(taylor(sin, 0, 6)))\n    [0.0, 1.0, 0.0, -0.166667, 0.0, 0.00833333, 0.0]\n\nIntervals are supported via :func:`mpmath.iv.sin`::\n\n    >>> iv.dps = 25; iv.pretty = True\n    >>> iv.sin([0,1])\n    [0.0, 0.841470984807896506652502331201]\n    >>> iv.sin([0,2])\n    [0.0, 1.0]\n'
sinc: str = '\n``sinc(x)`` computes the unnormalized sinc function, defined as\n\n.. math ::\n\n    \\mathrm{sinc}(x) = \\begin{cases}\n        \\sin(x)/x, & \\mbox{if } x \\ne 0 \\\\\n        1,         & \\mbox{if } x = 0.\n    \\end{cases}\n\nSee :func:`~mpmath.sincpi` for the normalized sinc function.\n\nSimple values and limits include::\n\n    >>> from mpmath import *\n    >>> mp.dps = 15; mp.pretty = True\n    >>> sinc(0)\n    1.0\n    >>> sinc(1)\n    0.841470984807897\n    >>> sinc(inf)\n    0.0\n\nThe integral of the sinc function is the sine integral Si::\n\n    >>> quad(sinc, [0, 1])\n    0.946083070367183\n    >>> si(1)\n    0.946083070367183\n'
sincpi: str = '\n``sincpi(x)`` computes the normalized sinc function, defined as\n\n.. math ::\n\n    \\mathrm{sinc}_{\\pi}(x) = \\begin{cases}\n        \\sin(\\pi x)/(\\pi x), & \\mbox{if } x \\ne 0 \\\\\n        1,                   & \\mbox{if } x = 0.\n    \\end{cases}\n\nEquivalently, we have\n`\\mathrm{sinc}_{\\pi}(x) = \\mathrm{sinc}(\\pi x)`.\n\nThe normalization entails that the function integrates\nto unity over the entire real line::\n\n    >>> from mpmath import *\n    >>> mp.dps = 15; mp.pretty = True\n    >>> quadosc(sincpi, [-inf, inf], period=2.0)\n    1.0\n\nLike, :func:`~mpmath.sinpi`, :func:`~mpmath.sincpi` is evaluated accurately\nat its roots::\n\n    >>> sincpi(10)\n    0.0\n'
sinh: str = '\nComputes the hyperbolic sine of `x`,\n`\\sinh(x) = (e^x - e^{-x})/2`. Values and limits include::\n\n    >>> from mpmath import *\n    >>> mp.dps = 25; mp.pretty = True\n    >>> sinh(0)\n    0.0\n    >>> sinh(1)\n    1.175201193643801456882382\n    >>> sinh(-inf), sinh(+inf)\n    (-inf, +inf)\n\nThe hyperbolic sine is an odd function, with a Maclaurin\nseries that starts::\n\n    >>> nprint(chop(taylor(sinh, 0, 5)))\n    [0.0, 1.0, 0.0, 0.166667, 0.0, 0.00833333]\n\nGeneralized to complex numbers, the hyperbolic sine is\nessentially a sine with a rotation `i` applied to\nthe argument; more precisely, `\\sinh x = -i \\sin ix`::\n\n    >>> sinh(2+3j)\n    (-3.590564589985779952012565 + 0.5309210862485198052670401j)\n    >>> j*sin(3-2j)\n    (-3.590564589985779952012565 + 0.5309210862485198052670401j)\n'
sinpi: str = '\nComputes `\\sin(\\pi x)`, more accurately than the expression\n``sin(pi*x)``::\n\n    >>> from mpmath import *\n    >>> mp.dps = 15; mp.pretty = True\n    >>> sinpi(10**10), sin(pi*(10**10))\n    (0.0, -2.23936276195592e-6)\n    >>> sinpi(10**10+0.5), sin(pi*(10**10+0.5))\n    (1.0, 0.999999999998721)\n'
spherharm: str = '\nEvaluates the spherical harmonic `Y_l^m(\\theta,\\phi)`,\n\n.. math ::\n\n    Y_l^m(\\theta,\\phi) = \\sqrt{\\frac{2l+1}{4\\pi}\\frac{(l-m)!}{(l+m)!}}\n        P_l^m(\\cos \\theta) e^{i m \\phi}\n\nwhere `P_l^m` is an associated Legendre function (see :func:`~mpmath.legenp`).\n\nHere `\\theta \\in [0, \\pi]` denotes the polar coordinate (ranging\nfrom the north pole to the south pole) and `\\phi \\in [0, 2 \\pi]` denotes the\nazimuthal coordinate on a sphere. Care should be used since many different\nconventions for spherical coordinate variables are used.\n\nUsually spherical harmonics are considered for `l \\in \\mathbb{N}`,\n`m \\in \\mathbb{Z}`, `|m| \\le l`. More generally, `l,m,\\theta,\\phi`\nare permitted to be complex numbers.\n\n.. note ::\n\n    :func:`~mpmath.spherharm` returns a complex number, even if the value is\n    purely real.\n\n**Plots**\n\n.. literalinclude :: /plots/spherharm40.py\n\n`Y_{4,0}`:\n\n.. image :: /plots/spherharm40.png\n\n`Y_{4,1}`:\n\n.. image :: /plots/spherharm41.png\n\n`Y_{4,2}`:\n\n.. image :: /plots/spherharm42.png\n\n`Y_{4,3}`:\n\n.. image :: /plots/spherharm43.png\n\n`Y_{4,4}`:\n\n.. image :: /plots/spherharm44.png\n\n**Examples**\n\nSome low-order spherical harmonics with reference values::\n\n    >>> from mpmath import *\n    >>> mp.dps = 25; mp.pretty = True\n    >>> theta = pi/4\n    >>> phi = pi/3\n    >>> spherharm(0,0,theta,phi); 0.5*sqrt(1/pi)*expj(0)\n    (0.2820947917738781434740397 + 0.0j)\n    (0.2820947917738781434740397 + 0.0j)\n    >>> spherharm(1,-1,theta,phi); 0.5*sqrt(3/(2*pi))*expj(-phi)*sin(theta)\n    (0.1221506279757299803965962 - 0.2115710938304086076055298j)\n    (0.1221506279757299803965962 - 0.2115710938304086076055298j)\n    >>> spherharm(1,0,theta,phi); 0.5*sqrt(3/pi)*cos(theta)*expj(0)\n    (0.3454941494713354792652446 + 0.0j)\n    (0.3454941494713354792652446 + 0.0j)\n    >>> spherharm(1,1,theta,phi); -0.5*sqrt(3/(2*pi))*expj(phi)*sin(theta)\n    (-0.1221506279757299803965962 - 0.2115710938304086076055298j)\n    (-0.1221506279757299803965962 - 0.2115710938304086076055298j)\n\nWith the normalization convention used, the spherical harmonics are orthonormal\non the unit sphere::\n\n    >>> sphere = [0,pi], [0,2*pi]\n    >>> dS = lambda t,p: fp.sin(t)   # differential element\n    >>> Y1 = lambda t,p: fp.spherharm(l1,m1,t,p)\n    >>> Y2 = lambda t,p: fp.conj(fp.spherharm(l2,m2,t,p))\n    >>> l1 = l2 = 3; m1 = m2 = 2\n    >>> fp.chop(fp.quad(lambda t,p: Y1(t,p)*Y2(t,p)*dS(t,p), *sphere))\n    1.0000000000000007\n    >>> m2 = 1    # m1 != m2\n    >>> print(fp.chop(fp.quad(lambda t,p: Y1(t,p)*Y2(t,p)*dS(t,p), *sphere)))\n    0.0\n\nEvaluation is accurate for large orders::\n\n    >>> spherharm(1000,750,0.5,0.25)\n    (3.776445785304252879026585e-102 - 5.82441278771834794493484e-102j)\n\nEvaluation works with complex parameter values::\n\n    >>> spherharm(1+j, 2j, 2+3j, -0.5j)\n    (64.44922331113759992154992 + 1981.693919841408089681743j)\n'
sqrt: str = "\n``sqrt(x)`` gives the principal square root of `x`, `\\sqrt x`.\nFor positive real numbers, the principal root is simply the\npositive square root. For arbitrary complex numbers, the principal\nsquare root is defined to satisfy `\\sqrt x = \\exp(\\log(x)/2)`.\nThe function thus has a branch cut along the negative half real axis.\n\nFor all mpmath numbers ``x``, calling ``sqrt(x)`` is equivalent to\nperforming ``x**0.5``.\n\n**Examples**\n\nBasic examples and limits::\n\n    >>> from mpmath import *\n    >>> mp.dps = 15; mp.pretty = True\n    >>> sqrt(10)\n    3.16227766016838\n    >>> sqrt(100)\n    10.0\n    >>> sqrt(-4)\n    (0.0 + 2.0j)\n    >>> sqrt(1+1j)\n    (1.09868411346781 + 0.455089860562227j)\n    >>> sqrt(inf)\n    +inf\n\nSquare root evaluation is fast at huge precision::\n\n    >>> mp.dps = 50000\n    >>> a = sqrt(3)\n    >>> str(a)[-10:]\n    '9329332815'\n\n:func:`mpmath.iv.sqrt` supports interval arguments::\n\n    >>> iv.dps = 15; iv.pretty = True\n    >>> iv.sqrt([16,100])\n    [4.0, 10.0]\n    >>> iv.sqrt(2)\n    [1.4142135623730949234, 1.4142135623730951455]\n    >>> iv.sqrt(2) ** 2\n    [1.9999999999999995559, 2.0000000000000004441]\n\n"
squarew: str = '\nComputes the square wave function using the definition:\n\n.. math::\n    x(t) = A(-1)^{\\left\\lfloor{2t / P}\\right\\rfloor}\n\nwhere `P` is the period of the wave and `A` is the amplitude.\n\n**Examples**\n\nSquare wave with period = 2, amplitude = 1 ::\n\n    >>> from mpmath import *\n    >>> mp.dps = 25; mp.pretty = True\n    >>> squarew(0,1,2)\n    1.0\n    >>> squarew(0.5,1,2)\n    1.0\n    >>> squarew(1,1,2)\n    -1.0\n    >>> squarew(1.5,1,2)\n    -1.0\n    >>> squarew(2,1,2)\n    1.0\n'
stieltjes: str = '\nFor a nonnegative integer `n`, ``stieltjes(n)`` computes the\n`n`-th Stieltjes constant `\\gamma_n`, defined as the\n`n`-th coefficient in the Laurent series expansion of the\nRiemann zeta function around the pole at `s = 1`. That is,\nwe have:\n\n.. math ::\n\n  \\zeta(s) = \\frac{1}{s-1} \\sum_{n=0}^{\\infty}\n      \\frac{(-1)^n}{n!} \\gamma_n (s-1)^n\n\nMore generally, ``stieltjes(n, a)`` gives the corresponding\ncoefficient `\\gamma_n(a)` for the Hurwitz zeta function\n`\\zeta(s,a)` (with `\\gamma_n = \\gamma_n(1)`).\n\n**Examples**\n\nThe zeroth Stieltjes constant is just Euler\'s constant `\\gamma`::\n\n    >>> from mpmath import *\n    >>> mp.dps = 15; mp.pretty = True\n    >>> stieltjes(0)\n    0.577215664901533\n\nSome more values are::\n\n    >>> stieltjes(1)\n    -0.0728158454836767\n    >>> stieltjes(10)\n    0.000205332814909065\n    >>> stieltjes(30)\n    0.00355772885557316\n    >>> stieltjes(1000)\n    -1.57095384420474e+486\n    >>> stieltjes(2000)\n    2.680424678918e+1109\n    >>> stieltjes(1, 2.5)\n    -0.23747539175716\n\nAn alternative way to compute `\\gamma_1`::\n\n    >>> diff(extradps(15)(lambda x: 1/(x-1) - zeta(x)), 1)\n    -0.0728158454836767\n\n:func:`~mpmath.stieltjes` supports arbitrary precision evaluation::\n\n    >>> mp.dps = 50\n    >>> stieltjes(2)\n    -0.0096903631928723184845303860352125293590658061013408\n\n**Algorithm**\n\n:func:`~mpmath.stieltjes` numerically evaluates the integral in\nthe following representation due to Ainsworth, Howell and\nCoffey [1], [2]:\n\n.. math ::\n\n  \\gamma_n(a) = \\frac{\\log^n a}{2a} - \\frac{\\log^{n+1}(a)}{n+1} +\n      \\frac{2}{a} \\Re \\int_0^{\\infty}\n      \\frac{(x/a-i)\\log^n(a-ix)}{(1+x^2/a^2)(e^{2\\pi x}-1)} dx.\n\nFor some reference values with `a = 1`, see e.g. [4].\n\n**References**\n\n1. O. R. Ainsworth & L. W. Howell, "An integral representation of\n   the generalized Euler-Mascheroni constants", NASA Technical\n   Paper 2456 (1985),\n   http://ntrs.nasa.gov/archive/nasa/casi.ntrs.nasa.gov/19850014994_1985014994.pdf\n\n2. M. W. Coffey, "The Stieltjes constants, their relation to the\n   `\\eta_j` coefficients, and representation of the Hurwitz\n   zeta function", \tarXiv:0706.0343v1 http://arxiv.org/abs/0706.0343\n\n3. http://mathworld.wolfram.com/StieltjesConstants.html\n\n4. http://pi.lacim.uqam.ca/piDATA/stieltjesgamma.txt\n\n'
stirling1: str = '\nGives the Stirling number of the first kind `s(n,k)`, defined by\n\n.. math ::\n\n    x(x-1)(x-2)\\cdots(x-n+1) = \\sum_{k=0}^n s(n,k) x^k.\n\nThe value is computed using an integer recurrence. The implementation\nis not optimized for approximating large values quickly.\n\n**Examples**\n\nComparing with the generating function::\n\n    >>> from mpmath import *\n    >>> mp.dps = 25; mp.pretty = True\n    >>> taylor(lambda x: ff(x, 5), 0, 5)\n    [0.0, 24.0, -50.0, 35.0, -10.0, 1.0]\n    >>> [stirling1(5, k) for k in range(6)]\n    [0.0, 24.0, -50.0, 35.0, -10.0, 1.0]\n\nRecurrence relation::\n\n    >>> n, k = 5, 3\n    >>> stirling1(n+1,k) + n*stirling1(n,k) - stirling1(n,k-1)\n    0.0\n\nThe matrices of Stirling numbers of first and second kind are inverses\nof each other::\n\n    >>> A = matrix(5, 5); B = matrix(5, 5)\n    >>> for n in range(5):\n    ...     for k in range(5):\n    ...         A[n,k] = stirling1(n,k)\n    ...         B[n,k] = stirling2(n,k)\n    ...\n    >>> A * B\n    [1.0  0.0  0.0  0.0  0.0]\n    [0.0  1.0  0.0  0.0  0.0]\n    [0.0  0.0  1.0  0.0  0.0]\n    [0.0  0.0  0.0  1.0  0.0]\n    [0.0  0.0  0.0  0.0  1.0]\n\nPass ``exact=True`` to obtain exact values of Stirling numbers as integers::\n\n    >>> stirling1(42, 5)\n    -2.864498971768501633736628e+50\n    >>> print(stirling1(42, 5, exact=True))\n    -286449897176850163373662803014001546235808317440000\n\n'
stirling2: str = '\nGives the Stirling number of the second kind `S(n,k)`, defined by\n\n.. math ::\n\n    x^n = \\sum_{k=0}^n S(n,k) x(x-1)(x-2)\\cdots(x-k+1)\n\nThe value is computed using integer arithmetic to evaluate a power sum.\nThe implementation is not optimized for approximating large values quickly.\n\n**Examples**\n\nComparing with the generating function::\n\n    >>> from mpmath import *\n    >>> mp.dps = 25; mp.pretty = True\n    >>> taylor(lambda x: sum(stirling2(5,k) * ff(x,k) for k in range(6)), 0, 5)\n    [0.0, 0.0, 0.0, 0.0, 0.0, 1.0]\n\nRecurrence relation::\n\n    >>> n, k = 5, 3\n    >>> stirling2(n+1,k) - k*stirling2(n,k) - stirling2(n,k-1)\n    0.0\n\nPass ``exact=True`` to obtain exact values of Stirling numbers as integers::\n\n    >>> stirling2(52, 10)\n    2.641822121003543906807485e+45\n    >>> print(stirling2(52, 10, exact=True))\n    2641822121003543906807485307053638921722527655\n\n\n'
struveh: str = "\nGives the Struve function\n\n.. math ::\n\n    \\,\\mathbf{H}_n(z) =\n    \\sum_{k=0}^\\infty \\frac{(-1)^k}{\\Gamma(k+\\frac{3}{2})\n        \\Gamma(k+n+\\frac{3}{2})} {\\left({\\frac{z}{2}}\\right)}^{2k+n+1}\n\nwhich is a solution to the Struve differential equation\n\n.. math ::\n\n    z^2 f''(z) + z f'(z) + (z^2-n^2) f(z) = \\frac{2 z^{n+1}}{\\pi (2n-1)!!}.\n\n**Examples**\n\nEvaluation for arbitrary real and complex arguments::\n\n    >>> from mpmath import *\n    >>> mp.dps = 25; mp.pretty = True\n    >>> struveh(0, 3.5)\n    0.3608207733778295024977797\n    >>> struveh(-1, 10)\n    -0.255212719726956768034732\n    >>> struveh(1, -100.5)\n    0.5819566816797362287502246\n    >>> struveh(2.5, 10000000000000)\n    3153915652525200060.308937\n    >>> struveh(2.5, -10000000000000)\n    (0.0 - 3153915652525200060.308937j)\n    >>> struveh(1+j, 1000000+4000000j)\n    (-3.066421087689197632388731e+1737173 - 1.596619701076529803290973e+1737173j)\n\nA Struve function of half-integer order is elementary; for example:\n\n    >>> z = 3\n    >>> struveh(0.5, 3)\n    0.9167076867564138178671595\n    >>> sqrt(2/(pi*z))*(1-cos(z))\n    0.9167076867564138178671595\n\nNumerically verifying the differential equation::\n\n    >>> z = mpf(4.5)\n    >>> n = 3\n    >>> f = lambda z: struveh(n,z)\n    >>> lhs = z**2*diff(f,z,2) + z*diff(f,z) + (z**2-n**2)*f(z)\n    >>> rhs = 2*z**(n+1)/fac2(2*n-1)/pi\n    >>> lhs\n    17.40359302709875496632744\n    >>> rhs\n    17.40359302709875496632744\n\n"
struvel: str = "\nGives the modified Struve function\n\n.. math ::\n\n    \\,\\mathbf{L}_n(z) = -i e^{-n\\pi i/2} \\mathbf{H}_n(i z)\n\nwhich solves to the modified Struve differential equation\n\n.. math ::\n\n    z^2 f''(z) + z f'(z) - (z^2+n^2) f(z) = \\frac{2 z^{n+1}}{\\pi (2n-1)!!}.\n\n**Examples**\n\nEvaluation for arbitrary real and complex arguments::\n\n    >>> from mpmath import *\n    >>> mp.dps = 25; mp.pretty = True\n    >>> struvel(0, 3.5)\n    7.180846515103737996249972\n    >>> struvel(-1, 10)\n    2670.994904980850550721511\n    >>> struvel(1, -100.5)\n    1.757089288053346261497686e+42\n    >>> struvel(2.5, 10000000000000)\n    4.160893281017115450519948e+4342944819025\n    >>> struvel(2.5, -10000000000000)\n    (0.0 - 4.160893281017115450519948e+4342944819025j)\n    >>> struvel(1+j, 700j)\n    (-0.1721150049480079451246076 + 0.1240770953126831093464055j)\n    >>> struvel(1+j, 1000000+4000000j)\n    (-2.973341637511505389128708e+434290 - 5.164633059729968297147448e+434290j)\n\nNumerically verifying the differential equation::\n\n    >>> z = mpf(3.5)\n    >>> n = 3\n    >>> f = lambda z: struvel(n,z)\n    >>> lhs = z**2*diff(f,z,2) + z*diff(f,z) - (z**2+n**2)*f(z)\n    >>> rhs = 2*z**(n+1)/fac2(2*n-1)/pi\n    >>> lhs\n    6.368850306060678353018165\n    >>> rhs\n    6.368850306060678353018165\n"
superfac: str = '\nComputes the superfactorial, defined as the product of\nconsecutive factorials\n\n.. math ::\n\n    \\mathrm{sf}(n) = \\prod_{k=1}^n k!\n\nFor general complex `z`, `\\mathrm{sf}(z)` is defined\nin terms of the Barnes G-function (see :func:`~mpmath.barnesg`).\n\n**Examples**\n\nThe first few superfactorials are (OEIS A000178)::\n\n    >>> from mpmath import *\n    >>> mp.dps = 15; mp.pretty = True\n    >>> for n in range(10):\n    ...     print("%s %s" % (n, superfac(n)))\n    ...\n    0 1.0\n    1 1.0\n    2 2.0\n    3 12.0\n    4 288.0\n    5 34560.0\n    6 24883200.0\n    7 125411328000.0\n    8 5.05658474496e+15\n    9 1.83493347225108e+21\n\nSuperfactorials grow very rapidly::\n\n    >>> superfac(1000)\n    3.24570818422368e+1177245\n    >>> superfac(10**10)\n    2.61398543581249e+467427913956904067453\n\nEvaluation is supported for arbitrary arguments::\n\n    >>> mp.dps = 25\n    >>> superfac(pi)\n    17.20051550121297985285333\n    >>> superfac(2+3j)\n    (-0.005915485633199789627466468 + 0.008156449464604044948738263j)\n    >>> diff(superfac, 1)\n    0.2645072034016070205673056\n\n**References**\n\n1. http://oeis.org/A000178\n\n'
tan: str = '\nComputes the tangent of `x`, `\\tan(x) = \\frac{\\sin(x)}{\\cos(x)}`.\nThe tangent function is singular at `x = (n+1/2)\\pi`, but\n``tan(x)`` always returns a finite result since `(n+1/2)\\pi`\ncannot be represented exactly using floating-point arithmetic.\n\n    >>> from mpmath import *\n    >>> mp.dps = 25; mp.pretty = True\n    >>> tan(pi/3)\n    1.732050807568877293527446\n    >>> tan(100000001)\n    -0.2015625081449864533091058\n    >>> tan(2+3j)\n    (-0.003764025641504248292751221 + 1.003238627353609801446359j)\n    >>> tan(inf)\n    nan\n    >>> nprint(chop(taylor(tan, 0, 6)))\n    [0.0, 1.0, 0.0, 0.333333, 0.0, 0.133333, 0.0]\n\nIntervals are supported via :func:`mpmath.iv.tan`::\n\n    >>> iv.dps = 25; iv.pretty = True\n    >>> iv.tan([0,1])\n    [0.0, 1.55740772465490223050697482944]\n    >>> iv.tan([0,2])  # Interval includes a singularity\n    [-inf, +inf]\n'
tanh: str = '\nComputes the hyperbolic tangent of `x`,\n`\\tanh(x) = \\sinh(x)/\\cosh(x)`. Values and limits include::\n\n    >>> from mpmath import *\n    >>> mp.dps = 25; mp.pretty = True\n    >>> tanh(0)\n    0.0\n    >>> tanh(1)\n    0.7615941559557648881194583\n    >>> tanh(-inf), tanh(inf)\n    (-1.0, 1.0)\n\nThe hyperbolic tangent is an odd, sigmoidal function, similar\nto the inverse tangent and error function. Its Maclaurin\nseries is::\n\n    >>> nprint(chop(taylor(tanh, 0, 5)))\n    [0.0, 1.0, 0.0, -0.333333, 0.0, 0.133333]\n\nGeneralized to complex numbers, the hyperbolic tangent is\nessentially a tangent with a rotation `i` applied to\nthe argument; more precisely, `\\tanh x = -i \\tan ix`::\n\n    >>> tanh(2+3j)\n    (0.9653858790221331242784803 - 0.009884375038322493720314034j)\n    >>> j*tan(3-2j)\n    (0.9653858790221331242784803 - 0.009884375038322493720314034j)\n'
trianglew: str = '\nComputes the triangle wave function using the definition:\n\n.. math::\n    x(t) = 2A\\left(\\frac{1}{2}-\\left|1-2 \\operatorname{frac}\\left(\\frac{x}{P}+\\frac{1}{4}\\right)\\right|\\right)\n\nwhere :math:`\\operatorname{frac}\\left(\\frac{t}{T}\\right) = \\frac{t}{T}-\\left\\lfloor{\\frac{t}{T}}\\right\\rfloor`\n, `P` is the period of the wave, and `A` is the amplitude.\n\n**Examples**\n\nTriangle wave with period = 2, amplitude = 1 ::\n\n    >>> from mpmath import *\n    >>> mp.dps = 25; mp.pretty = True\n    >>> trianglew(0,1,2)\n    0.0\n    >>> trianglew(0.25,1,2)\n    0.5\n    >>> trianglew(0.5,1,2)\n    1.0\n    >>> trianglew(1,1,2)\n    0.0\n    >>> trianglew(1.5,1,2)\n    -1.0\n    >>> trianglew(2,1,2)\n    0.0\n'
twinprime: str = '\nRepresents the twin prime constant, which is the factor `C_2`\nfeaturing in the Hardy-Littlewood conjecture for the growth of the\ntwin prime counting function,\n\n.. math ::\n\n    \\pi_2(n) \\sim 2 C_2 \\frac{n}{\\log^2 n}.\n\nIt is given by the product over primes\n\n.. math ::\n\n    C_2 = \\prod_{p\\ge3} \\frac{p(p-2)}{(p-1)^2} \\approx 0.66016\n\nComputing `C_2` to 50 digits::\n\n    >>> from mpmath import *\n    >>> mp.dps = 50; mp.pretty = True\n    >>> +twinprime\n    0.66016181584686957392781211001455577843262336028473\n\nReferences:\nhttp://mathworld.wolfram.com/TwinPrimesConstant.html\n'
unit_triangle: str = '\nComputes the unit triangle using the definition:\n\n.. math::\n    x(t) = A(-\\left| t \\right| + 1)\n\nwhere `A` is the amplitude.\n\n**Examples**\n\nUnit triangle with amplitude = 1 ::\n\n    >>> from mpmath import *\n    >>> mp.dps = 25; mp.pretty = True\n    >>> unit_triangle(-1,1)\n    0.0\n    >>> unit_triangle(-0.5,1)\n    0.5\n    >>> unit_triangle(0,1)\n    1.0\n    >>> unit_triangle(0.5,1)\n    0.5\n    >>> unit_triangle(1,1)\n    0.0\n'
unitroots: str = '\n``unitroots(n)`` returns `\\zeta_0, \\zeta_1, \\ldots, \\zeta_{n-1}`,\nall the distinct `n`-th roots of unity, as a list. If the option\n*primitive=True* is passed, only the primitive roots are returned.\n\nEvery `n`-th root of unity satisfies `(\\zeta_k)^n = 1`. There are `n` distinct\nroots for each `n` (`\\zeta_k` and `\\zeta_j` are the same when\n`k = j \\pmod n`), which form a regular polygon with vertices on the unit\ncircle. They are ordered counterclockwise with increasing `k`, starting\nwith `\\zeta_0 = 1`.\n\n**Examples**\n\nThe roots of unity up to `n = 4`::\n\n    >>> from mpmath import *\n    >>> mp.dps = 15; mp.pretty = True\n    >>> nprint(unitroots(1))\n    [1.0]\n    >>> nprint(unitroots(2))\n    [1.0, -1.0]\n    >>> nprint(unitroots(3))\n    [1.0, (-0.5 + 0.866025j), (-0.5 - 0.866025j)]\n    >>> nprint(unitroots(4))\n    [1.0, (0.0 + 1.0j), -1.0, (0.0 - 1.0j)]\n\nRoots of unity form a geometric series that sums to 0::\n\n    >>> mp.dps = 50\n    >>> chop(fsum(unitroots(25)))\n    0.0\n\nPrimitive roots up to `n = 4`::\n\n    >>> mp.dps = 15\n    >>> nprint(unitroots(1, primitive=True))\n    [1.0]\n    >>> nprint(unitroots(2, primitive=True))\n    [-1.0]\n    >>> nprint(unitroots(3, primitive=True))\n    [(-0.5 + 0.866025j), (-0.5 - 0.866025j)]\n    >>> nprint(unitroots(4, primitive=True))\n    [(0.0 + 1.0j), (0.0 - 1.0j)]\n\nThere are only four primitive 12th roots::\n\n    >>> nprint(unitroots(12, primitive=True))\n    [(0.866025 + 0.5j), (-0.866025 + 0.5j), (-0.866025 - 0.5j), (0.866025 - 0.5j)]\n\nThe `n`-th roots of unity form a group, the cyclic group of order `n`.\nAny primitive root `r` is a generator for this group, meaning that\n`r^0, r^1, \\ldots, r^{n-1}` gives the whole set of unit roots (in\nsome permuted order)::\n\n    >>> for r in unitroots(6): print(r)\n    ...\n    1.0\n    (0.5 + 0.866025403784439j)\n    (-0.5 + 0.866025403784439j)\n    -1.0\n    (-0.5 - 0.866025403784439j)\n    (0.5 - 0.866025403784439j)\n    >>> r = unitroots(6, primitive=True)[1]\n    >>> for k in range(6): print(chop(r**k))\n    ...\n    1.0\n    (0.5 - 0.866025403784439j)\n    (-0.5 - 0.866025403784439j)\n    -1.0\n    (-0.5 + 0.866025403784438j)\n    (0.5 + 0.866025403784438j)\n\nThe number of primitive roots equals the Euler totient function `\\phi(n)`::\n\n    >>> [len(unitroots(n, primitive=True)) for n in range(1,20)]\n    [1, 1, 2, 2, 4, 2, 6, 4, 6, 4, 10, 4, 12, 6, 8, 8, 16, 6, 18]\n\n'
webere: str = "\nGives the Weber function\n\n.. math ::\n\n    \\mathbf{E}_{\\nu}(z) = \\frac{1}{\\pi}\n        \\int_0^{\\pi} \\sin(\\nu t - z \\sin t) dt\n\nwhich is an entire function of both the parameter `\\nu` and\nthe argument `z`. It solves the inhomogeneous Bessel differential\nequation\n\n.. math ::\n\n    f''(z) + \\frac{1}{z}f'(z) + \\left(1-\\frac{\\nu^2}{z^2}\\right) f(z)\n        = -\\frac{1}{\\pi z^2} (z+\\nu+(z-\\nu)\\cos(\\pi \\nu)).\n\n**Examples**\n\nEvaluation for real and complex parameter and argument::\n\n    >>> from mpmath import *\n    >>> mp.dps = 25; mp.pretty = True\n    >>> webere(2,3)\n    -0.1057668973099018425662646\n    >>> webere(-3+4j, 2+5j)\n    (-585.8081418209852019290498 - 5033.314488899926921597203j)\n    >>> webere(3.25, 1e6j)\n    (-1.117960409887505906848456e+434291 - 4.630743639715893346570743e+434290j)\n    >>> webere(3.25, 1e6)\n    -0.00002812518265894315604914453\n\nUp to addition of a rational function of `z`, the Weber function coincides\nwith the Struve H-function when `\\nu` is an integer::\n\n    >>> webere(1,3); 2/pi-struveh(1,3)\n    -0.3834897968188690177372881\n    -0.3834897968188690177372881\n    >>> webere(5,3); 26/(35*pi)-struveh(5,3)\n    0.2009680659308154011878075\n    0.2009680659308154011878075\n\nVerifying the differential equation::\n\n    >>> v,z = mpf(2.25), 0.75\n    >>> f = lambda z: webere(v,z)\n    >>> diff(f,z,2) + diff(f,z)/z + (1-(v/z)**2)*f(z)\n    -1.097441848875479535164627\n    >>> -(z+v+(z-v)*cospi(v))/(pi*z**2)\n    -1.097441848875479535164627\n\nVerifying the integral representation::\n\n    >>> webere(v,z)\n    0.1486507351534283744485421\n    >>> quad(lambda t: sin(v*t-z*sin(t))/pi, [0,pi])\n    0.1486507351534283744485421\n\n**References**\n\n1. [DLMF]_ section 11.10: Anger-Weber Functions\n"
whitm: str = '\nEvaluates the Whittaker function `M(k,m,z)`, which gives a solution\nto the Whittaker differential equation\n\n.. math ::\n\n    \\frac{d^2f}{dz^2} + \\left(-\\frac{1}{4}+\\frac{k}{z}+\n      \\frac{(\\frac{1}{4}-m^2)}{z^2}\\right) f = 0.\n\nA second solution is given by :func:`~mpmath.whitw`.\n\nThe Whittaker functions are defined in Abramowitz & Stegun, section 13.1.\nThey are alternate forms of the confluent hypergeometric functions\n`\\,_1F_1` and `U`:\n\n.. math ::\n\n    M(k,m,z) = e^{-\\frac{1}{2}z} z^{\\frac{1}{2}+m}\n        \\,_1F_1(\\tfrac{1}{2}+m-k, 1+2m, z)\n\n    W(k,m,z) = e^{-\\frac{1}{2}z} z^{\\frac{1}{2}+m}\n        U(\\tfrac{1}{2}+m-k, 1+2m, z).\n\n**Examples**\n\nEvaluation for arbitrary real and complex arguments is supported::\n\n    >>> from mpmath import *\n    >>> mp.dps = 25; mp.pretty = True\n    >>> whitm(1, 1, 1)\n    0.7302596799460411820509668\n    >>> whitm(1, 1, -1)\n    (0.0 - 1.417977827655098025684246j)\n    >>> whitm(j, j/2, 2+3j)\n    (3.245477713363581112736478 - 0.822879187542699127327782j)\n    >>> whitm(2, 3, 100000)\n    4.303985255686378497193063e+21707\n\nEvaluation at zero::\n\n    >>> whitm(1,-1,0); whitm(1,-0.5,0); whitm(1,0,0)\n    +inf\n    nan\n    0.0\n\nWe can verify that :func:`~mpmath.whitm` numerically satisfies the\ndifferential equation for arbitrarily chosen values::\n\n    >>> k = mpf(0.25)\n    >>> m = mpf(1.5)\n    >>> f = lambda z: whitm(k,m,z)\n    >>> for z in [-1, 2.5, 3, 1+2j]:\n    ...     chop(diff(f,z,2) + (-0.25 + k/z + (0.25-m**2)/z**2)*f(z))\n    ...\n    0.0\n    0.0\n    0.0\n    0.0\n\nAn integral involving both :func:`~mpmath.whitm` and :func:`~mpmath.whitw`,\nverifying evaluation along the real axis::\n\n    >>> quad(lambda x: exp(-x)*whitm(3,2,x)*whitw(1,-2,x), [0,inf])\n    3.438869842576800225207341\n    >>> 128/(21*sqrt(pi))\n    3.438869842576800225207341\n\n'
whitw: str = '\nEvaluates the Whittaker function `W(k,m,z)`, which gives a second\nsolution to the Whittaker differential equation. (See :func:`~mpmath.whitm`.)\n\n**Examples**\n\nEvaluation for arbitrary real and complex arguments is supported::\n\n    >>> from mpmath import *\n    >>> mp.dps = 25; mp.pretty = True\n    >>> whitw(1, 1, 1)\n    1.19532063107581155661012\n    >>> whitw(1, 1, -1)\n    (-0.9424875979222187313924639 - 0.2607738054097702293308689j)\n    >>> whitw(j, j/2, 2+3j)\n    (0.1782899315111033879430369 - 0.01609578360403649340169406j)\n    >>> whitw(2, 3, 100000)\n    1.887705114889527446891274e-21705\n    >>> whitw(-1, -1, 100)\n    1.905250692824046162462058e-24\n\nEvaluation at zero::\n\n    >>> for m in [-1, -0.5, 0, 0.5, 1]:\n    ...     whitw(1, m, 0)\n    ...\n    +inf\n    nan\n    0.0\n    nan\n    +inf\n\nWe can verify that :func:`~mpmath.whitw` numerically satisfies the\ndifferential equation for arbitrarily chosen values::\n\n    >>> k = mpf(0.25)\n    >>> m = mpf(1.5)\n    >>> f = lambda z: whitw(k,m,z)\n    >>> for z in [-1, 2.5, 3, 1+2j]:\n    ...     chop(diff(f,z,2) + (-0.25 + k/z + (0.25-m**2)/z**2)*f(z))\n    ...\n    0.0\n    0.0\n    0.0\n    0.0\n\n'
zeta: str = '\nComputes the Riemann zeta function\n\n.. math ::\n\n  \\zeta(s) = 1+\\frac{1}{2^s}+\\frac{1}{3^s}+\\frac{1}{4^s}+\\ldots\n\nor, with `a \\ne 1`, the more general Hurwitz zeta function\n\n.. math ::\n\n    \\zeta(s,a) = \\sum_{k=0}^\\infty \\frac{1}{(a+k)^s}.\n\nOptionally, ``zeta(s, a, n)`` computes the `n`-th derivative with\nrespect to `s`,\n\n.. math ::\n\n    \\zeta^{(n)}(s,a) = (-1)^n \\sum_{k=0}^\\infty \\frac{\\log^n(a+k)}{(a+k)^s}.\n\nAlthough these series only converge for `\\Re(s) > 1`, the Riemann and Hurwitz\nzeta functions are defined through analytic continuation for arbitrary\ncomplex `s \\ne 1` (`s = 1` is a pole).\n\nThe implementation uses three algorithms: the Borwein algorithm for\nthe Riemann zeta function when `s` is close to the real line;\nthe Riemann-Siegel formula for the Riemann zeta function when `s` is\nlarge imaginary, and Euler-Maclaurin summation in all other cases.\nThe reflection formula for `\\Re(s) < 0` is implemented in some cases.\nThe algorithm can be chosen with ``method = \'borwein\'``,\n``method=\'riemann-siegel\'`` or ``method = \'euler-maclaurin\'``.\n\nThe parameter `a` is usually a rational number `a = p/q`, and may be specified\nas such by passing an integer tuple `(p, q)`. Evaluation is supported for\narbitrary complex `a`, but may be slow and/or inaccurate when `\\Re(s) < 0` for\nnonrational `a` or when computing derivatives.\n\n**Examples**\n\nSome values of the Riemann zeta function::\n\n    >>> from mpmath import *\n    >>> mp.dps = 25; mp.pretty = True\n    >>> zeta(2); pi**2 / 6\n    1.644934066848226436472415\n    1.644934066848226436472415\n    >>> zeta(0)\n    -0.5\n    >>> zeta(-1)\n    -0.08333333333333333333333333\n    >>> zeta(-2)\n    0.0\n\nFor large positive `s`, `\\zeta(s)` rapidly approaches 1::\n\n    >>> zeta(50)\n    1.000000000000000888178421\n    >>> zeta(100)\n    1.0\n    >>> zeta(inf)\n    1.0\n    >>> 1-sum((zeta(k)-1)/k for k in range(2,85)); +euler\n    0.5772156649015328606065121\n    0.5772156649015328606065121\n    >>> nsum(lambda k: zeta(k)-1, [2, inf])\n    1.0\n\nEvaluation is supported for complex `s` and `a`:\n\n    >>> zeta(-3+4j)\n    (-0.03373057338827757067584698 + 0.2774499251557093745297677j)\n    >>> zeta(2+3j, -1+j)\n    (389.6841230140842816370741 + 295.2674610150305334025962j)\n\nThe Riemann zeta function has so-called nontrivial zeros on\nthe critical line `s = 1/2 + it`::\n\n    >>> findroot(zeta, 0.5+14j); zetazero(1)\n    (0.5 + 14.13472514173469379045725j)\n    (0.5 + 14.13472514173469379045725j)\n    >>> findroot(zeta, 0.5+21j); zetazero(2)\n    (0.5 + 21.02203963877155499262848j)\n    (0.5 + 21.02203963877155499262848j)\n    >>> findroot(zeta, 0.5+25j); zetazero(3)\n    (0.5 + 25.01085758014568876321379j)\n    (0.5 + 25.01085758014568876321379j)\n    >>> chop(zeta(zetazero(10)))\n    0.0\n\nEvaluation on and near the critical line is supported for large\nheights `t` by means of the Riemann-Siegel formula (currently\nfor `a = 1`, `n \\le 4`)::\n\n    >>> zeta(0.5+100000j)\n    (1.073032014857753132114076 + 5.780848544363503984261041j)\n    >>> zeta(0.75+1000000j)\n    (0.9535316058375145020351559 + 0.9525945894834273060175651j)\n    >>> zeta(0.5+10000000j)\n    (11.45804061057709254500227 - 8.643437226836021723818215j)\n    >>> zeta(0.5+100000000j, derivative=1)\n    (51.12433106710194942681869 + 43.87221167872304520599418j)\n    >>> zeta(0.5+100000000j, derivative=2)\n    (-444.2760822795430400549229 - 896.3789978119185981665403j)\n    >>> zeta(0.5+100000000j, derivative=3)\n    (3230.72682687670422215339 + 14374.36950073615897616781j)\n    >>> zeta(0.5+100000000j, derivative=4)\n    (-11967.35573095046402130602 - 218945.7817789262839266148j)\n    >>> zeta(1+10000000j)    # off the line\n    (2.859846483332530337008882 + 0.491808047480981808903986j)\n    >>> zeta(1+10000000j, derivative=1)\n    (-4.333835494679647915673205 - 0.08405337962602933636096103j)\n    >>> zeta(1+10000000j, derivative=4)\n    (453.2764822702057701894278 - 581.963625832768189140995j)\n\nFor investigation of the zeta function zeros, the Riemann-Siegel\nZ-function is often more convenient than working with the Riemann\nzeta function directly (see :func:`~mpmath.siegelz`).\n\nSome values of the Hurwitz zeta function::\n\n    >>> zeta(2, 3); -5./4 + pi**2/6\n    0.3949340668482264364724152\n    0.3949340668482264364724152\n    >>> zeta(2, (3,4)); pi**2 - 8*catalan\n    2.541879647671606498397663\n    2.541879647671606498397663\n\nFor positive integer values of `s`, the Hurwitz zeta function is\nequivalent to a polygamma function (except for a normalizing factor)::\n\n    >>> zeta(4, (1,5)); psi(3, \'1/5\')/6\n    625.5408324774542966919938\n    625.5408324774542966919938\n\nEvaluation of derivatives::\n\n    >>> zeta(0, 3+4j, 1); loggamma(3+4j) - ln(2*pi)/2\n    (-2.675565317808456852310934 + 4.742664438034657928194889j)\n    (-2.675565317808456852310934 + 4.742664438034657928194889j)\n    >>> zeta(2, 1, 20)\n    2432902008176640000.000242\n    >>> zeta(3+4j, 5.5+2j, 4)\n    (-0.140075548947797130681075 - 0.3109263360275413251313634j)\n    >>> zeta(0.5+100000j, 1, 4)\n    (-10407.16081931495861539236 + 13777.78669862804508537384j)\n    >>> zeta(-100+0.5j, (1,3), derivative=4)\n    (4.007180821099823942702249e+79 + 4.916117957092593868321778e+78j)\n\nGenerating a Taylor series at `s = 2` using derivatives::\n\n    >>> for k in range(11): print("%s * (s-2)^%i" % (zeta(2,1,k)/fac(k), k))\n    ...\n    1.644934066848226436472415 * (s-2)^0\n    -0.9375482543158437537025741 * (s-2)^1\n    0.9946401171494505117104293 * (s-2)^2\n    -1.000024300473840810940657 * (s-2)^3\n    1.000061933072352565457512 * (s-2)^4\n    -1.000006869443931806408941 * (s-2)^5\n    1.000000173233769531820592 * (s-2)^6\n    -0.9999999569989868493432399 * (s-2)^7\n    0.9999999937218844508684206 * (s-2)^8\n    -0.9999999996355013916608284 * (s-2)^9\n    1.000000000004610645020747 * (s-2)^10\n\nEvaluation at zero and for negative integer `s`::\n\n    >>> zeta(0, 10)\n    -9.5\n    >>> zeta(-2, (2,3)); mpf(1)/81\n    0.01234567901234567901234568\n    0.01234567901234567901234568\n    >>> zeta(-3+4j, (5,4))\n    (0.2899236037682695182085988 + 0.06561206166091757973112783j)\n    >>> zeta(-3.25, 1/pi)\n    -0.0005117269627574430494396877\n    >>> zeta(-3.5, pi, 1)\n    11.156360390440003294709\n    >>> zeta(-100.5, (8,3))\n    -4.68162300487989766727122e+77\n    >>> zeta(-10.5, (-8,3))\n    (-0.01521913704446246609237979 + 29907.72510874248161608216j)\n    >>> zeta(-1000.5, (-8,3))\n    (1.031911949062334538202567e+1770 + 1.519555750556794218804724e+426j)\n    >>> zeta(-1+j, 3+4j)\n    (-16.32988355630802510888631 - 22.17706465801374033261383j)\n    >>> zeta(-1+j, 3+4j, 2)\n    (32.48985276392056641594055 - 51.11604466157397267043655j)\n    >>> diff(lambda s: zeta(s, 3+4j), -1+j, 2)\n    (32.48985276392056641594055 - 51.11604466157397267043655j)\n\n**References**\n\n1. http://mathworld.wolfram.com/RiemannZetaFunction.html\n\n2. http://mathworld.wolfram.com/HurwitzZetaFunction.html\n\n3. [BorweinZeta]_\n\n'
